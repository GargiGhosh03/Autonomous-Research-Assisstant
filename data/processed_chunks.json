{
  "chunks": [
    {
      "id": "p1.pdf_chunk0",
      "text": "Brain, Behavior, and Immunity 115 (2024) 470-479\n\nELSEVIER\n\nContents lists available at ScienceDirect\n\nBrain Behavior and Immunity\n\njournal homepage: www.elsevier.com/locate/ybrbi\n\nx BRAIN, BEHAVIOR, and IMMUNITY\n\nMachine learning and artificial intelligence in neuroscience: A primer\n\nfor researchers\n\nCheck for ie",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk1",
      "text": "Fakhirah Badrulhisham a, Esther Pogatzki-Zahn b, Daniel Segelcke b, Tamas Spisak c,d,\n\nJan Vollert e,f,*\n\na Royal Devon and Exeter Hospital NHS Trust, Exeter, United Kingdom\n\nb Department of Anaesthesiology, Intensive Care and Pain Medicine, University Hospital Muenster, Muenster, Germany\n\nc Institute of Diagnostic and Interventional Radiology and Neuroradiology, University Medicine Essen, Essen, Germany",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk2",
      "text": "d Center for Translational Neuro- and Behavioral Sciences, Department of Neurology, University Medicine Essen, Essen, Germany\n\ne Department of Clinical and Biomedical Sciences, Faculty of Health and Life Sciences, University of Exeter, Exeter, United Kingdom\n\nf Pain Research, Department of Surgery and Cancer, Imperial College London, London, United Kingdom\n\nA R T I C L E I N F O\n\nA B S T R A C T",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk3",
      "text": "Keywords: Machine learning Artificial intelligence Predictive modelling Neuroscience Pain fMRI Behavioural research *omics\n\nArtificial intelligence (AI) is often used to describe the automation of complex tasks that we would attribute intelligence to. Machine learning (ML) is commonly understood as a set of methods used to develop an AI. Both have seen a recent boom in usage, both in scientific and commercial fields.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk4",
      "text": "For the scientific community, ML can solve bottle necks created by complex, multi-dimensional data gener- ated, for example, by functional brain imaging or *omics approaches. ML can here identify patterns that could not have been found using traditional statistic approaches. However, ML comes with serious limitations that need to be kept in mind: their tendency to optimise solutions for the input data means it is of crucial importance to externally validate any findings before considering them",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk5",
      "text": "more than a hypothesis. Their black-box nature implies that their decisions usually cannot be understood, which renders their use in medical decision making prob- lematic and can lead to ethical issues.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk6",
      "text": "Here, we present an introduction for the curious to the field of ML/AI. We explain the principles as commonly used methods as well as recent methodological advancements before we discuss risks and what we see as future directions of the field. Finally, we show practical examples of neuroscience to illustrate the use and limitations of\n\nML.\n\n1. Introduction",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk7",
      "text": "In multiple domains of healthcare and biology, we face problems for which there are no mono-causal solutions: either, because we do not know possible paths to solution, due to the numerous, multidimensional variables involved or because we can imagine a path to solution, but it turns out to be a puzzle so complex that we cannot solve it. An example for the former could be attempting to predict the development of tu- mours based on *omics-datasets: we have only very limited under- standing and",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk8",
      "text": "hypotheses of which of these data holds potential as predictive cancer biomarkers, but we assume that there is a reasonable chance that some of them do. An example for the latter would be the",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk9",
      "text": "folding of a potential protein based on its amino-acid sequence: we",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk10",
      "text": "generally know the principles, however, taking all interactions into ac- count makes it computationally intractable to fully calculate the precise folding (Dill et al., 2008). Both examples have more things in common. For one, if we cannot find a perfect solution, we would still be excited about a very close estimate: for proteins, all we need to know is if it will modulate relevant pathways, and for the prediction of cancer, any improvement over current clinical algorithms of prediction would",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk11",
      "text": "be valuable, even if they are not perfect. Second, even if we do not un- derstand how the result is reached, in both cases, we could still put the result to a meaningful use. And lastly, for both cases, we could draw on",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk12",
      "text": "large datasets of annotated previous cases.\n\nComputationally, we have found that a group of algorithms widely\n\nknown as machine learning (ML) can produce extraordinary results on\n\n* Corresponding author at: Department of Clinical and Biomedical Sciences, University of Exeter Medical School, EMS Building G09, St Luke’s Campus, Heavitree Rd., Exeter EX1 2LU, United Kingdom.\n\nRd., Exeter EX1 2LU, United Kingdom.\n\nE-mail address: j.vollert@exeter.ac.uk (J. Vollert).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk13",
      "text": "E-mail address: j.vollert@exeter.ac.uk (J. Vollert).\n\nhttps://doi.org/10.1016/j.bbi.2023.11.005\n\nReceived 26 April 2023; Received in revised form 16 October 2023; Accepted 8 November 2023\n\nReceived 26 April 2023; Received in revised form 16 October 2023; Accepted 8 November 2023\n\nAvailable online 14 November 2023\n\n0889-1591/© 2023 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY-NC license (http://creativecommons.org/licenses/by- nc/4.0/).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk14",
      "text": "Brain Behavior and Immunity 115 (2024) 470-479\n\nF. Badrulhisham et al.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk15",
      "text": "these kinds of problems, which are too complex to solve perfectly. This solution generally requires the use of enormous amounts of exemplary annotated data for which we can accept a good result, even if we cannot explain the solution path. To some degree, this can be thought to mimic human decisions: a “good” doctor will decide to take out a tumour they assume to be malignant based largely on experience (using clinical guidelines and algorithms as a handrail). One of the central promises of",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk16",
      "text": "artificial intelligence in healthcare therefor is to replace the experience of one doctor with that of thousands of doctors.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk17",
      "text": "While leading to breakthroughs in some of these questions like protein folding prediction (Jumper et al., 2021), ML algorithms face multiple challenges, which need to be taken into serious account before applying and when judging the results. In this review, we aim to intro- duce frequently used techniques, explain basic concepts, show oppor- tunities and risks in the field, and provide some examples of neuroscientific research applications. We intend this review as a primer for the interested –",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk18",
      "text": "we therefore will use simplifications that can be seen as oversimplifications at points. We do so to keep to a beginner’s level, but please keep in mind that many, most, or all of the concepts explained here are more nuanced and complex than portrayed here when drilling down into them.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk19",
      "text": "1.2. Curve fitting – The path to the optimal solution",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk20",
      "text": "AI and ML approaches solve problems by optimizing complex forms of curve fitting. For example, data points for two groups (distinguished by shape and colour) are plotted in Fig. 1 according to hypothetical Features A and B, and the goal is to determine the relationship between these features and the grouping. In the simplest of cases, this will be a straight line. Realistically, more complex models will provide better fits for real data. The simple straight line will then be under-fitted: it",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk21",
      "text": "will perform its task poorly, due to an overly simplistic model.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk22",
      "text": "On the other end, a more complex model will always be able to provide a better fit for the given data, to the point of perfection. This is due to the nature of the method: it will always optimise the fit based on the data provided. Every input dataset will, however, be flawed in some ways, and can never be a perfect representation of the real world – therefore, external validation (replication of findings in a data set separately from the original data, ideally independent in means of population",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk23",
      "text": "and collection) of each finding is mandatory for findings based on ML. For instance, a ML-model that performs near perfectly on its training data set and badly on external (validation) data is over-fitted: it is optimised for specific data rather than the general case and hence useless for all practical purposes (Fig. 1B).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk24",
      "text": "1.1. Terminology and prominent methods\n\nWhile clear definitions are missing for most of the terms in the field, the term artificial intelligence (AI) is often used to describe the automa- tion of complex tasks we would generally attribute intelligence to (Luger, 2004). Machine Learning (ML), then, is a loosely connected group\n\nof methods to achieve an AI approach.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk25",
      "text": "Here, we will talk exclusively about specific AI: an AI used to solve a specific problem, which it has been trained for. An unfortunate extrap- olation is often made from the advancement in specific AIs to the rise of a general AI (the AI you know from mo. vies and literature, an artificial intelligence being able to solve a wide range of problems and being able to find solutions to new problems on its own). It is possible, but currently not foreseeable that the advancements in specific AI will",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk26",
      "text": "lead to the development of a general AI. Think of it in the same way that the dis- covery of a possible drug target in an animal model might or might not lead to safe and effective medication against dementia in humans. Of course, the discovery of the drug target increases the chance of future treatment, but it is only one of many steps in a long journey, each of which can fail, and none of which we can predict how long they will",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk27",
      "text": "take.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk28",
      "text": "Further subdivisions can go along with intent of application (diag- nostic versus prediction), input needed (supervised versus unsupervised learning), or mathematical background of approaches used (linear versus non-linear, symmetric versus non-symmetric). The difference between diagnostic versus prediction is whether an AI scanning a picture of a mole can decide if this mole is cancerous, or whether it will become cancerous. There are specialised approaches for both, but for the pur- pose of",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk29",
      "text": "this primer, it suffices to know that they exist, and the general principles and challenges remain the same. An exploratory approach aiming to define subtypes of moles could be unsupervised (without the need for prior grouping, the groups found might or might not overlap with being benign or malign), while an approach actively seeking to separate cancerous versus benign moles would be supervised: it would learn from a dataset of moles labelled as “cancerous” or “non- cancerous”. Alas, there is",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk30",
      "text": "no similarly simple explanation for the mathematical theories involved, but we can see them as an increasingly complex modelling, with linear more simplistic than non-linear, and symmetric more simplistic than non-symmetric. Simplicity is ideal: if a simple model can explain your data, this is the ideal case, and more",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk31",
      "text": "complex models should only be used if simple approaches fail.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk32",
      "text": "This shows why for the development of an AI, at least two inde- pendent datasets are needed: a training dataset, on which the “learning” (or model optimisation) takes place, and a validation dataset, on which the derived AI is validated to show it is not over-fitted and generalises to unseen data. Choosing ideal training and validation datasets defines success and failure of any AI approach, and it cannot be overstated how carefully these need to be chosen. Ideally, validation and training",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk33",
      "text": "datasets should be completely independent – for example, data collected at a different hospital by separate examiners, on another continent, and so on, to prove maximal generalizability of the AI. Often, this will not realistically be possible, at the very least, however, if only a single dataset is available, it must be split, and a proportion kept separately as validation dataset. In this case, the results will not be immediately generalisable: any AI is only ever validated for the data is has",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk34",
      "text": "been tested on.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk35",
      "text": "1.3. Unsupervised learning",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk36",
      "text": "Unsupervised learning uses a set of methods that do not depend on knowledge of outcome, for example, modern evolutionary trees are based on clustering of genetic resemblance. The outcome (the tree) was unknown to begin with and is a sole result of the principles of the al- gorithm. Unsupervised learning methods can generally be said to search for symmetry, order, or structure in data (see Fig. 2 for a visualisation of various methods (Pedregosa et al., 2011)). This can be exemplified by using",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk37",
      "text": "two-dimensional data: if you can visually observe patterns (like in the rows 1,2,4,5 of Fig. 2), the right unsupervised learning will also find these patterns – only that we usually use high-dimensional, not two- dimensional data, which cannot be plotted easily. An advantage is that a symmetric form is less prone to overfitting and results can often more easily be transferred to external data. The shapes constructed by unsupervised ML algorithms are also easier to interpret, providing the",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk38",
      "text": "opportunity to shape our understanding of biology.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk39",
      "text": "Some of the most-used methods include dimension-reduction ap- proaches like principal component analysis (Pearson, 1901); hierarchi- cal clustering, like Ward (Ward, 1963) or Neighbour-joining (Saitou and Nei, 1987); fast, heuristic methods ideally suited for very large datasets like k-means (MacQueen, 1967); and density-based approaches like DBSCAN (density-based spatial clustering of applications with noise) (Ester et al., 1996). As shown in Fig. 2, none of these are inherently better than",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk40",
      "text": "others, how they perform will depend on the structure of",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk41",
      "text": "your data.\n\n471\n\nF. Badrulhisham et al.\n\nBrain Behavior and Immunity 115 (2024) 470-479\n\nF. Badrulhisham et al.\n\n— Training data (A) ; Under-fit (low accuracy) Balanced Over-fit (low external validity) Feature B Feature B Feature A Es) g 2 icf & C a) .\" enue en U5 Feature A — Validation data (8) ‘ Under-fit (low accuracy) Over-fit (low external validity) Feature B Feature B Feature B Feature A Feature A",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk42",
      "text": "Fig. 1. Curve-fitting models. These are artificial data for illustration only. The linear underfitting, both in the training data set (A) and in the validation data set (B) cannot capture the nonlinear shape of the data, while the over-fitting can perfectly separate the training data set from the validation data set, but this model leads to a reduced performance on another data set. Accepting the error of the balance fit leads to better generalizability overall and thus to a more robust model.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk43",
      "text": "1.4. Supervised learning\n\n1.5. Neural networks and deep learning",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk44",
      "text": "Supervised learning depends on a training dataset with known out- comes or classification, for example, pictures of moles and the infor- mation if these are malignant or not. The advantage is that they are able to uncover non-linear, non-symmetrical relationships, however, the concept of fully optimising a function on a given training dataset makes them prone to over-fitting or adjusting to bias in the dataset (Spisak, 2022), which is not always easily spotted.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk45",
      "text": "In its simplest (though by no means simple) form, a supervised ma- chine learning can be a multiple linear regression that can be replaced by regularised linear regression models that can control model\n\ncomplexity or non-linear regression models if warranted by the data.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk46",
      "text": "Complex, non-linear, non-symmetrical methods have been respon- sible for most of the recent fast advances in the field like facial detection and other complex image processing tasks, protein folding and form the basis of ChatGPT. Support Vector Machines (Cortes and Vapnik, 1995), k-nearest neighbours (Cover and Hart, 1967), and Hidden Markov Models (Rabiner and Juang, 1986) and Markov Chain Monte Carlo methods (Hamra et al., 2013) are some of the most commonly used examples. They are based on",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk47",
      "text": "highly distinct mathematical models and assumptions, and their use differs, as they have been demonstrated to excel in different fields. Here, as a general example for supervised ma- chine learning, we will focus on neural networks (Hopfield, 1982), since they have gained most attention, which has been particularly the case through the development of Deep Learning (Hinton et al., 2006), a variant of neural networks.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk48",
      "text": "Neural networks are a method that has been developed mimicking biological process, similar to evolutionary algorithms. A neural network in its simplest form consists of an input layer (the features of your data), a hidden layer, and an output layer (the classification or prediction) (McCulloch and Pitts, 1943). The multiple nodes (perceptrons) of these layers are interconnected (see Fig. 3), and the number of hidden nodes will determine the complexity of the network (as well as its risk of over-",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk49",
      "text": "fitting). A node is modelled after a synapse, based on input signals, it provides forward a signal, or not (inspired by a post-synaptic potential either reaching the activation threshold at the axon hillock or not). In our (by now slightly overused) example of pictures of benign and ma- lignant moles, the input layer would be those pictures, the output layer would be the label provided (“cancerous” or “non-cancerous”). The hidden layer is the “ghost in the machine”: the black box classifying,",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk50",
      "text": "with no explanation how the classification was reached.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk51",
      "text": "Many recent advances in machine learning have been rooted in deep learning, using the principles of neural networks with multiple hidden layers, and hundreds, thousands, millions, and billions of nodes. Each layer can be interpreted as a level of abstraction, and the algorithms allow the network to choose and refine its own structure (LeCun et al., 2015). Deep learning has overtaken many classic AI techniques, and is behind many of the most impressive recent successes, including general use like",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk52",
      "text": "chatGPT and its successor, GPT-4 (OpenAI, 2023) and scientific tasks like protein folding (Jumper et al., 2021). However, deep learning is not a “magic bullet”, depending on dataset structure, classical ma- chine learning models (like tree-based models) can outperform them in",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk53",
      "text": "many real scenarios (Grinsztajn et al., 2022).\n\nSupervised (deep) learning approaches are generally “black boxes”.\n\n472\n\nF. Badrulhisham et al.\n\nBrain Behavior and Immunity 115 (2024) 470-479\n\nF. Badrulhisham et al.\n\nMini Batch k means Affinity Propagation Mean Shift Spectral Clustering Ward Birch Gaussian Mixture Agglomerative DBSCAN © Ww WV Ly) aK Ed @ 9",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk54",
      "text": "Fig. 2. The ability of various cluster methods to separate non-linear datasets, simulated using scikit-learn (Pedregosa et al., 2011). These are artificial data for illustration only. The ability of the clustering method to separate your data will depend on the structure of your data, which, in multiple dimensions, cannot be plotted and therefore remains usually unknown. The lowest panel shows that, even for uniform data distribution, the algorithm will always present a “best” solution.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk55",
      "text": "Hidden layer Output layer Input layer\n\nFig. 3. Simple example of a three-layer perceptron network. The input layer provides the knowledge we have, the output layer the result. The hidden layer is the “ghost in the machine”, the black box-part of the decision-making pro- cess. Modern deep learning AIs can use multiple hidden layers with almost endless nodes, GPT-4 uses billions of nodes, and trillions of parameters\n\n(OpenAI, 2023).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk56",
      "text": "They do not follow clear and identifiable rules but greedily learn from examples. This is similar to how humans learn intuitively compared to\n\nhow we learn at school: you are often more likely to know grammatic",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk57",
      "text": "rules of a second language you learned at school than your native lan- guage. At the same time, you might well be better at grammar in your native language, as you do not base your decision on the (simplified) grammatical rules but on practical usage experience of the common case and the many exemptions.\n\n2. Risks",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk58",
      "text": "With growing use, one of AI approaches inherent features – its black box approach – is becoming a growing concern. When used for explor- atory research, AI can find novel targets that are subsequently investi- gated. In this case, a black box is of little concern, as the meaningfulness of biological pathways and medical sciences will be described in sub- sequent experiments. However, AI is now used to assist human decision making (not only) in medicine, where it can be of high importance to",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk59",
      "text": "know why and how a decision was formed.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk60",
      "text": "Both the optimisation to training data and the subsequent applica- tion of AI by a wide range of users can lead to unintended consequences. An AI trained to detect malignant skin lesions has been shown to have learned that the presence of rulers in pictures shows malignance, as they are used more often for scaling in pictures of malignant lesions, biasing the training data set (Narla et al., 2018). On the user end, dermatologists will often use markers to highlight the lesion on a picture, which",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk61",
      "text": "can also increase the chance of the AI classifying the lesion as malignant (Winkler et al., 2019). An AI predicting complications of pneumonia wrongly suggested patients with asthma as low risk of pneumonia (while the opposite is the case) (Caruana et al., 2015). While these were easy-to- uncover teething problems, they illustrate the unforeseen conse- quences of invisible bias in data, and the fatal consequences blind trust",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk62",
      "text": "in AI-assisted decision making can have.\n\nAIs are trained on large datasets, and results can therefore only be as\n\n473\n\nBrain Behavior and Immunity 115 (2024) 470-479\n\nF. Badrulhisham et al.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk63",
      "text": "good as the input data (“garbage in, garbage out” rule of databases). This means that during data collection, careful consideration must be given to avoid errors in labelling or similar aspects that can lead to distorted results. As AI methods become more widely available, they will often be used on datasets that are fundamentally of a too-low quality. Results should be discarded, as only high-quality input data can lead to results that we can have enough trust in to warrant further use or",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk64",
      "text": "research.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk65",
      "text": "Even the best and well-collated existing large datasets are biased. This is partly based in human history. For example, image processing AIs often learn on ImageNet, but this database is heavily biased towards data from the US and Western Europe, while China and India, comprising more than a third of the world’s population, only constituted just 3 % of ImageNet data in 2017 (Shankar et al., 2017). Since AIs aim to optimise their accuracy, ignoring minorities is a frequent feature (Zou and",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk66",
      "text": "Schiebinger, 2018).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk67",
      "text": "approach, that is not always the case (Marek et al., 2022). The black box nature and often commercial use of ML products can lead to reproduc- ibility far lower compared to using traditional statistics (and it is not high there to begin with), as step-by-step replication cannot necessarily be done. This is compounded by the wide range of available methods (Hoffmann et al., 2021), making it difficult for external groups to independently replicate findings. The hypothesis-free, pattern-searching",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk68",
      "text": "approach of AI is, as mentioned above, prone to over-fitting, which can be abused to present findings that are likely random as real – similar to p-hacking or HARKing techniques in traditional statistics. However, black box findings that are unexplainable, unreproducible, and unre- plicable, can only be detrimental to the scientific progress, and oppose the principles of scientific research. We therefore note that conduct guidelines are needed, and ethical frameworks need to be developed which",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk69",
      "text": "also take transparency of reporting data and code sharing and reproducibility into account.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk70",
      "text": "In addition, by learning from human annotated data, the AI will learn our biases. In the beginning of this piece, we used the term “replace the experience of one doctor with that of thousands of doctors”. This will also include replacing the bias of one doctor with that of thousands of doc- tors. While we often believe any computer decision is impartial and unbiased, it has been shown multiple times that this is not the case: internet search algorithms propagate gender stereotypes (Vlasceanu and",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk71",
      "text": "Amodio, 2022), and AI-based decision making in US hospitals has been shown to disadvantage Black patients, negating them necessary care and treatment a similar White patient would have received (Obermeyer et al., 2019).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk72",
      "text": "2.1. Explainable AI",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk73",
      "text": "One approach to reduce the impact of the risks and limitations is opening up the black box by using explainable AI (XAI) methods (Vilone and Longo, 2021). In contrast to the black box of classic AI, they aim to create a white box, where decision making can be traced and understood (Castelvecchi, 2016). XAIs aim to be transparent, interpretable and explainable, features which would make them ideal for assisted decision making in healthcare (Rieg et al., 2020). However, with growing complexity of",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk74",
      "text": "AIs, explainability becomes near impossible to achieve, which can be understood when considering how for example neural networks aim to mimic, rather than understand human decision making – they do so as we cannot sufficiently explain how we come to decisions and cannot easily put our experience into simple rules. By training AIs to do similar, we end up with similarly complex decision making processes, that inherently cannot be explained in simple ways (Bhatt et al., 2020).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk75",
      "text": "2.3. A note on anthropomorphisms and hype",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk76",
      "text": "The field of AI/ML is, unfortunately, rich in anthropomorphising terms that install unrealistic expectations for readers and listeners. “We used a machine-learning approach to train a neural network with evolutionary improvement to achieve an artificial intelligence” is a sentence not unthinkable to read, or “brain-inspired deep neural net- works with attention mechanism that learned complex hidden repre- sentations to achieve an artificial intelligence system for diagnosis of cancer”. While",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk77",
      "text": "there are historic reasons for each of these terms (often, they were developed by mimicking human or biological behaviours and strategies), they evoke science-fiction associations they do not warrant. This can go so far as to computer programmers (Metz, 2022) or jour- nalists (Roose, 2023) believing the chatbot they converse with is sentient (or close to it). When looking at a robotic production arm in an industrial setting, we do not automatically think of the Terminator, in the same way, we",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk78",
      "text": "should not think of Blade Runner when reading about ChatGPT. The literature and film versions of robots and AIs are general: they have fully mastered to mimic humans and are able to make de- cisions and alter their behaviour almost freely. The robotic production arm and ChatGPT only mimic one very specific task, and, without explicit instructions, will not do that, either.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk79",
      "text": "3. Application in neuroscience\n\n3.1. Machine learning in preclinical neuroscience\n\n2.2. Reporting, transparency, reproducibility, and replicability",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk80",
      "text": "As, unfortunately, in all areas of research, there are concerns about transparent reporting and “spin” practices in machine learning, under- lined by a recent systematic review (Andaur Navarro et al., 2023). There are no current gold standards on conduct and reporting of ML and AI medical research, partly of course, as they are just a method for multiple means. Generally, reporting guidelines on AI/ML will include elements like mentioning the use of ML, as well as describing the specific methods",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk81",
      "text": "and purpose, methods to control for errors, and reporting of common",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk82",
      "text": "model-metrics.\n\nSpecific reporting guidelines can be found in the REWARD EQUA- TOR network for clinical trial protocols (SPIRIT-AI (Rivera et al., 2020)) and clinical trials (CONSORT-AI (Liu et al., 2020)). When developing tools used for assistance in decision making, DECIDE-AI should be fol-\n\nlowed (Vasey et al., 2022).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk83",
      "text": "A framework for reporting applicable to all medical AI research can be found in the MI-CLAIM checklist (Norgeot et al., 2020). Here, the authors also touch on the difficult topic of reproducibility. While, in some situations, ML/AI approaches can lead to findings that are easier to replicate as the effect sizes are higher (Spisak et al., 2023), making it",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk84",
      "text": "Identifying the neural elements that influence naturalistic behavioral motifs in freely moving animals stands as one of the paramount chal- lenges in contemporary neuroscience. To unravel these mechanisms, a variety of sophisticated ML/AI approaches are being formulated and utilized to discern behavioral patterns in rodents. (Fig. 4A). The detailed objective annotation of behavioural trajectories in real time without known influencing variables such as day and night phase or experi- menters are",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk85",
      "text": "crucial characteristics of modern methods (Sorge et al., 2014; Sadler et al., 2022). The capability to automatically extract be- haviors in rodents is a developmental leap that can fulfil this require- ment. In the age of machine and deep learning, it is possible to extract and quantify an almost infinite number of behavioural variables, to decompose behaviours into categories, subcategories and into minute behavioural sequences. However, the booming field of behavioural neuroethology still has",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk86",
      "text": "limitations because the community has not yet consolidated, developed and applied methods, which translates to an insufficient transfer of models from lab to lab. This arises from inade- quately established benchmarking and the scarce availability of exten- sive, thoroughly annotated data sets. In addition, the extraction of numerous variables correlates with an increasing amount of data, which requires data organisation, transfer and storage options. This is associ-",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk87",
      "text": "more likely to achieve similar qualitative findings in a separate\n\nated with a lack of platforms that enable the sharing of large data sets,\n\n474\n\nF. Badrulhisham et al.\n\nBrain Behavior and Immunity 115 (2024) 470-479\n\nF. Badrulhisham et al.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk88",
      "text": "(A) Video based recording of behaviour patterns a Data storage & h Annotate samples (D) Automated extraction of behaviour sequence © Training and model development Data storage uence. ames of Pain-related behaviour | Manual body part annotation ae ° 2 Rodent specific ~ a behavior Annotation Novel frames uence of ++ Tames e090 y Encoder-decoder Automated ‘network hl behaviour i classification Pose-estimation model Rearing” using body-part tracking",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk89",
      "text": "Fig. 4. Applications of machine learning in animal behavioural analyses. (A) Using AI/ML approaches, rodent-specific behaviours can be identified, isolated, and characterised. (B) Due to the enormous amount of data collected, data storage and the manual annotation of data sets are challenges in this method. By manually annotating body parts of rodents, such as tails, paws, ears or even parts of the face, (C) estimate body posture models over time can be generated via an encoder-",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk90",
      "text": "decoder network and in the next step, (D) behavioural components can be automatically detected and named.\n\nsimilar to sequencing databases in Omics (e.g., https://www.omicsdi. org and (Conesa and Beck, 2019)). In addition, most behavioural research labs have limited access to the latest tools for extracting and analysing behaviour, as their implementation requires advanced com-\n\nputer skills.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk91",
      "text": "The automated identification of behavioral motifs (stereotypical, sub-second) in most protocols unfolds through a graduated process and can be categorized into supervised and unsupervised approaches (as previously mentioned). In supervised approaches (e.g., JAABA (Kabra et al., 2013)), a user trains algorithms to recognise behavioural motives. In contrast, the unsupervised method (e.g., MoSeq (Wiltschko et al., 2015)) separates individual vi. deo sequences into behavioural syllables without",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk92",
      "text": "bias. The current development of applications that use indirect methods for behavioural extraction has emerged. Unsupervised or su- pervised ML approaches are also used in this indirect approach, the latter being the more common. In this method, virtual body landmarks of the animal (e.g., ears, paw, tail, etc, see Fig. 4B) are used to estimate body posture over time. Various open-source programmes can follow this approach. Examples of these tools include DeepLabCut (Mathis et al., 2018; Lauer et",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk93",
      "text": "al., 2022), SLEAP (Pereira et al., 2022), DANNCE (Dunn et al., 2021) or Anipose (Karashchuk et al., 2021).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk94",
      "text": "Initiating the identification of behavioral patterns begins with vi. deo recording. In recent years, the enhancement in camera image quality, coupled with a substantial reduction in initial costs, has rendered this a feasible option for a wide-ranging community. This is especially true for the vi. deo sampling rate (frames per second), which is necessary to extract behavioural sequences that occur in the sub-second range (e.g., hind paw withdrawal response to a stimulus of different modality)",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk95",
      "text": "and recording spectra (e.g., infrared). But also, the depth of field is a crucial characteristic, which, especially during observation in the home cage setting, is needed to track individual animals in three-dimensional space and to isolate complex behavioural patterns. Here, 3D approaches can also be helpful, using multiple cameras with different viewing angles to refine behaviour estimation in complex environments (e.g. laboratory cages) with multiple animals (Nath et al., 2019). Point",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk96",
      "text": "estimation models allow not only individual observation but also behavioural extraction of multiple animals within the same vi. deo (same cage) sequence and the associated social interaction (Lauer et al., 2022; Per- eira et al., 2022). The construction of these markerless point estimation models employs neural networks with an encoder-decoder architecture to generate probability density diagrams. These diagrams are derived from features that the network is required to learn. Output diagram",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk97",
      "text": "shows the probability of the existence of the learned feature. The resulting probability densities will be used for localisation, which is the basis for whole-body or whole-limb point skeletons for subsequent pose estimation and behaviour classification. In order to extract more",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk98",
      "text": "rearing, social interaction from the point probabilities, advanced tracking algorithms are used in combination with other algorithms (e.g. UMAP (McInnes et al., 2018), random forest classifiers), or deep- learning models (e.g., recurrent convolutional neural networks). Tools used in this field to extract and quantify information on attitude and behaviour include SiMBA (Nilsson et al., 2020), B-SOiD (Hsu and Yttri, 2021), MoSeq (Wiltschko et al., 2015) and uBAM (Brattoli et al., 2021), among",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk99",
      "text": "others. The possibility of longitudinal 24/7 extraction of natu- ralistic behaviour, hypothesis-driven modulation of cage environment (e.g. day/night cycle, enrichment, selective socialisation of cage mates with different health status (Segelcke et al., 2023)) and integrating state- of-the-art optogenetic tools for the targeted modulation of neuronal structures makes such approaches even more valuable (Hao et al.,",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk100",
      "text": "2021).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk101",
      "text": "Some of these tools and analysis pipelines have already been vali- dated for the extraction of highly complex pain-related behaviour. Pain- related behaviours can be expressed in a variety of behavioural ways, but most assays have focused on experimental stimulation of the hind paw with noxious or non-noxious stimuli of different modalities (e.g., mechanical, thermal) and the resulting paw withdrawal response has established itself as the most common method for detecting pain-related behaviours",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk102",
      "text": "(Deuis et al., 2017). Present ML approaches concentrate on enhancing the binary assessment of the withdrawal response by auto- mating the reflection and affective components, aiming to isolate sig- natures differentiating between noxious and non-noxious stimuli. In recent work, paw and body movement features can be automatically extracted from behavioural trajectories using e.g., PAWS (Pain Assess- ment at Withdrawal Speeds, based on SLEAP) to then identify infor- mation from paw kinematics",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk103",
      "text": "(Abdus-Saboor et al., 2019; Jones et al., 2020). Based on these data, a univariate pain score was developed using ordinal logistic regression for different harmless and noxious stimuli at the posterior paw and validated with basolateral amygdala activation",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk104",
      "text": "(Jones et al., 2020).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk105",
      "text": "Taken together, ML/AI pipelines for automated behavioural analysis have proven to be extremely powerful in different research directions, with only a subset of current pain research in mice described here as an example. Increased implementation of these automated behavioural approaches (preferably using comparable systems) can, consequently, increase the efficiency and translational potential of preclinical in- vestigations and improve their reproducibility. For scientists working in",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk106",
      "text": "neuro-behavioural research, there are unprecedented opportunities in implementing automated behavioural analysis tools. Increased tool implementation can consequently enhance the efficiency and trans- lational potential of preclinical investigations. However, a real improvement in the replicability and reproducibility of data from such innovative approaches can only be achieved in the long term based on",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk107",
      "text": "nuanced behavioural signatures, such as grooming, straightening,\n\ncomparable or uniform standards: a challenge that must be met in the\n\n475\n\nBrain Behavior and Immunity 115 (2024) 470-479\n\nF. Badrulhisham et al.\n\nfuture.\n\n3.2. Machine learning in neuro-gastroenterology\n\n(Mayer et al., 2019). We look forward to the findings of prospectively designed and registered studies, which will provide the first confirma- tory results in the field (Berentsen et al., 2020).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk108",
      "text": "Neuro-gastroenterology is the study of functional gut disorders such as irritable bowel syndrome (IBS) and functional dyspepsia, which are prevalent worldwide and can be challenging for clinicians to diagnose and treat and are critical for public health as they result in disability, impaired quality of life, and economic burden (Black and Ford, 2020).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk109",
      "text": "At its core is the understanding of the gut-brain axis, which describes the complex, bi-directional communication, and interaction between the central and enteric nervous system (Carabotti et al., 2015). Neuro- gastroenterology is a field with challenges that make it particularly suited to attempt machine learning approaches: for better understanding of the underlying mechanisms, using microbiomic and metabolomic datasets results in high-dimensional data, which needs to be integrated with",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk110",
      "text": "multiple levels of patient-reported outcomes or imaging data (fMRI). Such complex, multi-layered data can be mined using ML (Kaur et al., 2021).",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk111",
      "text": "3.3. AI in the intersection of cognitive, computational, and clinical neurosciences",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk112",
      "text": "AI and cognitive neuroscience live in a symbiotic relationship. While the former continuously draws inspiration from our knowledge of bio- logical neural systems to develop artificial neural networks, the latter harnesses the power of AI to expand our understanding of these bio- logical systems (Kriegeskorte and Douglas, 2018). Examples range from the use of computational models based on reinforcement learning al- gorithms or recurrent neural networks to model human adaptive behaviour and",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk113",
      "text": "decision making (Gl¨ascher et al., 2010; Ito et al., 2022), to deep neural networks that help us better understand and decode how brain activity represents images viewed (Seeliger et al., 2018), and words heard or spoken by (Anumanchipalli et al., 2019; Goldstein et al., 2022) human participants.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk114",
      "text": "There is increasing evidence that gut microbiota plays a key role in the regulation of the gut-brain axis. In addition to their local interactions with intestinal cells and the enteric nervous system, microbes in the gut have also been shown to modulate the central nervous system through neuroendocrine and metabolic pathways (Martin et al., 2018). It is becoming clear that the composition of the gut microbiome can there- fore influence a wide range of disorders – proximal somatoform",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk115",
      "text": "gastrointestinal disorders such as functional dyspepsia and IBS, but also mental health disorders such as depression (Morais et al., 2021). Using ML, microbial signatures have been shown to potentially play a role in psychological distress in IBS (Peter et al., 2018), depression phenotype (Stevens et al., 2021), amnestic mild cognitive impairment (Liu et al., 2021), autism-spectrum disorders (Wu et al., 2020), and others. A pilot clinical study demonstrated how using ML to personalise",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk116",
      "text": "nutritional strategy based on individual gut microbiome features could lead the way towards a personalised treatment for IBS (Ghaffari et al., 2022). In this study, individual microbiome modulation through diet significantly improves IBS-related symptoms in patients with IBS-mixed over regular, non-individualised IBS diet (Karakan et al., 2022). While all these findings should be seen as serendipitous, exploratory findings for now, they might advance our understanding of the generation, and",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk117",
      "text": "potential",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk118",
      "text": "treatment, of these diseases in previously unexpected ways.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk119",
      "text": "AI-assisted decision-making might in the future add to clinical al- gorithms (Kordi et al., 2022), although current findings need to be independently validated and replicated. However, we are starting to learn crucial lessons along the way: for example, IBS-constipation and functional constipation have been treated as distinct conditions, thought to have distinct pathophysiology. Using an ML approach to compare the accuracy of diagnostic models for IBS-constipation and functional con- stipation",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk120",
      "text": "based on ’uni-symptomatic’ versus ’syndromic’ models, Ruffle et al (Ruffle et al., 2021) have shown that syndromic models do not significantly improve diagnostic accuracy, which suggests that they are not separate conditions but a single syndrome within one clinical",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk121",
      "text": "In addition to enhancing our understanding of micro- and macro- scale neurocomputational processes, AI/ML have the potential to open up new avenues for translational and clinical research. ML-based pre- dictive models, commonly referred to as “neural signatures” or “neu- romarkers”, integrate information from complex neural measures (fMRI, EEG, MEG, etc.) to decode and predict various clinical and behavioural traits or states.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk122",
      "text": "Several studies aim to construct neuromarkers that can directly di- agnose or characterise various clinical conditions (de Vos et al., 2018; Horien et al., 2022; Jiang et al., 2023). In such studies, however, it often becomes hard to disentangle what is being modelled because of the multidimensional and heterogeneous nature of clinical conditions and co-occurring health conditions (e.g., co-morbidities, medication use). Neuromarker research has thus turned towards the so-called “compo- nent",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk123",
      "text": "process approach” (Woo et al., 2017), which aims to first develop neural signatures for basic “component processes”, i.e. basic traits or states that can be examined in standardised circumstances and even experimentally manipulated in some cases. The resulting neural signa- tures can serve as robust and explainable intermediate features for the modelling of multiple clinical conditions. One of the pioneering exam- ples is the Neurologic Pain Signature (NPS (Wager et al., 2013)), a machine",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk124",
      "text": "learning model that derives an objective readout of ongoing pain experience from brain activity, as measured by fMRI. The NPS has been extensively validated by a series of studies and was found to display high reliability, broad external validity, and strong effect sizes in large independent samples (Zunhammer et al., 2018; Han et al., 2022). Task- elicited brain activity has also been found to be predictive for vicarious pain (Zhou et al., 2020), fear (Zhou et al., 2021), negative affect (Chang",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk125",
      "text": "et al., 2015), craving (Garrison et al., 2023), reward (Speer et al., 2023) and many other states and traits. Multivariate ML models can also capitalise on brain activity measured in lack of any explicit stimulation (resting state), or even on brain morphology, to predict individual traits like pain sensitivity (Spisak et al., 2020; Kotikalapudi et al., 2023), learning (Kincses et al., 2023), cognition (Sripada et al., 2020), intel-",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk126",
      "text": "spectrum.\n\nIntegration of structural and functional brain imaging into neuro- gastroenterology will lead to a deeper understanding of disease mech- anisms, and a better understanding of the microbiome-gut-brain axis (Mayer et al., 2019). Using a support vector machine ML approach, Mao et al (Mao et al., 2020) showed an altered resting-state functional con- nectivity and effective connectivity of the habenula for IBS patients compared to healthy controls, advancing our understanding of the brain",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk127",
      "text": "regions involved in IBS.\n\nTaken together, neuro-gastroenterology is a field that can certainly profit from the application of ML approaches. However, current studies often suffer from low reporting quality, and the complex nature of data involved calls for the creation of larger, multi-site consortia to generate\n\nreliable, high-quality, multi-dimensional data of high external validity\n\nlectual capacity (Tong et al., 2022), and others.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk128",
      "text": "While ML-based brain signatures can reach unprecedented effect sizes (Hedges g = 2.3 in case of the NPS), predictive modelling itself is not a magic bullet. The lack of external validation and bad methodo- logical practice lead, in many cases, to overly optimistic performance estimates and unrealistic expectations regarding the usefulness of such models (Sui et al., 2020; Varoquaux and Cheplygina, 2022). Just like traditional univariate analyses, such low-performing models still suffer from",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk129",
      "text": "limited power, replicability, and predictive utility even with sample sizes in the thousands (Marek et al., 2022; Spisak et al., 2023). Another problem is that such brain-based models are susceptible to capture spurious or out-of-interest associations that can be detrimental to the model’s clinical validity and generalizability and lead to",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk130",
      "text": "476\n\nBrain Behavior and Immunity 115 (2024) 470-479\n\nF. Badrulhisham et al.\n\nsensitivity to artefacts – in practice, this can mean minority- disadvantaging or racially biased models (Spisak, 2022).\n\nCRediT authorship contribution statement",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk131",
      "text": "In summary, AI holds immense potential not only for expanding our understanding of how the brain works but also for making this knowl- edge applicable in clinical contexts and to complement existing clinical approaches. However, to realise this potential, neuromarkers of the future must overcome significant challenges, such as ensuring broad generalizability across diverse contexts, promoting equity across sub- populations, and developing models with high neuroscientific validity and",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk132",
      "text": "interpretability.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk133",
      "text": "Fakhirah Badrulhisham: Writing – review & editing, Writing – original draft. Esther Pogatzki-Zahn: Writing – review & editing. Daniel Segelcke: Visualization, Writing – review & editing, Writing – original draft. Tamas Spisak: Writing – review & editing, Writing – original draft. Jan Vollert: Visualization, Writing – review & editing, Conceptualization, Writing – original draft.\n\nDeclaration of Competing Interest\n\n4. Resources and further reading",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk134",
      "text": "There are multiple starting points to experimenting with ML, for a user experienced in using Python, we highly recommend scikit-learn (Pedregosa et al., 2011). Its rich online resources and as well as its focus on essential methods make it a great place for beginners that still goes a long way. Fig. 2 has been created using sample data from scikit-learn. For a (pun intended) deeper dive, tensorflow (Ramsundar, 2018) and PyTorch (Ketkar, 2017) are open-source platforms for deep learning by Google",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk135",
      "text": "and OpenAI.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk136",
      "text": "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\nData availability\n\nNo data was used for the research described in the article.\n\nReferences",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk137",
      "text": "A developing quasi-standard in biological data science is R statistical computing (R Core Team, 2022). R is an incredibly rich open-source project, with endless resources for biomedical sciences. A dedicated online community has created packages (collections of functions) for almost every possible task. For machine learning specifically, this in- cludes for example caret (for regression models), e1071 (for k-nearest neighbours and support vector machines), neuralnet (for neural net- works), and",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk138",
      "text": "keras (for deep learning). The advantage of using R is that is does not stop at ML: there are excellent tools for any aspect of biomedical data, many of them have been collated within the Bio- conductor project (Gentleman et al., 2004). Visualisation of any plot can be achieved using ggplot2, and shinyapps allow construction of web- based user interfaces. There are also commercial packages for ML, Matlab for example has a valuable ML toolbox and is used for both",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk139",
      "text": "Abdus-Saboor, I., Fried, N.T., Lay, M., Burdge, J., Swanson, K., Fischer, R., Jones, J., Dong, P., Cai, W., Guo, X., Tao, Y.-X., Bethea, J., Ma, M., Dong, X., Ding, L., Luo, W., 2019. Development of a Mouse Pain Scale Using Sub-second Behavioral Mapping and Statistical Modeling. Cell Reports 28, 1623–1634.e4.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk140",
      "text": "Andaur Navarro, C.L., Damen, J.A., Takada, T., Nijman, S.W.J., Dhiman, P., Ma, J., Collins, G.S., Bajpai, R., Riley, R.D., Moons, K.G., Hooft, L., 2023. Systematic review finds “Spin” practices and poor reporting standards in studies on machine learning- based prediction models. Journal of Clinical Epidemiology. https://doi.org/ 10.1016/j.jclinepi.2023.03.024.\n\nAnumanchipalli, G.K., Chartier, J., Chang, E.F., 2019. Speech synthesis from neural decoding of spoken sentences. Nature 568, 493–498.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk141",
      "text": "Berentsen, B., Nagaraja, B.H., Teige, E.P., Lied, G.A., Lundervold, A.J., Lundervold, K., Steinsvik, E.K., Hillestad, E.R., Valeur, J., Brønstad, I., Gilja, O.H., Osnes, B., Hatlebakk, J.G., Ha´asz, J., Labus, J., Gupta, A., Mayer, E.A., Benitez-P´aez, A., Sanz, Y., Lundervold, A., Hausken, T., 2020. Study protocol of the Bergen brain-gut- microbiota-axis study: A prospective case-report characterization and dietary intervention study to evaluate the effects of microbiota alterations on",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk142",
      "text": "cognition and anatomical and functional brain connectivity in patients with irritable bowel",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk143",
      "text": "commercial and research applications.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk144",
      "text": "We have aimed to provide a short introduction to machine learning in general, and its application in neurosciences, but of course, this has remained somewhat superficial. Others have taken similar, but com- plimentary approaches. Connor (Connor, 2019) provides a more methods-focussed introduction, while others focus on practical aspects for application in, e.g., pain research (L¨otsch et al., 2022). For deeper reads, there are many. For using R in biomedical research, the University of",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk145",
      "text": "California, Riverside, has collated excellent learning materials (GEN242, 2022). Finally, Zou and Schiebinger (Zou and Schiebinger, 2018) summarise bias inherent in human data and what it means for AI in a plastic way.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk146",
      "text": "syndrome. Medicine 99, e21950.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk147",
      "text": "Bhatt, U., Xiang, A., Sharma, S., Weller, A., Taly, A., Jia, Y., Ghosh, J., Puri, R., Moura, J. M.F., Eckersley, P., 2020. Explainable machine learning in deployment, in: FAT* ’20. Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency : January 27-30, 2020, Barcelona, Spain. FAT* ’20: Conference on Fairness, Accountability, and Transparency, Barcelona Spain. 27 01 2020 30 01 2020. The Association for Computing Machinery, New York, New York, pp. 648–657.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk148",
      "text": "Black, C.J., Ford, A.C., 2020. Global burden of irritable bowel syndrome: trends, predictions and risk factors. Nature Reviews. Gastroenterology & Hepatology 17, 473–486.\n\nBrattoli, B., Büchler, U., Dorkenwald, M., Reiser, P., Filli, L., Helmchen, F., Wahl, A.-S., Ommer, B., 2021. Unsupervised behaviour analysis and magnification (uBAM) using deep learning. Nat Mach Intell 3, 495–506.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk149",
      "text": "Carabotti, M., Scirocco, A., Maselli, M.A., Severi, C., 2015. The gut-brain axis: interactions between enteric microbiota, central and enteric nervous systems. Annals of Gastroenterology : Quarterly Publication of the Hellenic Society of Gastroenterology 28, 203–209.\n\n5. Future directions and closing remarks",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk150",
      "text": "ML and AI have multiple inherent risks and fallacies; however, their success is undeniable, and for better or worse, their use in biomedical sciences is unstoppable at this point. The recent advancements in deep learning, as exemplified in the changes between GPT-3 and GPT-4 have been at an unforeseen pace, and teething problems aside, AIs will soon\n\noutperform humans in countless tasks.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk151",
      "text": "Caruana, R., Lou, Y., Gehrke, J., Koch, P., Sturm, M., Elhadad, N., 2015. Intelligible Models for HealthCare, in: Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. KDD ’15: The 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Sydney NSW Australia. 10 08 2015 13 08 2015. ACM, New York, NY, pp. 1721–1730.\n\nCastelvecchi, D., 2016. Can we open the black box of AI? Nature 538, 20–23.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk152",
      "text": "Chang, L.J., Gianaros, P.J., Manuck, S.B., Krishnan, A., Wager, T.D., 2015. A Sensitive and Specific Neural Signature for Picture-Induced Negative Affect. PLoS Biology 13, e1002180.\n\nConesa, A., Beck, S., 2019. Making multi-omics data accessible to researchers. Sci Data 6, 251.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk153",
      "text": "We would argue that as most AIs remain a black box, with decision making that can be influenced by human bias or unexpected elements of training data, their best use is for hypothesis generation, exploratory, and discovery research. Their use in medical decision making depends on the context and, in many circumstances can be problematic, while ethical issues are not resolved, and explainable AI has not moved for- ward significantly. Since currently, AIs remain black boxes, these should at most",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk154",
      "text": "be one of multiple indicators for human-centred decision",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk155",
      "text": "making.\n\nConnor, C.W., 2019. Artificial Intelligence and Machine Learning in Anesthesiology. Anesthesiology 131, 1346–1359.\n\nCortes, C., Vapnik, V., 1995. Support-vector networks. Mach Learn 20, 273–297. Cover, T., Hart, P., 1967. Nearest neighbor pattern classification. IEEE Trans. Inform. Theory 13, 21–27.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk156",
      "text": "de Vos, F., Koini, M., Schouten, T.M., Seiler, S., van der Grond, J., Lechner, A., Schmidt, R., de Rooij, M., Rombouts, S.A.R.B., 2018. A comprehensive analysis of resting state fMRI measures to classify individual patients with Alzheimer’s disease. NeuroImage 167, 62–72.\n\nDeuis, J.R., Dvorakova, L.S., Vetter, I., 2017. Methods Used to Evaluate Pain Behaviors in Rodents. Frontiers in Molecular Neuroscience 10, 284.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk157",
      "text": "Dill, K.A., Ozkan, S.B., Shell, M.S., Weikl, T.R., 2008. The protein folding problem. Annual Review of Biophysics 37, 289–316.\n\n477",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk158",
      "text": "Brain Behavior and Immunity 115 (2024) 470-479\n\nF. Badrulhisham et al.\n\nDunn, T.W., Marshall, J.D., Severson, K.S., Aldarondo, D.E., Hildebrand, D.G.C., Chettih, S.N., Wang, W.L., Gellis, A.J., Carlson, D.E., Aronov, D., Freiwald, W.A., ¨ Wang, F., Olveczky, B.P., 2021. Geometric deep learning enables 3D kinematic profiling across species and environments. Nature Methods 18, 564–573.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk159",
      "text": "Ester, M., Kriegel, H.P., Sander, J., Xu, X., 1996. A density-based algorithm for discovering clusters in large spatial databases with noise. Proceedings of 2nd International Conference on Knowledge Discovery and Data Mining (KDD), 226–231.\n\nKaur, H., Singh, Y., Singh, S., Singh, R.B., 2021. Gut microbiome-mediated epigenetic regulation of brain disorder and application of machine learning for multi-omics data analysis. Genome 64, 355–371.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk160",
      "text": "Ketkar, N., 2017. Deep Learning with Python: A Hands-on Introduction, 1st ed. Apress, Berkeley, CA, Online-Ressourcen.\n\nKincses, B., Forkmann, K., Schlitt, F., Pawlik, R., Schmidt, K., Timmann, D., Elsenbruch, S., Wiech, K., Bingel, U., Spisak, T., 2023. RCPL preprint: An externally validated resting-state brain connectivity signature of pain-related learning.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk161",
      "text": "Garrison, K.A., Sinha, R., Potenza, M.N., Gao, S., Liang, Q., Lacadie, C., Scheinost, D., 2023. Transdiagnostic Connectome-Based Prediction of Craving. The American Journal of Psychiatry appiajp21121207.\n\nKordi, M., Dehghan, M.J., Shayesteh, A.A., Azizi, A., 2022. The impact of artificial intelligence algorithms on management of patients with irritable bowel syndrome: A systematic review. Informatics in Medicine Unlocked 29, 100891.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk162",
      "text": "GEN242, 2022. Introduction. https://girke.bioinformatics.ucr.edu/GEN242/about/ introduction/. Accessed 17 March 2023.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk163",
      "text": "Gentleman, R.C., Carey, V.J., Bates, D.M., Bolstad, B., Dettling, M., Dudoit, S., Ellis, B., Gautier, L., Ge, Y., Gentry, J., Hornik, K., Hothorn, T., Huber, W., Iacus, S., Irizarry, R., Leisch, F., Li, C., Maechler, M., Rossini, A.J., Sawitzki, G., Smith, C., Smyth, G., Tierney, L., Yang, J.Y.H., Zhang, J., 2004. Bioconductor: open software development for computational biology and bioinformatics. Genome Biology 5, R80.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk164",
      "text": "Ghaffari, P., Shoaie, S., Nielsen, L.K., 2022. Irritable bowel syndrome and microbiome; Switching from conventional diagnosis and therapies to personalized interventions. J Transl Med 20, 173.\n\nKotikalapudi, R., Kincses, B., Zunhammer, M., Schlitt, F., Asan, L., Schmidt-Wilcke, T., Kincses, Z., Bingel, U., Spisak, T., 2023. Brain morphology predicts individual sensitivity to pain: a multi-center machine learning approach. Pain.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk165",
      "text": "Kriegeskorte, N., Douglas, P.K., 2018. Cognitive computational neuroscience. Nature Neuroscience 21, 1148–1160.\n\nLauer, J., Zhou, M., Ye, S., Menegas, W., Schneider, S., Nath, T., Rahman, M.M., Di Santo, V., Soberanes, D., Feng, G., Murthy, V.N., Lauder, G., Dulac, C., Mathis, M.W., Mathis, A., 2022. Multi-animal pose estimation, identification and tracking with DeepLabCut. Nature Methods 19, 496–504.\n\nLeCun, Y., Bengio, Y., Hinton, G., 2015. Deep learning. Nature 521, 436–444.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk166",
      "text": "Gl¨ascher, J., Daw, N., Dayan, P., O’Doherty, J.P., 2010. States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning. Neuron 66, 585–595.\n\nLiu, P., Jia, X.-Z., Chen, Y., Yu, Y., Zhang, K., Lin, Y.-J., Wang, B.-H., Peng, G.-P., 2021. Gut microbiota interacts with intrinsic brain activity of patients with amnestic mild cognitive impairment. CNS Neuroscience & Therapeutics 27, 163–173.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk167",
      "text": "Goldstein, A., Zada, Z., Buchnik, E., Schain, M., Price, A., Aubrey, B., Nastase, S.A., Feder, A., Emanuel, D., Cohen, A., Jansen, A., Gazula, H., Choe, G., Rao, A., Kim, C., Casto, C., Fanda, L., Doyle, W., Friedman, D., Dugan, P., Melloni, L., Reichart, R., Devore, S., Flinker, A., Hasenfratz, L., Levy, O., Hassidim, A., Brenner, M., Matias, Y., Norman, K.A., Devinsky, O., Hasson, U., 2022. Shared computational principles for language processing in humans and deep language models. Nature",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk168",
      "text": "Neuroscience 25, 369–380.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk169",
      "text": "Liu, X., Rivera, S.C., Moher, D., Calvert, M.J., Denniston, A.K., 2020. Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI Extension. BMJ (clinical Research Ed.) 370, m3164.\n\nL¨otsch, J., Ultsch, A., Mayer, B., Kringel, D., 2022. Artificial intelligence and machine learning in pain research: a data scientometric analysis. Pain Reports 7, e1044.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk170",
      "text": "Luger, G.F., 2004. Artificial intelligence: Structures and Strategies for Complex Problem Solving, 5th ed. Addison-Wesley, Harlow, p. 936.\n\nGrinsztajn, L., Oyallon, E., Varoquaux, G., 2022. Why do tree-based models still outperform deep learning on tabular data? https://arxiv.org/pdf/2207.08815.\n\nHamra, G., MacLehose, R., Richardson, D., 2013. Markov chain Monte Carlo: an introduction for epidemiologists. International Journal of Epidemiology 42, 627–634.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk171",
      "text": "Han, X., Ashar, Y.K., Kragel, P., Petre, B., Schelkun, V., Atlas, L.Y., Chang, L.J., Jepma, M., Koban, L., Losin, E.A.R., Roy, M., Woo, C.-W., Wager, T.D., 2022. Effect sizes and test-retest reliability of the fMRI-based neurologic pain signature. NeuroImage 247, 118844.\n\nHao, Y., Thomas, A.M., Li, N., 2021. Fully autonomous mouse behavioral and optogenetic experiments in home-cage. eLife 10.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk172",
      "text": "Hinton, G.E., Osindero, S., Teh, Y.-W., 2006. A fast learning algorithm for deep belief nets. Neural Computation 18, 1527–1554.\n\nHoffmann, S., Sch¨onbrodt, F., Elsas, R., Wilson, R., Strasser, U., Boulesteix, A.-L., 2021. The multiplicity of analysis strategies jeopardizes replicability: lessons learned across disciplines. Royal Society Open Science 8, 201925.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk173",
      "text": "MacQueen, J.B., 1967. Some Methods for Classification and Analysis of Multivariate Observations, in: Proc. of the fifth Berkeley Symposium on Mathematical Statistics and Probability. University of California Press, pp. 281–297.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk174",
      "text": "Mao, C.P., Chen, F.R., Huo, J.H., Zhang, L., Zhang, G.R., Zhang, B., Zhou, X.Q., 2020. Altered resting-state functional connectivity and effective connectivity of the habenula in irritable bowel syndrome: A cross-sectional and machine learning study. Human Brain Mapping 41, 3655–3666.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk175",
      "text": "Marek, S., Tervo-Clemmens, B., Calabro, F.J., Montez, D.F., Kay, B.P., Hatoum, A.S., Donohue, M.R., Foran, W., Miller, R.L., Hendrickson, T.J., Malone, S.M., Kandala, S., Feczko, E., Miranda-Dominguez, O., Graham, A.M., Earl, E.A., Perrone, A.J., Cordova, M., Doyle, O., Moore, L.A., Conan, G.M., Uriarte, J., Snider, K., Lynch, B.J., Wilgenbusch, J.C., Pengo, T., Tam, A., Chen, J., Newbold, D.J., Zheng, A., Seider, N. A., Van, A.N., Metoki, A., Chauvin, R.J., Laumann, T.O., Greene, D.J.,",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk176",
      "text": "Petersen, S.E., Garavan, H., Thompson, W.K., Nichols, T.E., Yeo, B.T.T., Barch, D.M., Luna, B., Fair, D.A., Dosenbach, N.U.F., 2022. Reproducible brain-wide association studies require thousands of individuals. Nature 603, 654–660.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk177",
      "text": "Hopfield, J.J., 1982. Neural networks and physical systems with emergent collective computational abilities. Proceedings of the National Academy of Sciences of the United States of America 79, 2554–2558.\n\nHorien, C., Floris, D.L., Greene, A.S., Noble, S., Rolison, M., Tejavibulya, L., O’Connor, D., McPartland, J.C., Scheinost, D., Chawarska, K., Lake, E.M.R., Constable, R.T., 2022. Functional Connectome-Based Predictive Modeling in Autism. Biological Psychiatry 92, 626–642.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk178",
      "text": "Hsu, A.I., Yttri, E.A., 2021. B-SOiD, an open-source unsupervised algorithm for identification and fast prediction of behaviors. Nature Communications 12, 5188.\n\nMartin, C.R., Osadchiy, V., Kalani, A., Mayer, E.A., 2018. The Brain-Gut-Microbiome Axis. Cellular and Molecular Gastroenterology and Hepatology 6, 133–148.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk179",
      "text": "Mathis, A., Mamidanna, P., Cury, K.M., Abe, T., Murthy, V.N., Mathis, M.W., Bethge, M., 2018. DeepLabCut: markerless pose estimation of user-defined body parts with deep learning. Nature Neuroscience 21, 1281–1289.\n\nMayer, E.A., Labus, J., Aziz, Q., Tracey, I., Kilpatrick, L., Elsenbruch, S., Schweinhardt, P., van Oudenhove, L., Borsook, D., 2019. Role of brain imaging in disorders of brain-gut interaction: a Rome Working Team Report. Gut 68, 1701–1715.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk180",
      "text": "Ito, T., Yang, G.R., Laurent, P., Schultz, D.H., Cole, M.W., 2022. Constructing neural network models from brain data reveals representational transformations linked to adaptive behavior. Nat Commun 13, 673.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk181",
      "text": "Jiang, Y., Wang, J., Zhou, E., Palaniyappan, L., Luo, C., Ji, G., Yang, J., Wang, Y., Zhang, Y., Huang, C.-C., Tsai, S.-J., Chang, X., Xie, C., Zhang, W., Lv, J., Chen, D.i., Shen, C., Wu, X., Zhang, B., Kuang, N., Sun, Y.-J., Kang, J., Zhang, J., Huang, H., He, H., Duan, M., Tang, Y., Zhang, T., Li, C., Yu, X., Si, T., Yue, W., Liu, Z., Cui, L.-B., Wang, K., Cheng, J., Lin, C.-P., Yao, D., Cheng, W., Feng, J., 2023. Neuroimaging biomarkers define neurophysiological subtypes with distinct",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk182",
      "text": "trajectories in",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk183",
      "text": "schizophrenia. Nat. Mental Health 1, 186–199.\n\nMcCulloch, W.S., Pitts, W., 1943. A logical calculus of the ideas immanent in nervous activity. Bulletin of Mathematical Biophysics 5, 115–133.\n\nMcInnes, L., Healy, J., Melville, J., 2018. UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. https://arxiv.org/pdf/1802.03426.\n\nMetz, R., 2022. No, Google’s AI is not sentient. CNN.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk184",
      "text": "Morais, L.H., Schreiber, H.L., Mazmanian, S.K., 2021. The gut microbiota-brain axis in behaviour and brain disorders. Nat Rev Microbiol 19, 241–255.\n\nNarla, A., Kuprel, B., Sarin, K., Novoa, R., Ko, J., 2018. Automated Classification of Skin Lesions: From Pixels to Practice. The Journal of Investigative Dermatology 138, 2108–2110.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk185",
      "text": "Jones, J.M., Foster, W., Twomey, C.R., Burdge, J., Ahmed, O.M., Pereira, T.D., Wojick, J. A., Corder, G., Plotkin, J.B., Abdus-Saboor, I., 2020. A machine-vision approach for automated pain measurement at millisecond timescales. eLife 9.\n\nNath, T., Mathis, A., Chen, A.C., Patel, A., Bethge, M., Mathis, M.W., 2019. Using DeepLabCut for 3D markerless pose estimation across species and behaviors. Nature Protocols 14, 2152–2176.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk186",
      "text": "Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O., Tunyasuvunakool, K., Bates, R., ˇZídek, A., Potapenko, A., Bridgland, A., Meyer, C., Kohl, S.A.A., Ballard, A.J., Cowie, A., Romera-Paredes, B., Nikolov, S., Jain, R., Adler, J., Back, T., Petersen, S., Reiman, D., Clancy, E., Zielinski, M., Steinegger, M., Pacholska, M., Berghammer, T., Bodenstein, S., Silver, D., Vinyals, O., Senior, A.W., Kavukcuoglu, K., Kohli, P., Hassabis, D., 2021. Highly accurate protein",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk187",
      "text": "structure",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk188",
      "text": "prediction with AlphaFold. Nature 596, 583–589.\n\nKabra, M., Robie, A.A., Rivera-Alba, M., Branson, S., Branson, K., 2013. JAABA: interactive machine learning for automatic annotation of animal behavior. Nature Methods 10, 64–67.\n\nNilsson, S.R.O., Goodwin, N.L., Choong, J.J., Hwang, S., Wright, H.R., Norville, Z.C., Tong, X., Lin, D., Bentzley, B.S., Eshel, N., McLaughlin, R.J., Golden, S.A., 2020. Simple Behavioral Analysis (SimBA) – an open source toolkit for computer",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk189",
      "text": "classification of complex social behaviors in experimental animals.\n\nNorgeot, B., Quer, G., Beaulieu-Jones, B.K., Torkamani, A., Dias, R., Gianfrancesco, M., Arnaout, R., Kohane, I.S., Saria, S., Topol, E., Obermeyer, Z., Yu, B., Butte, A.J., 2020. Minimum information about clinical artificial intelligence modeling: the MI- CLAIM checklist. Nature Medicine 26, 1320–1324.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk190",
      "text": "Obermeyer, Z., Powers, B., Vogeli, C., Mullainathan, S., 2019. Dissecting Racial Bias in an Algorithm Used to Manage the Health of Populations. Science 366, 447–453.\n\nKarakan, T., Gundogdu, A., Alag¨ozlü, H., Ekmen, N., Ozgul, S., Tunali, V., Hora, M., Beyazgul, D., Nalbantoglu, O.U., 2022. Artificial intelligence-based personalized diet: A pilot clinical study for irritable bowel syndrome. Gut Microbes 14, 2138672.\n\nOpenAI, 2023. GPT-4 Technical Report, 99 pp. https://arxiv.org/pdf/2303.08774.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk191",
      "text": "Pearson, K., 1901. LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of 2, 559–572.\n\nKarashchuk, P., Rupp, K.L., Dickinson, E.S., Walling-Bell, S., Sanders, E., Azim, E., Brunton, B.W., Tuthill, J.C., 2021. Anipose: A toolkit for robust markerless 3D pose\n\nestimation. Cell Reports 36, 109730.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk192",
      "text": "Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, ´E., 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research 12, 2825–2830.\n\n478",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk193",
      "text": "Brain Behavior and Immunity 115 (2024) 470-479\n\nF. Badrulhisham et al.\n\nPereira, T.D., Tabris, N., Matsliah, A., Turner, D.M., Li, J., Ravindranath, S., Papadoyannis, E.S., Normand, E., Deutsch, D.S., Wang, Z.Y., McKenzie-Smith, G.C., Mitelut, C.C., Castro, M.D., D’Uva, J., Kislin, M., Sanes, D.H., Kocher, S.D., Wang, S.- S.-H., Falkner, A.L., Shaevitz, J.W., Murthy, M., 2022. SLEAP: A deep learning system for multi-animal pose tracking. Nature Methods 19, 486–495.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk194",
      "text": "Peter, J., Fournier, C., Durdevic, M., Knoblich, L., Keip, B., Dejaco, C., Trauner, M., Moser, G., 2018. A Microbial Signature of Psychological Distress in Irritable Bowel Syndrome. Psychosomatic Medicine 80, 698–709.\n\nR Core Team, 2022. R: A Language and Environment for Statistical Computing. Austria, Vienna https://www.R-project.org/.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk195",
      "text": "Sripada, C., Rutherford, S., Angstadt, M., Thompson, W.K., Luciana, M., Weigard, A., Hyde, L.H., Heitzeg, M., 2020. Prediction of neurocognition in youth from resting state fMRI. Molecular Psychiatry 25, 3413–3421.\n\nStevens, B.R., Roesch, L., Thiago, P., Russell, J.T., Pepine, C.J., Holbert, R.C., Raizada, M. K., Triplett, E.W., 2021. Depression phenotype identified by using single nucleotide exact amplicon sequence variants of the human gut microbiome. Molecular Psychiatry 26, 4277–4287.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk196",
      "text": "Sui, J., Jiang, R., Bustillo, J., Calhoun, V., 2020. Neuroimaging-based Individualized Prediction of Cognition and Behavior for Mental Disorders and Health: Methods and Promises. Biological Psychiatry 88, 818–828.\n\nRabiner, L., Juang, B., 1986. An introduction to hidden Markov models. IEEE ASSP Mag. 3, 4–16.\n\nRamsundar, R.Z.B.B., 2018. TensorFlow for Deep Learning. O’Reilly Media Inc [Place of publication not identified], 1 online resource.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk197",
      "text": "Rieg, T., Frick, J., Baumgartl, H., Buettner, R., 2020. Demonstration of the potential of white-box machine learning approaches to gain insights from cardiovascular disease electrocardiograms. PloS One 15, e0243615.\n\nRivera, S.C., Liu, X., Chan, A.-W., Denniston, A.K., Calvert, M.J., 2020. Guidelines for clinical trial protocols for interventions involving artificial intelligence: the SPIRIT- AI Extension. BMJ (clinical Research Ed.) 370, m3210.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk198",
      "text": "Roose, K., 2023. Why a Conversation With Bing’s Chatbot Left Me Deeply Unsettled. The. New York times.\n\nTong, X., Xie, H., Carlisle, N., Fonzo, G.A., Oathes, D.J., Jiang, J., Zhang, Y., 2022. Transdiagnostic connectome signatures from resting-state fMRI predict individual- level intellectual capacity. Translational Psychiatry 12, 367.\n\nVaroquaux, G., Cheplygina, V., 2022. Machine learning for medical imaging: methodological failures and recommendations for the future. NPJ Digital Medicine 5, 48.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk199",
      "text": "Vasey, B., Nagendran, M., Campbell, B., Clifton, D.A., Collins, G.S., Denaxas, S., Denniston, A.K., Faes, L., Geerts, B., Ibrahim, M., Liu, X., Mateen, B.A., Mathur, P., McCradden, M.D., Morgan, L., Ordish, J., Rogers, C., Saria, S., Ting, D.S.W., Watkinson, P., Weber, W., Wheatstone, P., McCulloch, P., 2022. Reporting guideline for the early-stage clinical evaluation of decision support systems driven by artificial intelligence: DECIDE-AI. Nature Medicine 28, 924–933.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk200",
      "text": "Ruffle, J.K., Tinkler, L., Emmett, C., Ford, A.C., Nachev, P., Aziz, Q., Farmer, A.D., Yiannakou, Y., 2021. Constipation Predominant Irritable Bowel Syndrome and Functional Constipation Are Not Discrete Disorders: A Machine Learning Approach. The American Journal of Gastroenterology 116, 142–151.\n\nSadler, K.E., Mogil, J.S., Stucky, C.L., 2022. Innovations and advances in modelling and measuring pain in animals. Nat Rev Neurosci 23, 70–85.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk201",
      "text": "Saitou, N., Nei, M., 1987. The neighbor-joining method: a new method for reconstructing phylogenetic trees. Molecular Biology and Evolution 4, 406–425.\n\nVilone, G., Longo, L., 2021. Notions of explainability and evaluation approaches for explainable artificial intelligence. Information Fusion 76, 89–106.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk202",
      "text": "Vlasceanu, M., Amodio, D.M., 2022. Propagation of societal gender inequality by internet search algorithms. Proceedings of the National Academy of Sciences of the United States of America 119, e2204529119.\n\nWager, T.D., Atlas, L.Y., Lindquist, M.A., Roy, M., Woo, C.-W., Kross, E., 2013. An fMRI- based neurologic signature of physical pain. The New England Journal of Medicine 368, 1388–1397.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk203",
      "text": "Seeliger, K., Güçlü, U., Ambrogioni, L., Güçlütürk, Y., van Gerven, M.A.J., 2018. Generative adversarial networks for reconstructing natural images from brain activity. NeuroImage 181, 775–785.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk204",
      "text": "Segelcke, D., Linnemann, J., Pradier, B., Kronenberg, D., Stange, R., Richter, S.H., G¨orlich, D., Baldini, N., Di Pompo, G., Verri, W.A., Avnet, S., Pogatzki-Zahn, E.M., 2023. Behavioral Voluntary and Social Bioassays Enabling Identification of Complex and Sex-Dependent Pain-(-Related) Phenotypes in Rats with Bone Cancer. Cancers\n\n15.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk205",
      "text": "Shankar, S., Halpern, Y., Breck, E., Atwood, J., Wilson, J., Sculley, D., 2017. No Classification without Representation: Assessing Geodiversity Issues in Open Data Sets for the Developing World. https://arxiv.org/pdf/1711.08536.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk206",
      "text": "Sorge, R.E., Martin, L.J., Isbester, K.A., Sotocinal, S.G., Rosen, S., Tuttle, A.H., Wieskopf, J.S., Acland, E.L., Dokova, A., Kadoura, B., Leger, P., Mapplebeck, J.C.S., McPhail, M., Delaney, A., Wigerblad, G., Schumann, A.P., Quinn, T., Frasnelli, J., Svensson, C.I., Sternberg, W.F., Mogil, J.S., 2014. Olfactory exposure to males, including men, causes stress and related analgesia in rodents. Nature Methods 11, 629–632.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk207",
      "text": "Speer, S.P.H., Keysers, C., Barrios, J.C., Teurlings, C.J.S., Smidts, A., Boksem, M.A.S., Wager, T.D., Gazzola, V., 2023. A multivariate brain signature for reward. NeuroImage 271, 119990.\n\nSpisak, T., 2022. Statistical quantification of confounding bias in machine learning models. GigaScience 11.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk208",
      "text": "Spisak, T., Kincses, B., Schlitt, F., Zunhammer, M., Schmidt-Wilcke, T., Kincses, Z.T., Bingel, U., 2020. Pain-free resting-state functional brain connectivity predicts individual pain sensitivity. Nat Commun 11, 187.\n\nSpisak, T., Bingel, U., Wager, T.D., 2023. Multivariate BWAS can be replicable with moderate sample sizes. Nature 615, E4–E7.\n\nWard, J.H., 1963. Hierarchical Grouping to Optimize an Objective Function. Journal of the American Statistical Association 58, 236–244.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk209",
      "text": "Wiltschko, A.B., Johnson, M.J., Iurilli, G., Peterson, R.E., Katon, J.M., Pashkovski, S.L., Abraira, V.E., Adams, R.P., Datta, S.R., 2015. Mapping Sub-Second Structure in Mouse Behavior. Neuron 88, 1121–1135.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk210",
      "text": "Winkler, J.K., Fink, C., Toberer, F., Enk, A., Deinlein, T., Hofmann-Wellenhof, R., Thomas, L., Lallas, A., Blum, A., Stolz, W., Haenssle, H.A., 2019. Association Between Surgical Skin Markings in Dermoscopic Images and Diagnostic Performance of a Deep Learning Convolutional Neural Network for Melanoma Recognition. JAMA Dermatology 155, 1135–1141.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk211",
      "text": "Woo, C.-W., Chang, L.J., Lindquist, M.A., Wager, T.D., 2017. Building better biomarkers: brain models in translational neuroimaging. Nature Neuroscience 20, 365–377.\n\nWu, T., Wang, H., Lu, W., Zhai, Q., Zhang, Q., Yuan, W., Gu, Z., Zhao, J., Zhang, H., Chen, W., 2020. Potential of gut microbiome for detection of autism spectrum disorder. Microbial Pathogenesis 149, 104568.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk212",
      "text": "Zhou, F., Li, J., Zhao, W., Xu, L., Zheng, X., Fu, M., Yao, S., Kendrick, K.M., Wager, T.D., Becker, B., 2020. Empathic pain evoked by sensory and emotional-communicative cues share common and process-specific neural representations. eLife 9.\n\nZhou, F., Zhao, W., Qi, Z., Geng, Y., Yao, S., Kendrick, K.M., Wager, T.D., Becker, B., 2021. A distributed fMRI-based signature for the subjective experience of fear. Nat\n\nCommun 12, 6643.",
      "source": "p1.pdf"
    },
    {
      "id": "p1.pdf_chunk213",
      "text": "Zou, J., Schiebinger, L., 2018. AI can be sexist and racist - it’s time to make it fair. Nature 559, 324–326.\n\nZunhammer, M., Bingel, U., Wager, T.D., 2018. Placebo Effects on the Neurologic Pain Signature: A Meta-analysis of Individual Participant Functional Magnetic Resonance Imaging Data. JAMA Neurology 75, 1321–1330.\n\n479",
      "source": "p1.pdf"
    },
    {
      "id": "p2.pdf_chunk0",
      "text": "Neuroscience Research 215 (2025) 3-14\n\nELSEVIER\n\nContents lists available at ScienceDirect\n\nNeuroscience Research\n\njournal homepage: www.sciencedirect.com/journal/neuroscience-research\n\nReview article\n\nLarge-scale foundation models and generative AI for BigData neuroscience\n\n‘iss eck for",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk1",
      "text": "Ran Wang a, Zhe Sage Chen a,b,c,*\n\na Department of Psychiatry, New York University Grossman School of Medicine, New York, NY 10016, USA\n\nb Department of Neuroscience and Physiology, Neuroscience Institute, New York University Grossman School of Medicine, New York, NY 10016, USA\n\nc Department of Biomedical Engineering, New York University Tandon School of Engineering, Brooklyn, NY 11201, USA\n\nA R T I C L E I N F O\n\nA B S T R A C T",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk2",
      "text": "Keywords: Foundation model Generative AI BigData Transformer Self-supervised learning Transfer learning Representation learning Embedding Brain-machine interface",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk3",
      "text": "Recent advances in machine learning have led to revolutionary breakthroughs in computer games, image and natural language understanding, and scientific discovery. Foundation models and large-scale language models (LLMs) have recently achieved human-like intelligence thanks to BigData. With the help of self-supervised learning (SSL) and transfer learning, these models may potentially reshape the landscapes of neuroscience research and make a significant impact on the future. Here we present a",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk4",
      "text": "mini-review on recent advances in foundation models and generative AI models as well as their applications in neuroscience, including natural language and speech, semantic memory, brain-machine interfaces (BMIs), and data augmentation. We argue that this paradigm-shift framework will open new avenues for many neuroscience research directions and discuss the accompanying challenges and opportunities.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk5",
      "text": "1. Introduction\n\nand many findings derived from this line of research may have a\n\npotentially significant impact on neuroscience.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk6",
      "text": "Advances in neurotechnology have allowed us to record large-scale, high-throughput neural data through in vivo electrophysiology and brain imaging. These sources of BigData present a challenge for various neural data analyses such as decoding and functional connectivity analysis, as well as closed-loop brain-machine interface (BMI) applica- tions in neuroscience experiments (Chen and Pesaran, 2021. In parallel, machine learning research is also moving very fast. Several reviews on the interplay",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk7",
      "text": "between AI and neuroscience research have been pub- lished (Hassabis et al., 2017; Richards et al., 2019; Saxe et al., 2021; Macpherson et al., 2021. Rapid advances in deep learning and devel- opment of large-scale foundation models and large language models (LLMs) have taken the whole world by storm, demonstrating remarkable and revolutionary findings in generating high-resolution synthetic im- ages and yielding human-like natural language understanding (Zhao et al., 2023; Naveed et al., 2023;",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk8",
      "text": "Singhal et al., 2023. The past few years have witnessed a paradigm shift in AI to foundation models in nearly every aspect of machine learning applications. How will these techno- logical changes impact neuroscience and what are the implications for the field? Answering this question is part of our motivation to write this review. However, since the field is relatively new, the number of pub- lished studies on neuroscience applications based on foundation models",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk9",
      "text": "or LLMs is relatively small. Nevertheless, the interest is rapidly growing",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk10",
      "text": "In this mini-review, we first provide a brief overview of foundation models and their building block—transformers, then extend our over- view to a broad class of generative AI tools. Next, we review important concepts in representation learning, self-supervised learning (SSL) and transfer learning, which will play important roles in cross-modality applications. Further, we review recent applications of foundation models and generative AI in various neuroscience research areas, including but not",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk11",
      "text": "limited to large-scale brain imaging data analysis, natural speech and language understanding, memory, emotion, mental state decoding, behavior, BMI, and data augmentation. Finally, we conclude the review with discussions and outlook on future research",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk12",
      "text": "opportunities and challenges.\n\n2. Foundation models and generative AI\n\n2.1. What are foundation models?\n\nFoundation models have become a new paradigm for building AI systems, in which models trained on a large amount of unlabeled data can be adapted to many other applications. The foundation models are often trained using self-supervision with BigData, and can be adapted to a wide range of tasks (e.g., text, images, speech, structured data, brain",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk13",
      "text": "* Corresponding author at: Department of Psychiatry, New York University Grossman School of Medicine, New York, NY 10016, USA.\n\nE-mail address: zhe.chen@nyulangone.org (Z.S. Chen).",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk14",
      "text": "https://doi.org/10.1016/j.neures.2024.06.003\n\nReceived 9 June 2024; Accepted 9 June 2024\n\nReceived 9 June 2024; Accepted 9 June 2024\n\nAvailable online 17 June 2024\n\n0168-0102/© 2024 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\n\nNeuroscience Research 215 (2025) 3-14\n\nR. Wang and Z.S. Chen",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk15",
      "text": "signals, and high-dimensional tensor data) (Fig. 1). One of the popular class foundation models is LLMs (Table 1), which take language input and generate synthesized output. In general, foundation models work with multi-modal data types.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk16",
      "text": "In a recent group study conducted at Stanford University, it was concluded that “foundation models are scientifically interesting due to their impressive performance and capabilities, but what makes them critical to study is the fact that they are quickly being integrated into real-world de- ployments of AI systems with far-reaching consequences on people” (Bom-\n\nmasani et al., 2021.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk17",
      "text": "At the very high level, there are two fundamental ideas in the LLM and foundation models: (i) embedding, which aims to convert words or tokens into high-dimensional statistically meaningful numbers; (ii) SSL\n\nor contrastive learning.\n\nTable 1\n\nA\n\nA selective list of foundation models and LLMs.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk18",
      "text": "Model Characterization Developer BERT CLIP Codex generative language model language-image pre-training general-purpose programming model Google Open AI Open AI DALE-E, DALL- text-to-image models Open AI E2 GPT-3 GPT-4 SORA causal sequence model for NLP multi-modal model text-to-video model Open AI Open AI Open AI PaLM, PaLM2 multi-lingual pathways language models Google LLaMA, LLaMA2 foundational language model, code generation Meta SEER GATO model self-supervised computer vision model",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk19",
      "text": "multi-modal, multi-task, multi-embodiment Meta DeepMind policy DINOv2 foundational models for vision Meta",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk20",
      "text": "2.1.1. Embedding",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk21",
      "text": "Embedding is a feature extraction technique that nonlinearly trans- forms the input signal to a representational vector, which enable users to easily index, search, compute, and visualize. In language processing applications, a word embedding is the projection of words onto a meaningful space in which words that “are nearby in meaning” appear nearby in the embedding. Take ChatGPT as an example, the dimen- sionality of the embedding space can be high-dimensional (hundreds to thousands depending",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk22",
      "text": "on the specific layer). Therefore, the embedding vectors that contain a string of numbers are located in the coordinates of “linguistic feature space” (Wolfram, 2023). In deep neural networks, embedding layers enable us to learn the relationship between high-dimensional inputs and outputs more efficiently.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk23",
      "text": "2.1.2. SSL learning",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk24",
      "text": "In real life, humans and animals can learn efficiently from observa- tion or very few labeled examples, pointing to the limitation of BigData- based supervised learning. SSL is predictive learning in that it aims to predict missing parts of the input. In recent years, SSL techniques have achieved immense successes in natural language processing (NLP) and computer vision by enabling models to learn from BigData at unprece- dented scales (Millet et al., 2023; Balestriero et al., 2023. Depending on",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk25",
      "text": "the objective, SSL can be a generative, contrastive, or generative-contrastive (adversarial) form; a comprehensive survey of SSL is referred to elsewhere (Liu et al., 2023. Under the SSL framework, fine-tuning the pre-trained models with a small percentage of labeled data can achieve comparable results with the supervised training (Eldele et al., 2023. In NLP, pre-training methods like BERT (Bidirectional Encoder Representations from Transformers) have shown strong per- formance gains using SSL",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk26",
      "text": "that masks individual words or subword units (Devlin et al., 2019. Recently, Joshi et al. (2020) proposed an extended version of BERT known as SpanBERT, which can mask contiguous random spans instead of random tokens and train the span boundary representations to better predict the entire content of the masked span; by so doing, SpanBERT consistently outperforms BERT, with the largest",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk27",
      "text": "gains on span selection tasks.\n\n2.2. Transformer model",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk28",
      "text": "A transformer model is a deep neural network that learns context and thus meaning by tracking relationships in sequential data. Specifically, transformers were developed to solve the problem of sequence trans- duction that transforms an input sequence to an output sequence, enabling end-to-end learning in machine translation, text generation and sentiment analysis (Vaswani et al., 2017. Transformers are the building blocks in many foundation models, such as BERT and GPT (Generative Pre-trained",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk29",
      "text": "Transformer). Transformers are computation- ally efficient in simultaneous sequence processing since model training can be sped up through parallelization, a key feature missing in recur- rent neural networks (RNNs) and long short-term memory (LSTM). This feature has also made the creation of LLMs feasible.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk30",
      "text": "The transformer model has a seq2seq neural network architecture, consisting of encoding, decoding and self-attention modules (Fig. 2a). There are several concepts fundamental to computations in the\n\ntransformer:\n\n• word embeddings: computing vector representations of words.\n\n• positional embeddings: encoding the position of each token in a sequence and adding the positional information to the word\n\nembeddings",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk31",
      "text": "• attention: understanding the context of a word by considering the words that come before or after it. In other words, if the meaning is a result of the relationship between words, then self-attention is a general way of learning the meaning underlying a sentence (Vaswani\n\net al., 2017.\n\n• self-attention: weighing the importance of different parts of the input sequence against each other.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk32",
      "text": "Uni- or multi-modal data Foundation model Text Images Video Structured data Music Speech Brain signals Pre-training: Self-supervised learning, Contrastive learning a Embedding Tasks Question answering Image/video generation Image captioning Object recognition Speech generation Sentiment analysis Adaptation: fine-tuning, transfer learning",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk33",
      "text": "Fig. 1. A schematic diagram of foundation models. Unlike traditional machine learning models are designed for a specific task, foundation models are trained on a\n\nwide range of unlabeled data and can also perform other tasks.\n\nNeuroscience Research 215 (2025) 3-14\n\nR. Wang and Z.S. Chen",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk34",
      "text": "a Output Probabilities Multi-Head Attention —t. Tinear Linear) v K Q Nx Scaled Dot-Product Attention Positional Encoding CY Positional 4 Encoding © Output Embedding Input Embedding Inputs Outputs (shifted right) Latent Space Encoder Training set Discriminator Latent space Real sample v (@.g., uniform) a 4 es oe. Fake Generator - A L So >> econ > -. 4 «> F Noise vector a Fake sample forward process d q(+|X+-1) OQ. -O@. & aa reverse process (r) Sonne Reconst. p(x|Z0) Decoder q(Xt|Xt-1) p(Zo)",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk35",
      "text": "q(Zo|x) ze KL(q(Zo|x)||p(Zo)) Latent —__Latent Space Diffusion Diffusion Latent \"Tatent Space Dencising Denoising",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk36",
      "text": "Fig. 2. Schematics of several generative AI models: (a) the Transformer architecture, (b) VAE, (c) GAN, (d) diffusion model. (e) LSGM. The multi-head attention in the decoder implements several masked, single-attention functions, where [Q, K, V] represent three embedding vectors for queries, keys, and values, respectively. To minimize the reconstruction error characterized by the distribution p(x∣z0), the encoder and decoder are trained to minimize the KL divergence between a proposal",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk37",
      "text": "distribution q(z0∣x) and the distribution p(z0).",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk38",
      "text": "(a) Panel a is adapted with permission from (Vaswani et al., 2017, where the architecture follows an encoder-decoder structure without the use of convolution and recurrence. (b) Panel c is adapted with permission from (Goetschalckx et al., 2021, Elsevier, where the GAN was used to generate synthetic images by simultaneously training a discriminator and generator. (c) Panel e is adapted with permission from (Vahdat et al., 2021, where Zo and z, represent two latent variables following a",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk39",
      "text": "diffusion-based stochastic differential equation (SDE). (d) Panel d is adapted with permission from (Ho et al., 2020, in which the forward process is sampled from a Markov chain characterized by the transition distribution q(x;|x;1), and the reverse process is sampled from a parameterized distribution po(x;_1|x).",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk40",
      "text": "• multi-head attention: allowing the network to learn multiple ways of\n\nweighing the input sequence against itself.\n\n2.3. Generative AI\n\n2.3. Generative AI\n\nIn addition to NLP applications, the transformer architecture has been applied in other domains such as computer vision (Dosovitskiy et al., 2020, visual stimulus classification (Bagchi and Bathula, 2022, neural data analysis (Ye and Pandarinath, 2021, and reinforcement learning (RL) (Li et al., 2023a.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk41",
      "text": "Generative AI describes a class of algorithms that can be used to create new content, including audio, code, images, text, simulations, and videos. Several representative generative AI algorithms are sum-\n\nmarized below.\n\n• Variational Autoencoder (VAE): VAE is a generative AI algorithm that uses deep learning to generate new content, detect anomalies and remove noise (Kingma and Welling, 2013. VAE consists of an\n\nencoder and a decoder, separated by the latent space (Fig. 2b). The",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk42",
      "text": "R. Wang and Z.S. Chen\n\nNeuroscience Research 215 (2025) 3-14\n\nR. Wang and Z.S. Chen\n\nlatent space contains an abstract representation of the data con- taining only the most meaningful information (i.e., dimensionality reduction). The model can learn the data distribution, so that a corresponding output can be reconstructed based on a new sample\n\ninput.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk43",
      "text": "• Generative Adversarial Network (GAN): A GAN is a class of deep learning framework that uses two neural networks, the generator and the discriminator (Fig. 2c), to generate new and realistic synthetic data that are similar to the samples among the training set. Specif- ically, the generator network takes random noise as input and gen- erates synthetic data, and aims to produce data that are indistinguishable from the real data in the training set. The generator tries to create realistic samples",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk44",
      "text": "and follow the patterns present in the original dataset. On the other hand, the discriminator network evaluates the data it receives and tries to distinguish between real data from the training set and the synthetic data produced by the generator. Its goal is to correctly classify whether the input data is real or generated by the generator. The discriminator provides feedback to the generator, helping it improve its generated samples. To date, the GAN and many of its variants have numerous",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk45",
      "text": "applica- tions in image generation, image-to-image translation, super- resolution imaging, text-to-image synthesis, and video generation (Goodfellow et al., 2014; Gui et al., 2020; Goetschalckx et al., 2021.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk46",
      "text": "describe complicated scenes, but also can synthesize new images or samples, which represents a critical step towards artificial general in-\n\ntelligence (AGI).",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk47",
      "text": "Furthermore, foundation models may provide a starting point for developing more advanced generative AI systems. Researchers and de- velopers often fine-tune or extend the foundation models to create specialized generative models tailored to specific tasks or domains. More importantly, foundation models may facilitate transfer learning, which is vital for generative AI as it allows models to leverage the knowledge and representations learned by foundation models to generate diverse and",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk48",
      "text": "contextually appropriate content across different domains. One exciting application of generative AI is to decode brain signals and transform them into text or images, which may have a clinical impact on the lives of individuals with traumatic brain injury (TBI) or severe pa- ralysis who cannot communicate through speech, typing, or gestures (Metzger et al., 2023,2022; D´efossez et al., 2023; VanRullen and Reddy, 2019; Tang et al., 2023. Recently, GAN-based (Dado et al., 2022 and diffusion",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk49",
      "text": "model-based (Takagi and Nishimoto, 2023 approaches have been developed to reconstruct human faces or visual images from fMRI recordings. See (Gong et al., 2023 for a short review on generative AI for brain imaging applications.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk50",
      "text": "3. Representation learning and transfer learning",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk51",
      "text": "• Generative Pre-trained Transformer (GPT): GPT is specifically referred to as a series of language models that use the transformer architecture to understand and generate coherent and contextually relevant text. Because of powerful predictive ability, GPT is effective for a variety of NLP tasks, including text generation, translation, and summarization. The basic idea behind GPT is to apply SSL and train the large-scale model based on big datasets containing a diverse range of text from various",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk52",
      "text": "sources. Upon the completion of learning, the model takes the sequence of tokens that corresponds to the text in the past and finds an embedding that represents them, and further generates a large number of values that turn into probabilities for predicting possible next tokens (Wolfram, 2023. The newer GPT developments, such as GPT-3 (Brown et al.), GPT-4, and SORA, represent a landmark in this line of technology due to their impres- sive generative power and being trained on increasingly",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk53",
      "text": "complex",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk54",
      "text": "large-scale models.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk55",
      "text": "• Diffusion Model: Diffusion models refer to a class of latent generative models that are used to model the distribution of data based on Markov chains and variational inference (Fig. 2d) (Ho et al., 2020; Rombach et al., 2022. These models are designed to capture the underlying data distribution by iteratively transforming a simple distribution into a complex one. Diffusion models offer a promising avenue for deep generative modeling owing to robust expressive capacity, and ability to generate",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk56",
      "text": "data via ancestral sampling without the prerequisite of a posterior distribution. Unlike other deep generative models such as VAE and GAN, training diffusion models is relatively simple. To date, diffusion models have been used in image",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk57",
      "text": "generation, NLP, and time series analysis.\n\n• Latent Score-based Generative Model (LSGM): The LSGM generalizes the ideas of VAE and the diffusion model, maps the input onto a latent space and applies the diffusion model in the latent embeddings of the data (Fig. 2e) (Vahdat et al., 2021. As an extension of score-based generative models (Song and Ermon, 2019; Song et al., 2021, the LSGM has several key computational advantages: synthesis speed, expressivity, and tailored encoders and decoders.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk58",
      "text": "3.1. Representation learning",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk59",
      "text": "Representation Learning refers to a class of machine learning algo- rithms that extract meaningful patterns from raw data to create repre- sentations easily understood or processed (Bengio et al., 2014. During this process, dimensionality reduction, regularization, invariance, and sparsity play important roles. Current LLMs heavily rely on effective representation learning algorithms. Representation learning can be achieved by unsupervised, supervised, and self-supervised frameworks. For",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk60",
      "text": "instance, as a special case of SSL paradigm, contrastive learning can learn an embedding space such that similar instances have close repre- sentations while dissimilar instances stay far apart from each other. In addition to computer vision and NLP tasks, contrastive learning has been used to extract meaningful representations from neural data, including data from electroencephalography (EEG), magnetoencephalography (MEG), functional magnetic resonance imaging (fMRI), and other neuroscience",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk61",
      "text": "modalities (Kostas et al., 2021. For instance, contrastive learning has enabled researchers to uncover patterns in brain connec- tivity data, providing insight into the organization and communication between different brain regions, and identifying connectivity-based biomarkers between healthy and pathological brains (Tong et al., 2021. Contrastive learning can also learn representations in the latent feature space based on dimensionality reduction. One such an example is contrastive PCA (cPCA),",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk62",
      "text": "which can identify the dominant subspace that distinguishes two datasets collected from different conditions (Abid et al., 2018. Additionally, contrastive variational autoencoder (cVAE) (Aglinskas et al., 2022, as an extension of cPCA, offers a more flexible approach capable of modeling nonlinear relationships between the in- puts and latent features. Finally, another contrastive learning paradigm, contrastive predictive coding (CPC) (van den Oord et al., 2019, learns self-supervised",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk63",
      "text": "representations by predicting the future in latent space by using autoregressive models and VAE; the model uses a probabilistic contrastive loss, which induces the latent space to capture information that is maximally useful to predict future data.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk64",
      "text": "Foundation models can serve as a basis for generative AI. BERT and GPT models have already been used as the building blocks for devel- oping more sophisticated generative AI models. For instance, Fei et al. (2022) developed a self-supervised pre-trained foundation model on vision-language multi-modal input, which only requires weak semantic correlated image-text training pairs; specifically, they demonstrated that\n\nthe foundation model not only can generate high-level concepts and",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk65",
      "text": "3.2. Transfer learning\n\nTransfer learning represents a class of machine learning technique where knowledge learned from a task is reused in order to boost per- formance on a related task or generalize out-of-distribution via targeted re-training (Pan and Yang, 2010. In deep learning models, transfer learning has been widely used in computer vision, image classification,\n\nNeuroscience Research 215 (2025) 3-14\n\nR. Wang and Z.S. Chen\n\nand NLP tasks (Yosinski et al., 2014; Goodfellow et al., 2016.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk66",
      "text": "Transfer learning has found many applications in neuroscience. In neuroimaging data analysis, pre-trained models from NLP or computer vision domains, can be fine-tuned or used to extract features from raw neural data, facilitating out-of-domain tasks such as classification, seg- mentation, and decoding of neural activity. For instance, pre-trained models from related medical imaging tasks can be adapted to process and interpret neuroimaging data, leading to a more accurate and effi- cient",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk67",
      "text": "analysis. Additionally, since the relationship between cognitive tasks is usually represented by similarity of neural representations or activated brain regions, transfer learning may perform better in task decoding with fMRI data if the source and the target cognitive tasks activate similar brain regions (Qu et al., 2022).",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk68",
      "text": "In BMI research, transfer learning can improve the performance and adaptability of BMI systems by leveraging knowledge from related tasks. Pre-trained models may help enhance the decoding of neural signals for controlling external devices or for interpreting brain activity associated with specific motor or cognitive tasks.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk69",
      "text": "Transfer learning can assist in the early detection and diagnosis of neurological or psychiatric disorders by leveraging knowledge from related medical domains. Pre-trained models from medical imaging or clinical data analysis can be adapted to identify biomarkers associated with specific pathological conditions, aiding in early intervention and personalized treatment strategies. Notably, transfer learning can work well where the data sample size is small in neuroimaging-based pre- diction",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk70",
      "text": "(Ardalan and Subbian, 2022; Malik and Bzdok, 2022 and ECo- G/EEG decoding analysis (Zhang et al., 2021; Peterson et al., 2021.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk71",
      "text": "4. Foundation models and generative AI for neuroscience applications\n\n4.1. Context-dependent embedding mapping",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk72",
      "text": "As discussed earlier, representation learning can identify context- dependent embeddings for a broad class of input signals. For instance, if the input is a speech signal, the embedding mapping for speech rep- resentation may be produced by “wave2vec” (Schneider et al., 2019; Baevski et al., 2020; Millet et al., 2023, HuBERT (Hsu et al., 2021, and “data2vec” (Baevski et al., 2022,2023. If the input is a neural time series such as an EEG signal, the embedding mapping for EEG may include “EEG2vec”",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk73",
      "text": "(Zhu et al., 2023 or other representation learning methods (Kostas et al., 2021; Rafiei et al., 2022; Wagh et al., 2021. Such methods have been demonstrated in neuroscience applications such as automatic sleep staging (Banville et al., 2020; Yang et al., 2023 and seizure",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk74",
      "text": "detection (Tang et al., 2022.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk75",
      "text": "In neural data analysis, embeddings have been widely adopted in unsupervised or supervised representation learning. For instance, automated neuron reconstruction and annotation of volume electron microscopy (VEM) datasets of three-dimensional images of brain tissue are computationally intensive and challenging. Schubert et al. (2019) first used unsupervised training to infer morphology embeddings (“neuron2vec”) of neuron reconstructions, and then trained cellular morphology neural networks",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk76",
      "text": "(CMNs) to identify glia cells via supervised classification; they also demonstrated how CMNs can be used to identify subcellular compartments and the cell types of neuron reconstructions.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk77",
      "text": "Embeddings are useful for revealing low-dimensional neural dy- namics and modeling naturalistic behaviors (Wang and Guet, 2022; Schneider et al., 2023. Although traditional latent variable models have been used for analyzing neural and behavioral data (Chen, 2015; Lat- imer et al., 2015; Calhoun et al., 2019; Bolkan et al., 2022; Ashwood et al., 2022; Lakshminarasimhan et al., 2023, most of them are limited in encoding the context dependence. Incorporating task-relevant embed- ding vectors to",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk78",
      "text": "form a context-relevant embedding would allow us to perform end-to-end learning efficiently. Recently, Ye and Pandarinath (2021) have proposed a non-recurrent, BERT encoder-based neural data",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk79",
      "text": "transformer (NDT) model to explicitly model autonomous neural\n\npopulation activity and reported comparable performance between the NDT model and other RNN models. In their NDT model, inputs to transformer layers were first normalized and enriched through contex- tual information (“self-attention” blocks), and passed through a feed- forward module.\n\n4.2. Brain imaging",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk80",
      "text": "Human neuroimaging provides a window to examine healthy and diseased brains, in terms of both structural and functional forms, including EEG, MEG, fMRI, diffusion tensor imaging (DTI), and positron emission tomography (PET). See (Gong et al., 2023 for a review of generative AI for brain imaging, covering co-registration, super-- resolution, enhancement, classification, segmentation, cross-modality, brain network analysis, and decoding analysis.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk81",
      "text": "Several lines of work have proposed generative AI approaches to reconstruct visual images based on fMRI data (Seeliger et al., 2018; VanRullen and Reddy, 2019; Ferrante et al., 2023a. For instance, Van- Rullen and Reddy (2019) first trained a VAE network using a GAN un- supervised procedure over a large dataset of celebrity faces, where the VAE latent space provided a topologically organized 1024-dimensional embedding of each image. Next, they presented thousands of face im- ages to human",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk82",
      "text": "subjects and learned a linear mapping between multi-voxel fMRI activation patterns and latent embeddings. Finally, they applied this mapping to novel face images, translating fMRI pat- terns into reconstructed faces.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk83",
      "text": "Lu et al. (2022) developed a self-supervised pre-trained image-text multi-modal foundation model which outperformed CLIP (Contrastive Language-Image Pre-Training) model even with a small percentage ( ~ 3.75 %) of training pairs. The image and text were first encoded indi- vidually by pre-trained uni-modal large-scale models, vision transformer (ViT) and BERT. The output of BERT was then projected to a trained mapping layer that aligns with ViT features. By comparing the encoded image encoding",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk84",
      "text": "feature with fMRI imaging of the human visual cortex, their results showed that the proposed multi-modal model has higher",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk85",
      "text": "prediction accuracy than the uni-modal image encoder.\n\n4.3. Natural language and speech\n\nSpeech and language understanding involves a deep comprehension of their generation and processing (in both sound and text), enabling computers to perform tasks such as speech recognition, language\n\ntranslation, sentiment analysis, and text summarization.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk86",
      "text": "Representing human speech from brain signals (such as ECoG and fMRI) may include decoding neural activity associated with speech production, perception, or comprehension. It has been known that natural speech reveals a semantic map that tiles the human cerebral cortex (Huth et al., 2016a, and the semantic space is continuously distributed across the brain describing representations of thousands of\n\nobject and action categories (Huth et al., 2012,2016b.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk87",
      "text": "On the one hand, the rich features extracted from the foundation models provide a new hypothesis when studying brain representations during specific speech and language tasks. For example, the ECoG ac- tivity in the superior temporal gyrus (STG) and inferior frontal gyrus (IFG) of the human brain was found to be correlated with features extracted by the GPT model (Goldstein et al., 2022). Since predictive pre-training of the GPT model was capable of encoding contextual in- formation, word onset,",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk88",
      "text": "and word surprisal, this finding suggests that the human auditory cortex may encode speech in a similar manner. The contextual encoding phenomenon was also found when correlating neural representations in the human auditory cortex with the HuBERT",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk89",
      "text": "model’s embeddings (Li et al., 2023b).\n\nOn the other hand, a growing number of studies have focused on decoding human speech from invasive brain recordings, using either intracranial ECoG or intracortical spiking activity (Metzger et al., 2022;\n\nMoses et al., 2021; Willett et al., 2023) (see the review of BMI\n\nNeuroscience Research 215 (2025) 3-14\n\nR. Wang and Z.S. Chen",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk90",
      "text": "applications below). Recently, D´efossez et al. (2023) have developed a contrastive learning approach to decode speech based on non-invasive magneto- or electro-encephalography (MEG/EEG). They first employed a large-scale pre-trained speech encoding model (“wave2vec 2.0” (Baevski et al., 2020) to extract semantic features from speech, and then trained a decoding model to extract features that converged to the speech features of the corresponding trail while diverging from speech features of",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk91",
      "text": "other trails. The model was capable of identifying the speech segment with features that best matched the decoded neural features. This work represents a large step forward in clinical practice without putting patients at the risk of brain surgery.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk92",
      "text": "Furthermore, EEG signals can be leveraged to augment multi-modal NLP models while using less training data (Hollenstein et al., 2021; in combination with EEG data, BERT embeddings have shown consistently improved performance for NLP tasks.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk93",
      "text": "emotion decoding: the generative component is a multi-view VAE that learns the brain activity of left and right hemispheres, as well as their differences, and the discriminative component is a multi-label classifi- cation network. Furthermore, they used a label-aware module for emotion-specific neural representation learning and modeled the de- pendency of emotional states by a masked self-attention mechanisms.\n\n4.6. Naturalistic behavior",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk94",
      "text": "An important goal in neuroscience is to uncover the circuit mecha- nisms underlying cognitive processes and behavior, for which quanti- tative behavioral descriptions may play a vital role in linking brain activity and behavior (Krakauer et al., 2017; Pereira et al., 2020). Unlike constrained behaviors (such as head-fixed tasks or planar reach-and-grasp movement), naturalistic behavior refers to the behavior that animals have a tendency to exhibit under natural or realistic con- ditions, which",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk95",
      "text": "is often beneficial to biological functioning.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk96",
      "text": "4.4. Memory and semantic reconstruction\n\nIn the traditional episodic memory paradigm, subjects are usually required to memorize arbitrary items (words or images), lacking the fundamental components in real-life naturalistic events occurring over a longer timescale. Multimedia stimuli such as music and film, however, may provide rich contextual and naturalistic memory behaviors\n\n(Groussard et al., 2009).",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk97",
      "text": "In neuroscience experiments, recollection of short audiovisual seg- ments from movies can be viewed as a proxy to real-life memory that consists of a stream of continuous sensory experiences. In contrast to pure reconstruction of static images from brain imaging (Shen et al., 2019; Horikawa et al., 2013), reconstructing high-quality images with correct semantics from brain recordings is more challenging due to the complex underlying representations of brain signals and the scarcity of data",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk98",
      "text": "annotations. In the literature, neural decoders have been developed for semantic reconstruction of movie or visual experiences (Huth et al., 2016b; Nishimoto et al., 2011). Extension of this framework using generative AI would represent a promising research direction.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk99",
      "text": "Recently, Chen et al. (2023) proposed a conditional diffusion model with sparse masked modeling for human visual decoding. Inspired by sparse coding in the primary visual cortex, they first applied SSL and mask modeling in a large latent space for fMRI data; then they augmented a latent diffusion model (LDM) to reconstruct highly plau- sible images with semantically matching details from fMRI recordings using very few paired annotations.\n\n4.5. Mental state and emotion",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk100",
      "text": "Decoding brain states and mental processes based on brain imaging data has been an active research area (Poldrack et al., 2012; Rubin et al., 2017). However, the common challenge is that sample sizes are rela- tively small and models are prone to overfitting. Recently, to decode mental states, Thomas et al. (2022) proposed to leverage publicly shared fMRI data (https://openneuro.org/) to pretrain a foundation model. Their procedure consisted of two steps. In the first step, they performed",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk101",
      "text": "self-supervised learning on fMRI time series using various model stra- tegies: seq-to-seq autoencoder, casual sequence modeling (similar to GPT-3), sequence-BERT, and network-BERT. In the second step, they applied a plug-in and adaptation to decoding mental states. In so doing, the mental states can be viewed as a high-dimensional neural embed- ding, and NLP-inspired architectures were able to learn useful repre- sentations of fMRI time series; more importantly, the pre-trained model also",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk102",
      "text": "improved the decoding accuracy of mental states (compared to several baseline models).",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk103",
      "text": "Decoding emotions from brain activity is one fundamental task in human-computer interaction, yet most decoding methods are limited by the number of emotion categories or have ignored the discrepancy of emotion expression between two brain hemispheres. Recently, Fu et al.\n\n(2022) proposed a multi-view multi-label hybrid model for fine-grained",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk104",
      "text": "Given the success of sequence modeling in NLP, it is tempting to frame behavior analysis as a sequence modeling problem and apply this idea to context-relevant behavioral embedding and attention computa- tion. Recently, Reed et al. (2022) have proposed a generalist agent (GATO) model for multi-modal, multi-task learning. Specifically, they encoded various modalities into a single vector space of “tokens” that can be ingested by a large sequence model such as transformers; they also proposed",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk105",
      "text": "various “tokenization” approaches to capture the large amount of multi-modal data that include standard vision and language",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk106",
      "text": "datasets and some RL benchmarks.\n\n4.7. Brain-machine interfaces",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk107",
      "text": "A BMI is a system that establishes a direct communication pathway between the brain’s electrical activity and an external device, reading out the encoded stimuli (e.g., speech, vision, location) or translating thought into action (i.e., neuroprosthetics) (Gilja et al., 2012; Lebedev and Nicolelis, 2017; Willett et al., 2021). Such mind-reading devices can be used not only for clinical applications (Shanechi, 2019; Moses et al., 2021; Zhang et al., 2023; Sun et al., 2022, but also for scientific",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk108",
      "text": "inquiry",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk109",
      "text": "in basic science questions (Sadtler et al., 2014.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk110",
      "text": "Data sources in different BMIs have a varying degree of signal-to- noise ratio (SNR). For instance, while sharing the same temporal reso- lution, ECoG has a higher SNR than the scalp EEG. On the other hand, calcium imaging or fMRI data have a much lower temporal resolution than ECoG or EEG. Because of this variability, directly mapping neural signals onto decoding targets (e.g., text, speech, and music) is not optimal. Pre-trained foundation models can mitigate this by incorpo- rating prior",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk111",
      "text": "knowledge about the decoding targets, aligning them more",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk112",
      "text": "closely with the neural signals.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk113",
      "text": "To date, LLMs have been incorporated into BMI systems to enhance text decoding. A wide range of machine learning techniques have been employed to increase the efficiency and accuracy of EEG-based spelling systems (Speier et al., 2016. In practice, these language models can either auto-complete decoded words or be integrated into classifiers to refine the probability estimates of potential letters based on previously decoded ones. Leveraging language models has proven to significantly reduce",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk114",
      "text": "word-error-rates, especially when decoding text from intracra- nial ECoG or Utah array during speech attempts (Moses et al., 2021; Metzger et al., 2022,2023; Willett et al., 2021,2023. A notable recent study (Tang et al., 2023 utilized a pre-trained GPT-2 model to interpret perceived speech from fMRI scans, converting neural patterns into text. This research, which involved over 16 h of fMRI data from participants listening to stories, has showcased the potential of BMI in decoding imagined",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk115",
      "text": "speech and even in cross-modal decoding, such as interpreting",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk116",
      "text": "text representations of mental states during silent film viewing.\n\nFoundation models have also been instrumental in enhancing the performance of BMI systems, especially in decoding audio and visual\n\nsignals (Metzger et al., 2023; Anumanchipalli et al., 2019; Wang et al.,\n\nNeuroscience Research 215 (2025) 3-14\n\nR. Wang and Z.S. Chen",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk117",
      "text": "2020,2023; Takagi and Nishimoto, 2023; Denk et al., 2023; Bellier et al., 2023; Benchetrit et al., 2023). For instance, Metzger et al. (2023) uti- lized a pre-trained speech generative model to decode clear speech from neural signals. Specifically, they used a sophisticated transformer-based speech encoding model (“HuBERT”) to learn a compact representation of speech, which was then transformed into high-quality speech using a pre-trained synthesizer. Beyond speech, music decoding has also seen",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk118",
      "text": "progresses with the aid of generative AI. Multiple lines of recent research (Denk et al., 2023; Bellier et al., 2023) have demonstrated the feasibility of decoding music from neural signals using deep learning, with pre-trained models such as musicLM (Agostinelli et al., 2023, to produce high-quality outputs. Similarly, image reconstruction from fMRI scans has achieved remarkable accuracy with the help of image generative models such as the VAE, GAN, and diffusion models (Takagi and Nish- imoto,",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk119",
      "text": "2023; Ferrante et al., 2023b; VanRullen and Reddy, 2019; Huang et al., 2021; Ozcelik and VanRullen, 2023). In these studies, neural signals were first converted into latent representations, and then used to produce images through various generative models (Table 2). For instance, a two-stage scene reconstruction framework called “Brain-- Diffuser” has been proposed: in the first stage, a low-level image is first reconstructed via a very deep VAE, and in the second stage, a latent diffusion model",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk120",
      "text": "conditioned on predicted multi-modal (text and visual) features is used to reconstruct high-quality images (Ozcelik and Van-",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk121",
      "text": "pre-trained image generator. The brain-to-image readout was decoded with a foundational image model known as DINOv2. The authors re- ported that MEG-based decoding can recover high-level visual features compared to fMRI-based decoding, offering a real-time BMI paradigm ( ~ 250 ms delay) for the human brain.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk122",
      "text": "To date, most of brain decoding applications have been reported in human research since data format and acquisition are relatively uni- versal, which may not be the case in animal studies. Recently, built upon a foundation model known as Perceiver IO (Jaegle et al., 2022, Azabou et al. (2023) developed a new framework called POYO (Pre-training On manY NeurOns) for large-scale training transformer models end-to-end on multi-session and across-individual electrophysiology datasets. POYO introduces",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk123",
      "text": "innovative spike-based tokenization strategies and uses pre-trained models (with possible fine tuning) for neural population decoding. Using a transformer architecture, POYO applies both cross-attention and self-attention in the latent space after latent em- beddings of neural events. Their work demonstrates the power of transfer learning and transformer to achieve rapid and scalable neural decoding.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk124",
      "text": "4.8. Data augmentation\n\nRullen, 2023).\n\nRemarkably, Benchetrit et al. (2023) developed an real-time visual decoding strategy from MEG recordings using a foundation model. The model consists of three modules: (i) pre-trained embedding obtained\n\nfrom images, (ii) an MEG module trained end-to-end, and (iii) a\n\nTable 2\n\nTable 2\n\nA representative list of recent BMI and neural decoding studies based on generative AI.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk125",
      "text": "Data Model Application ECoG bidirectional brain2speech et al., 2019 LSTM ECoG GAN, transfer brain2speech ECoG ECoG learning ResNet RNN, language model brain2speech brain2text RNN arrays 2022 ECoG ECoG neural network HuBERT, brain2text brain2speech 2023 bidirectional RNN ECoG sequential CNN- brain2speech Nishimoto, 2023 fMRI fMRI LSTM GPT-2 diffusion model brain2text brain2image fMRI VAE, GAN brain2face Reddy, 2019 2023a fMRI fMRI CNN generative image- brain2feature 2023b to-text transformer",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk126",
      "text": "VanRullen, 2023 fMRI fMRI MEG, EEG deep VAE, LSTM very deep VAE, diffusion model Contrastive brain2image brain2image brain2speech 2023 Language-Image Pre-Training 2023 MEG DINOv2 brain2image ECoG feedforward brain2music neural network fMRI MusicLM brain2music spikes PerceiverIO brain2behavior",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk127",
      "text": "Study\n\n(Anumanchipalli\n\n(Wang et al., 2020\n\n(Wang et al., 2023\n\n(Willett et al., 2021\n\nbrain2speech2text\n\n(Willett et al., 2023 microelectrode\n\n(Metzger et al.,\n\n(Metzger et al.,\n\n(Liu et al., 2023\n\n(Tang et al., 2023\n\n(Takagi and\n\n(VanRullen and\n\n(Ferrante et al.,\n\nbrain2image&text\n\n(Ferrante et al.,\n\n(Huang et al., 2021\n\n(Ozcelik and\n\n(D´efossez et al.,\n\n(Benchetrit et al.,\n\n(Bellier et al., 2023",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk128",
      "text": "Machine learning-driven data augmentation techniques are benefi- cial to alleviate the sample imbalance or insufficiency problem (Chawla et al., 2002; He and Garcia, 2009. This is particularly important for improving the generalization ability of deep learning. Recently, data-centric deep learning or generative AI strategies (e.g., data regen- eration and synthetic data generation) have been proposed to improve the consistency between the existing and augmented data, especially in clinical",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk129",
      "text": "applications where labeled samples may be scarce or the data privacy is a concern (Zhang et al., 2022. For instance, combining RNN and GAN may help construct generative models of synthetic time series and impute missing data (Yoon et al., 2019; Lee et al., 2021; Habashi et al., 2023. In one example, combined GAN and VAE models utilized three-dimensional convolution to model high-dimensional fMRI sensors with structured spatial correlations and the synthesized datasets were then used to augment",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk130",
      "text": "classifiers designed to predict cognitive and behavioral outcomes (Zhuang et al., 2019. In another example, an auxiliary classifier GAN (AC-GAN) was used to generate synthetic interictal epileptiform discharges (IED) from EEG recordings of epileptic patients (Geng et al., 2021; Geng and Chen, 2021.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk131",
      "text": "Bird et al. (2021) employed an LLM (based on GPT-2) to augment the EEG/MEG dataset for a classification task. After initial training, the GPT model was used to generate realistic synthetic neural signals as the augmented data; a marginal improvement was reported in classification\n\nperformance.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk132",
      "text": "Soingern et al. (2023) investigated a diffusion model-based EEG data augmentation strategy known as “WaveGrad” and compared it with other commonly used data augmentation techniques; their results showed a consistent improvement and better efficacy in the EEG motor\n\nimagery classification task.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk133",
      "text": "Recently, a text data augmentation approach based on ChatGPT (named AugGPT) (Dai et al., 2023 has been developed to overcome the challenge of limited sample sizes in NLP tasks (Pellicer et al., 2023. Specifically, sentences in the training set were rephrased into concep- tually similar variations as the augmented data with the same label of the original sample. The results showed that data augmentation based on such a large-scale pre-trained model increased the classification ac- curacy by a big",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk134",
      "text": "margin in comparison with standard data augmentation methods. However, more research is still needed to see whether similar",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk135",
      "text": "techniques can apply to neural data augmentation.\n\n(Denk et al., 2023\n\n(Azabou et al.,\n\n2023\n\nNeuroscience Research 215 (2025) 3-14\n\nR. Wang and Z.S. Chen\n\n5. Discussion and conclusion\n\n5.1. Crosstalk between AI and neuroscience",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk136",
      "text": "AI and neuroscience have been driving each other forward. Not only has neuroscience inspired the development of deep learning and AI technologies (Hassabis et al., 2017, but explainable AI and deep learning have also generated opportunities for in-depth neuroscience in- vestigations (Richards et al., 2019; Saxe et al., 2021. For instance, bio- logically constrained CNN models have enabled neuroscientists to directly compare data in the visual cortex and uncover the underlying computational",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk137",
      "text": "principles (Yamins and Hong, 2014; Yamins and DiCarlo, 2016; Shi et al., 2022. Recently, Schneider et al. (2023) proposed a contrastive learning-based neural network model for jointly modeling neural and behavioral dynamics. The SSL algorithm, known as CERBA, which combines ideas from nonlinear independent component analysis (ICA) with contrastive learning, may identify interpretable and consis- tent neural embeddings of high-dimensional neural recordings using auxiliary variables (such as time",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk138",
      "text": "or behavioral measures). Importantly, it can generate embeddings across multiple subjects and cope with dis- tribution shifts among experimental sessions, subjects, and recording modalities. In another example, Caucheteux et al. (2023) applied deep language algorithms (based on GPT-2) to predict nearby words and discovered that the activations of language models linearly map onto the brain responses to speech, and these predictions are organized hierar- chically in frontoparietal and temporal",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk139",
      "text": "cortices. These findings illustrate that the synergy between neuroscience and AI can largely improve our",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk140",
      "text": "understanding of human cognition.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk141",
      "text": "It is also worth mentioning that current AI technologies have relied on oversimplified models of neural systems. First and foremost, the standard artificial neurons in deep neural networks are “point neurons” that focus on somatic computation, yet the importance of nonlinear dendritic computation has been ignored. However, it has been known that the dendrite also plays an important role in neuronal computations and biological learning, such as enhancing expressivity of single neu- rons,",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk142",
      "text": "improving neuronal resources and generalization abilities, utiliz- ing internal learning signals, and enabling continual learning, contextual representation, and predictive coding (Acharya et al., 2022; Hodassman et al., 2022; Hawkins and Ahmad, 2016. Deep learning models have the potential to reproduce the computational complexity of biologically realistic neurons’ I/O properties (Beniaguev et al., 2021. Second, brain oscillations are important hallmarks in representing neural dynamics for a",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk143",
      "text": "wide range of tasks in cognition, attention, memory, decision-making, and sensorimotor integration. Future devel- opment of next-generation neuroAI models and biologically plausible learning algorithms remains a central research direction to transform a “black-box” to “glass box” model while achieving a good trade-off be- tween performance and interpretability.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk144",
      "text": "5.2. Outlook and outstanding questions\n\net al., 2015. However, there is a major gap in basic and clinical neuro- science applications because of the lack of high-quality training samples and benchmarks. However, this issue has been noticed in some research communities (e.g., AI for Epilepsy, (Chung et al., 2022), and the status quo may change soon. Several large-scale public datasets (Table 3) have become increasingly popular in open-source research.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk145",
      "text": "Finally, we present several outstanding questions that might moti- vate future research in the intersection of AI and neuroscience.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk146",
      "text": "• Since the majority of foundation models have been trained on single- modal data, it is unclear whether the model would benefit from training based on multi-modal or cross-modal data when the decoding domain is on single modality. For instance, in simultaneous EEG-fMRI recordings, can we train a foundation model based on their joint measurements, and then apply the pre-trained model in EEG-alone or fMRI-alone decoding analysis? While the prior knowledge of the cross-modal relationship may be",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk147",
      "text": "beneficial, the variability in SNR and spatiotemporal resolution between the two modalities may create practical barriers. Furthermore, it remains an open question how we should apply SSL to identify an optimal analysis pipeline for multi-modal neuroimaging data.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk148",
      "text": "• Representation learning and foundation models have great potential in RL, including end-to-end policy learning (Bahl et al., 2020 and multi-agent communications (Foerster et al., 2016. However, it re- mains unclear how well the foundation models and learned embed- ding representations can generalize across tasks in RL. For instance, RL algorithms have been developed in BMI applications, enabling individuals with motor disabilities to control external devices using neural signals. It still",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk149",
      "text": "needs to be thoroughly tested whether the pre-trained policy can generalize across subjects, tasks, and envi- ronments. Identifying common as well as individualized decision-making or control policies under the new representation",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk150",
      "text": "learning paradigm will continue to be an active research topic.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk151",
      "text": "• While ChatGPT can be used as an interface between users and external systems, serving as a bridge between individuals with limited mobility and the external world, it is vital to revolutionize the communication capability of BMIs by translating thoughts into text- based information and refining the dynamics of human-machine interaction. However, it remains unclear how ChatGPT or GPT-like models can be optimally integrated into the BMI systems. Further- more, can we adapt these models or",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk152",
      "text": "generative AI to interpret and produce text that syncs flawlessly with a user’s intentions while abiding by ethical and privacy mandates? The recurrent engagement of users with ChatGPT offers prospects to transform the lives of those with disabilities and to develop personalized and adaptable BMI",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk153",
      "text": "systems, escalating user gratification and optimizing system outputs.\n\n• Ongoing research has continued producing new frontiers in foun- dation models and generative AI, such as the new autonomous AI agent tools (AutoGPT, MetaGPT and AutoGen) (see a compiled list at\n\nhttps://github.com/steven2358/awesome-generative-ai).",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk154",
      "text": "Looking ahead, foundation models and generative AI will likely see a rapid research growth in method development and applications, espe- cially in brain imaging and large-scale neural and behavioral data ana- lyses (Moor et al., 2023. In clinical applications, foundation models and generative AI may have a great impact on personalized medicine. A growing number of ChatBots, such as ChatGPT and Bard, can play an active role in mitigating the worldwide crisis in mental health (Chen et al., 2022.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk155",
      "text": "In multi-modal BMI systems, generative AI will help combine speech, vision and motor modalities to improve the function- ality and decoding accuracy. Future developments of brain-to-content neurotechnologies may have promising applications in immersive vir-",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk156",
      "text": "tual reality, video games, marketing, and personalizied education.\n\nIn computer vision and NLP, BigData-empowered machine learning technologies have improved in performance steadily over the years,\n\nassessed by quantitative benchmarks (Deng et al., 2009; Russakovsky\n\nTable 3\n\nPublic datasets for open-source neuroscience research.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk157",
      "text": "Creator Data modality Website Allen Brain Observatory CRCNS electrophysiology, calcium imaging electrophysiology, https://observatory.bra in-map.org/ https://crcns.org/ neuroimaging data-sets MIT Lab for medical research data https://physionet.org Computational Physiology Harvard EEG Dataset EEG https://bdsp.io/content /harvard-eeg-db/ OpenNeuro human neuroimaging OpenNeuro.org Human Connectome neuroimaging https://www.humanc\n\nhuman neuroimaging\n\nProject\n\nonnectome.org/\n\n10",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk158",
      "text": "Neuroscience Research 215 (2025) 3-14\n\nR. Wang and Z.S. Chen\n\nIntegration of these emerging AI technologies into neuroscience applications presents more challenges and opportunities.\n\nBaevski, A., Hsu, W.N., Xu, Q., Babu, A., Gu, J., Auli, M., 2022.Data2vec: A general framework for self-supervised learning in speech, vision and language.arXiv: 2202.03555.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk159",
      "text": "In conclusion, many research areas in neuroscience have greatly benefited from BigData-empowered machine learning. Exploitation of large-scale foundation models, generative AI, and transfer learning tools will enable us to potentially probe neuroscience questions and brain-to- content technology in new dimensions. The landscape of neuroscience research is rapidly changing, and our imagination is only the limit for creativity. We hope this mini-review will inspire more exciting work in the near",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk160",
      "text": "future.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk161",
      "text": "Baevski, A., Zhou, H., Mohamed, A., Auli, M., 2020.wav2vec 2.0: A Framework for Self- supervised Learning of Speech Representations, arXiv:2006.11477.\n\nBagchi, S., Bathula, D.R., 2022. EEG-ConvTransformer for single-trial EEG-based visual stimulus classification. Pattern Recognit. 129, 108757 https://doi.org/10.1016/j.\n\npatcog.2022.108757.\n\nBahl, S., Mukadam, M., Gupta, A., Pathak, D., 2020.Neural Dynamic Policies for End-to- end Sensorimotor Learning, In: NeurIPS.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk162",
      "text": "Balestriero, R., Ibrahim, M., Sobal, V., Morcos, A., Shekhar, S., Goldstein, T., Bordes, F., Bardes, A., Mialon, G., Tian, Y., Schwarzschild, A., Wilson, A.G., Geiping, J., Garrido, Q., Fernandez, P., Bar, A., Pirsiavash, H., LeCun, Y., Goldblum, M., 2023.A Cookbook of Self-supervised Learning.10.48550/arXiv.2304.12210.\n\nFunding\n\nThe work was partially supported by grants MH118928, DA056394, NS123928, NS121776, MH132642, and NS135170 from the US National",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk163",
      "text": "Institutes of Health. We thank Katherine Eisert for careful proofreading.\n\nBanville, H., Chehab, O., Hyv¨arinen, A., Engemann, D.A., Gramfort, A., 2020.Uncovering the structure of clinical EEG signals with self-supervised learning.10.48550/ arXiv.2007.16104.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk164",
      "text": "Bellier, L., Llorens, A., Marciano, D., Gunduz, A., Schalk, G., Brunner, P., Knight, R.T., 2023. Music can be reconstructed from human auditory cortex activity using nonlinear decoding models. PLoS Biol. 21, e3002176 https://doi.org/10.1371/ journal.pbio.3002176.\n\nBenchetrit, Y., Banville1, H., King, J.R., 2023.Brain decoding: toward real-time reconstruction of visual perception.〈https://ai.meta.com/static-resource/image-de coding〉.\n\nCRediT authorship contribution statement",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk165",
      "text": "Bengio, Y., Courville, A., Vincent, P., 2014.Representation Learning: A Review and New Perspectives, arXiv:1206.5538.\n\nZhe Sage Chen: Conceptualization, Investigation, Methodology, Project administration, Supervision, Visualization, Writing – original draft, Writing – review & editing. Ran Wang: Conceptualization, Writing – original draft, Writing – review & editing.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk166",
      "text": "Beniaguev, D., Segev, I., London, M., 2021. Single cortical neurons as deep artificial neural networks. Neuron 109, 2727–2739. https://doi.org/10.1016/j.\n\nneuron.2021.07.002.\n\nBird, J.J., Pritchard, M., Fratini, A., Ek´art, A., Faria, D.R., 2021. Synthetic biological signals machine-generated by GPT-2 improve the classification of EEG and EMG through data augmentation. IEEE Robot. Autom. Lett. 6, 3498–3504. https://doi.\n\norg/10.1109/LRA.2021.3056355.\n\nDeclaration of Competing Interest",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk167",
      "text": "Bolkan, S.S., Stone, I.R., Pinto, L., Ashwood, Z.C., Garcia, J.M.I., Herman, A.L., Singh, P., Bandi, A., Cox, J., Zimmerman, C.A., Cho, J.R., Engelhard, B., Pillow, J.W., Witten, I. B., 2022. Opponent control of behavior by dorsomedial striatal pathways depends on task demands and internal state. Nat. Neurosci. 25, 345–357. https://doi.org/ 10.1038/s41593-022-01021-9.\n\nThe authors declare no competing interests.\n\nData Availability",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk168",
      "text": "No data was used for the research described in the current article.\n\nAcknowledgments\n\nThe authors thank Dr. Ryota Kobayashi and Dr. Ken Nakae for the invitation to participate in a Special Session at the Annual Japanese Neuroscience Meeting held in Sendai, Japan on August 3, 2023, which motivated the writing of this review.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk169",
      "text": "Bommasani, R., Hudson, D.A., Adeli, E., Altman, R., Arora, S., vonArx, S., Bernstein, M. S., Bohg, J., Bosselut, A., Brunskill, E., Brynjolfsson, E., Buch, S., Card, D., Castellon, R., Chatterji, N.S., Chen, A.S., Creel, K.A., Davis, J., Demszky, D., Donahue, C., Doumbouya, M., Durmus, E., Ermon, S., Etchemendy, J., Ethayarajh, K., Fei-Fei, L., Finn, C., Gale, T., Gillespie, L.E., Goel, K., Goodman, N.D., Grossman, S., Guha, N., Hashimoto, T., Henderson, P., Hewitt, J., Ho, D.E., Hong, J., Hsu,",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk170",
      "text": "K., Huang, J., Icard, T.F., Jain, S., Jurafsky, D., Kalluri, P., Karamcheti, S., Keeling, G., Khani, F., Khattab, O., Koh, P.W., Krass, M.S., Krishna, R., Kuditipudi, R., Kumar, A., Ladhak, F., Lee, M., Lee, T., Leskovec, J., Levent, I., Li, X.L., Li, X., Ma, T., Malik, A., Manning, C.D., Mirchandani, S.P., Mitchell, E., Munyikwa, Z., Nair, S., Narayan, A., Narayanan, D., Newman, B., Nie, A., Niebles, J.C., Nilforoshan, H., Nyarko, J.F., Ogut, G., Orr, L., Papadimitriou, I., Park, J.S., Piech,",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk171",
      "text": "C., Portelance, E., Potts, C., Raghunathan, A., Reich, R., Ren, H., Rong, F., Roohani, Y.H., Ruiz, C., Ryan, J., R’e, C., Sadigh, D., Sagawa, S., Santhanam, K., Shih, A., Srinivasan, K.P., Tamkin, A., Taori, R., Thomas, A.W., Tram`er, F., Wang, R.E., Wang, W., Wu, B., Wu, J., Wu, Y., Xie, S.M., Yasunaga, M., You, J., Zaharia, M.A., Zhang, M., Zhang, T., Zhang, X., Zhang, Y., Zheng, L., Zhou, K., Liang, P., 2021.On the Opportunities and Risks of Foundation Models, ArXiv",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk172",
      "text": "〈https://crfm.stanford.edu/assets/report.pdf〉.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk173",
      "text": "References\n\nAbid, A., Zhang, M.J., Bagaria, V.K., Zou, J., 2018. Exploring patterns enriched in a dataset with contrastive principal component analysis. Nat. Commun. 9, 2134.\n\nhttps://doi.org/10.1038/s41467-018-04608-8.\n\nAcharya, J., Basu, A., Legenstein, R., Limbacher, T., Poirazi, P., Wu, X., 2022. Dendritic computing: branching deeper into machine learning. Neuroscience 489, 275–289.\n\nhttps://doi.org/10.1016/j.neuroscience.2021.10.001.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk174",
      "text": "Aglinskas, A., Hartshorne, J.K., Anzellotti, S., 2022. Contrastive machine learning reveals the structure of neuroanatomical variation within autism. Science 376, 1074–1076.\n\nhttps://doi.org/10.1126/science.abm2461.\n\nAgostinelli, A., Denk, T.I., Borsos, Z., Engel, J., Verzetti, M., Caillon, A., Huang, Q., Jansen, A., Roberts, A., Tagliasacchi, M., et al., 2023.MusicLM: Generating music from text.10.48550/arXiv.2301.11325.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk175",
      "text": "Anumanchipalli, G.K., Chartier, J., Chang, E.F., 2019. Speech synthesis from neural decoding of spoken sentences. Nature 568, 493–498. https://doi.org/10.1038/\n\ns41586-019-1119-1.\n\nArdalan, Z., Subbian, V., 2022. Transfer learning approaches for neuroimaging analysis: a scoping review. Front. Artif. Intell. 5, 780405 https://doi.org/10.3389/\n\nfrai.2022.780405.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk176",
      "text": "Ashwood, Z.C., Roy, N.A., Stone, I.R., Laboratory, I.B., Urai, A.E., Churchland, A.K., Pouget, A., Pillow, J.W., 2022. Mice alternate between discrete strategies during perceptual decision-making. Nat. Neurosci. 25, 201–212. https://doi.org/10.1038/\n\ns41593-021-01007-z.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk177",
      "text": "Azabou, M., Arora, V., Ganesh, V., Mao, X., Nachimuthu, S., Mendelson, M., Richards, B., Perich, M., Lajoie, G., Dyer, E.L., 2023.A Unified, Scalable Framework for Neural Population Decoding, In: Thirty-seventh Conference on Neural Information\n\nProcessing Systems.\n\nBaevski, A., Babu, A., Hsu, W.N., Auli, M., 2023.Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language, arXiv:\n\n2212.07525.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk178",
      "text": "Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., Amodei, D., 2020. Language models are few-shot learners. In: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., Lin, H.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk179",
      "text": "(Eds.), Advances in Neural Information Processing Systems. Curran Associates, Inc.,",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk180",
      "text": "pp. 1877–1901\n\nCalhoun, A.J., Pillow, J.W., Murthy, M., 2019. Unsupervised identification of the internal states that shape natural behavior. Nat. Neurosci. 22, 2040–2049. https://doi.org/ 10.1371/journal.pbio.3002176.\n\nCaucheteux, C., Gramfort, A., King, J.R., 2023. Decoding speech from non-invasive brain recordings. Nat. Hum. Behav. 7, 430–441. https://doi.org/10.1038/s41562-022-\n\n01516-2.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk181",
      "text": "Chawla, N.V., Bowyer, K.W., Hall, L.O., Kegelmeyer, W.P., 2002. SMOTE: synthetic minority over-sampling technique. J. Artif. Intell. Res. 16, 321–357. https://doi.org/ 10.1613/jair.953.\n\nChen, Z., 2015. Advanced State Space Methods for Neural and Clinical Data (Ed.). Cambridge University Press.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk182",
      "text": "Chen, Z.S., Kulkarni, P., Galatzer-Levy, I., Bigio, B., Nasca, C., Zhang, Y., 2022. Modern views of machine learning for future precision psychiatry. Patterns 3, 100602. https://doi.org/10.1016/j.patter.2022.100602.\n\nChen, Z.S., Pesaran, B., 2021. Improving scalability in systems neuroscience. Neuron 109, 1776–1790. https://doi.org/10.1016/j.neuron.2021.03.025.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk183",
      "text": "Chen, Z., Qing, J., Xiang, T., Yue, W.L., Zhou, J.H., 2023.Seeing Beyond the Brain: Conditional Diffusion Model with Sparse Masked Modeling for Vision\n\nDecoding.10.48550/arXiv.2211.06956.\n\nChung, Y.G., Jeon, Y., Yoo, S., Kim, H., Hwang, H., 2022. Big data analysis and artificial intelligence in epilepsy—common data model analysis and machine learning-based\n\n11\n\nNeuroscience Research 215 (2025) 3-14\n\nR. Wang and Z.S. Chen",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk184",
      "text": "seizure detection and forecasting. Clin. Exp. Pedia 65, 272–282. https://doi.org/ 10.3345/cep.2021.00766.\n\nHo, J., Jain, A., Abbeel, P., 2020.Denoising diffusion probabilistic models.arXiv preprint abs/2006.11239. 10.48550/arXiv.2006.11239.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk185",
      "text": "Dado, T., Güçlütürk, Y., Ambrogioni, L., Ras, G., Bosch, S., van Gerven, M., Güçlü, U., 2022. Hyperrealistic neural decoding for reconstructing faces from fMRI activations via the GAN latent space. Sci. Rep. 12, 14. https://doi.org/10.1038/s41598-021- 03938-w.\n\nDai, H., Liu, Z., Liao, W., Huang, X., Cao, Y., Wu, Z., Zhao, L., Xu, S., Liu, W., Liu, N., et al., 2023.AugGPT: Leveraging ChatGPT for text data augmentation.arXiv preprint 10.48550/arXiv.2302.13007.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk186",
      "text": "D´efossez, A., Caucheteux, C., Rapin, J., Kabeli, O., King, J.R., 2023. Decoding speech from non-invasive brain recordings. Nat. Mach. Intell. 5, 1097–1107. https://doi.\n\norg/10.1038/s42256-023-00714-5.\n\nvan den Oord, A., Li, Y., Vinyals, O., 2019.Representation Learning with Contrastive Predictive Coding.10.48550/arXiv.1807.03748.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk187",
      "text": "Hodassman, S., Vardi, R., Tugendhaft, Y., Goldental, A., Kanter, I., 2022. Efficient dendritic learning as an alternative to synaptic plasticity hypothesis. Sci. Rep. 12, 6571. https://doi.org/10.1038/s41598-022-10466-8.\n\nHollenstein, N., Renggli, C., Glaus, B., Barrett, M., Troendle, M., Langer, N., Zhang, C., 2021. Decoding EEG brain activity for multi-modal natural language processing. Front. Hum. Neurosci. 15, 659410 https://doi.org/10.3389/fnhum.2021.659410.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk188",
      "text": "Horikawa, T., Tamaki, M., Miyawaki, Y., Kamitani, Y., 2013. Neural decoding of visual imagery during sleep. Science 340, 639–642. https://doi.org/10.1126/ science.1234330.\n\nHsu, W.N., Bolte, B., Tsai, Y.H.H., Lakhotia, K., Salakhutdinov, R., Mohamed, A., 2021. HuBERT: Self-supervised Speech Represent. Learn. Masked Predict. Hidden Units arXiv:2106.07447.\n\nDeng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., 2009. Imagen. Large-scale Hierarchical Image Database. CVPR09.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk189",
      "text": "Denk, T.I., Takagi, Y., Matsuyama, T., Agostinelli, A., Nakai, T., Frank, C., Nishimoto, S., 2023.Brain2music: Reconstructing Music from Human Brain Activity.10.48550/ arXiv.2307.11078.\n\nDevlin, J., Chang, M.W., Lee, K., Toutanova, K., 2019.BERT: pre-training of deep bidirectional transformers for language understanding, In: Proceedings of NAACL- HLT 2019, Association for Computational Linguistics.4171-4186.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk190",
      "text": "Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et al., 2020.An image is worth 16x16 words: Transformers for image recognition at scale.10.48550/\n\narXiv.2010.11929.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk191",
      "text": "Eldele, E., Ragab, M., Chen, Z., Wu, M., Kwoh, C.K., Li, X., 2023. Self-supervised learning for label- efficient sleep stage classification: a comprehensive evaluation. IEEE Trans. Neural Syst. Rehabil. Eng. 31, 1333–1342. https://doi.org/10.1109/\n\nTNSRE.2023.3245285.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk192",
      "text": "Fei, N., Lu, Z., Gao, Y., Yang, G., Huo, Y., Wen, J., Lu, H., Song, R., Gao, X., Xiang, T., et al., 2022. Towards artificial general intelligence via a multimodal foundation model. Nat. Commun. 13, 3094. https://doi.org/10.1038/s41467-022-30761-2.\n\nFerrante, M., Boccato, T., Toschi, N., 2023a.Semantic Brain Decoding: from fMRI to Conceptually Similar Image Reconstruction of Visual Stimuli.10.48550/ arXiv.2212.06726.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk193",
      "text": "Huang, W., Yan, H., Wang, C., Yang, X., Li, J., Zuo, Z., Zhang, J., Chen, H., 2021. Deep natural image reconstruction from human brain activity based on conditional progressively growing generative adversarial networks. Neurosci. Bull. 37, 369–379. https://doi.org/10.1007/s12264-020-00613-4.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk194",
      "text": "Huth, A.G., De Heer, W.A., Griffiths, T.L., Theunissen, F.E., Gallant, J.L., 2016a. Natural speech reveals the semantic maps that tile human cerebral cortex. Nature 532, 453–458. https://doi.org/10.1038/nature17637.\n\nHuth, A.G., Lee, T., Nishimoto1, S., Bilenko, N.Y., Vu, A.T., Gallant, J.L., 2016b. Decoding the semantic content of natural movies from human brain activity. Front. Syst. Neurosci. 10, 81. https://doi.org/10.3389/fnsys.2016.00081.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk195",
      "text": "Huth, A.G., Nishimoto1, S., Vu, A.T., Gallant, J.L., 2012. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. Neuron 76, 1210–1224. https://doi.org/10.1016/j.\n\nneuron.2012.10.014.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk196",
      "text": "Jaegle, A., Borgeaud, S., Alayrac, J.B., Doersch, C., Ionescu, C., Ding, D., Koppula, S., Zoran, D., Brock, A., Shelhamer, E., H´enaff, O., Botvinick, M.M., Zisserman, A., Vinyals, O., Carreira, J., 2022.Perceiver io: A General Architecture for Structured Inputs & Outputs.10.48550/arXiv.2107.14795.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk197",
      "text": "Joshi, M., Chen, D., Liu, Y., Weld, D.S., Zettlemoyer, L., Levy, O., 2020. SpanBERT: Improving pre-training by representing and predicting spans. Transactions of the Association for. Comput. Linguist. 8, 64–77. https://doi.org/10.1162/tacl_a_00300. Kingma, D.P., Welling, M., 2013.Auto-Encoding Variational Bayes.arXiv:1312.6114.\n\nFerrante, M., Ozcelik, F., Boccato, T., VanRullen, R., Toschi, N., 2023b.Brain Captioning: Decoding Human Brain Activity Into Images and Text.10.48550/arXiv.2305.11560.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk198",
      "text": "Foerster, J.N., Assael, Y.M., de Freitas, N., Whiteson, S., 2016. Learning to Communicate with Deep Multi-agent Reinforcement Learning. Advances in Neural Information Processing Systems. Curran Associates Inc., Red Hook, NY, USA, pp. 2145–2153.\n\nFu, K., Du, C., Wang, S., He, H., 2022.Multi-View Multi-label Fine-grained Emotion Decoding from Human Brain Activity.IEEE Transactions on Neural Networks and\n\nLearning Systems.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk199",
      "text": "Geng, D., Alkhachroum, A., MeloBicchi, M., Cajigas, I., Chen, Z.S., 2021. Deep learning for robust detection of interictal epileptiform discharges. J. Neural Eng. 18, 056015\n\nhttps://doi.org/10.1088/1741-2552/abf28e.\n\nGeng, D., Chen, Z.S., 2021.Auxiliary classifier generalized adversarial network (AC-GAN) for interictal epileptiform discharge modeling and data augmentation, In: Proc. IEEE EMBS Neural Engineering Conference (NER), 5508-5518.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk200",
      "text": "Gilja, V., Nuyujukian, P., Chestek, C.A., Cunningham, J.P., Yu, B.M., Fan, J.M., Churchland, M.M., Kaufman, M.T., Kao, J.C., Ryu, S.I., Shenoy, K.V., 2012. A high- performance neural prosthesis enabled by control algorithm design. Nat. Neurosci. 15, 1752–1757. https://doi.org/10.1038/nn.3265.\n\nGoetschalckx, L., Andonian, A., Wagemans, J., 2021. Generative adversarial networks unlock new methods for cognitive science. Trends Neurosci. 25, 788–801. https:// doi.org/10.1016/j.tics.2021.06.006.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk201",
      "text": "Goldstein, A., Zada, Z., Buchnik, E., Schain, M., Price, A., Aubrey, B., Nastase, S.A., Feder, A., Emanuel, D., Cohen, A., et al., 2022. Shared computational principles for language processing in humans and deep language models. Nat. Neurosci. 25, 369–380. https://doi.org/10.1038/s41593-022-01026-4.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk202",
      "text": "Kostas, D., Aroca-Ouellette, S., Rudzicz, F., 2021. BENDR: Using transformers and a contrastive self-supervised learning task to learn from massive amounts of EEG data. Front Hum. Neurosci. 15, 653659 https://doi.org/10.3389/fnhum.2021.653659.\n\nKrakauer, J.W., Ghazanfar, A.A., Gomez-Marin, A., MacIver, M.A., Poeppel, D., 2017. Neuroscience needs behavior: correcting a reductionist bias. Neuron 93, 480–490. https://doi.org/10.1016/j.neuron.2016.12.041.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk203",
      "text": "Lakshminarasimhan, K.J., Avila, E., Pitkow, X., Angelaki, D.E., 2023. Dynamical latent state computation in the male macaque posterior parietal cortex. Nat. Commun. 14, 1832. https://doi.org/10.1038/s41467-023-37400-4.\n\nLatimer, K.W., Yates, J.L., Meister, M.L.R., Huk, A.C., Pillow, J.W., 2015. Single-trial spike trains in parietal cortex reveal discrete steps during decision-making. Science 349, 184–187. https://doi.org/10.1126/science.aaa4056.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk204",
      "text": "Lebedev, M., Nicolelis, M., 2017. Brain-machine interfaces: from basic science to neuroprostheses and neurorehabilitation. Physiol. Rev. 97, 767–837. https://doi.\n\norg/10.1152/physrev.00027.2016.\n\nLee, W., Lee, J., Kim, Y., 2021. Contextual imputation with missing sequence of EEG signals using generative adversarial networks. IEEE Access 9, 151753.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk205",
      "text": "Li, Y., Anumanchipalli, G.K., Mohamed, A., Lu, J., Wu, J., Chang, E.F., 2023b. Dissecting neural computations of the human auditory pathway using deep neural networks for speech. Nat. Neurosci. https://doi.org/10.1038/s41593-023-01468-4.\n\nLi, W., Luo, H., Lin, Z., Zhang, C., Lu, Z., Ye, D., 2023a.A Survey on Transformers in Reinforcement Learning.10.48550/arXiv.2301.03044.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk206",
      "text": "Liu, Y., Zhao, Z., Xu, M., Yu, H., Zhu, Y., Zhang, J., Bu, L., Zhang, X., Lu, J., Li, Y., Ming, D., Wu, J., 2023. Decoding and synthesizing tonal language speech from brain activity. Sci. Adv. 9, eadh0478 https://doi.org/10.1126/sciadv.adh0478.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk207",
      "text": "Gong, C., Jing, C., Chen, X., Pun, C.M., Huang, G., Saha, A., Nieuwoudt, M., Li, H., Hu, Y., Wang, S., 2023. Generative AI for brain image computing and brain network computing: a review. Front. Neurosci. 17, 1203104 https://doi.org/10.3389/ fnins.2023.1203104.\n\nGoodfellow, I., Bengio, Y., Courville, A., 2016. Deep Learning. MIT Press, Cambridge, MA.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk208",
      "text": "Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., 2014. Generative adversarial nets. In: Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N., Weinberger, K. (Eds.), Advances in Neural Information Processing Systems. Curran Associates, Inc.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk209",
      "text": "Groussard, M., Viader, F., Landeau, B., Desgranges, B., Eustache, F., Platel, H., 2009. Neural correlates underlying musical semantic memory. Ann. NY Acad. Sci. 1169, 278–281. https://doi.org/10.1111/j.1749-6632.2009.04784.x.\n\nGui, J., Sun, Z., Wen, Y., Tao, D., Ye, J., 2020.A review on generative adversarial networks: Algorithms, theory, and applications.10.48550/arXiv.2001.06937.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk210",
      "text": "Habashi, A.G., Azab, A.M., Eldawlatly, S., Aly, G.M., 2023. Generative adversarial networks in EEG analysis: an overview. J. Neuroeng. Rehabil. 20, 40. https://doi. org/10.1186/s12984-023-01169-w.\n\nHassabis, D., Kumaran, D., Summerfield, C., Botvinick, M., 2017. Neuroscience-inspired artificial intelligence. Neuron 95, 245–258.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk211",
      "text": "Lu, H., Zhou, Q., Fei, N., Lu, Z., Ding, M., Wen, J., Du, C., Zhao, X., Sun, H., He, H., et al., 2022.Multimodal foundation models are better simulators of the human brain.arXiv preprint 10.48550/arXiv.2208.08263.\n\nMacpherson, T., Churchland, A., Sejnowski, T., DiCarlo, J., Kamitani, Y., Takahashi, H., Hikida, T., 2021. Natural and artificial intelligence: a brief introduction to the interplay between ai and neuroscience research. Neural Netw. 144, 603–613.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk212",
      "text": "https://doi.org/10.1016/j.neunet.2021.09.018.\n\nMalik, N., Bzdok, D., 2022. From YouTube to the brain: transfer learning can improve brain-imaging predictions with deep learning. Neural Netw. 153, 325–338. https://\n\ndoi.org/10.1016/j.neunet.2022.06.014.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk213",
      "text": "Metzger, S.L., Littlejohn, K.T., Silva, A.B., Moses, D.A., Seaton, M.P., Wang, R., Dougherty, M.E., Liu, J.R., Wu, P., Berger, M.A., Zhuravleva, I., Tu-Chan, A., Ganguly, K., Anumanchipalli, G.K., Chang, E.F., 2023. A high-performance neuroprosthesis for speech decoding and avatar control. Nature 620, 1037–1046.\n\nhttps://doi.org/10.1038/s41586-023-06443-4.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk214",
      "text": "Metzger, S.L., Liu, J.R., Moses, D.A., Dougherty, M.E., Seaton, M.P., Littlejohn, K.T., Chartier, J., Anumanchipalli, G.K., Tu-Chan, A., Ganguly, K., Chang, E.F., 2022. Generalizable spelling using a speech neuroprosthesis in an individual with severe limb and vocal paralysis. Nat. Commun. 13, 6510. https://doi.org/10.1038/s41467-\n\n022-33611-3.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk215",
      "text": "Hawkins, J., Ahmad, S., 2016. Why neurons have thousands of synapses, a theory of sequence memory in neocortex. Front. Neural Circuits 10, 23. https://doi.org/\n\n10.3389/fncir.2016.00023.\n\nHe, H., Garcia, E., 2009. Learning from imbalanced data. IEEE Trans. Knowl. Data Eng. 21, 1263–1284.\n\nMillet, J., Caucheteux, C., Orhan, P., Boubenec, Y., Gramfort, A., Dunbar, E., Pallier, C., King, J.R., 2023.toward A Realistic Model of Speech Processing in the Brain with",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk216",
      "text": "Self-supervised Learning.10.48550/arXiv.2206.01685.\n\n12\n\nNeuroscience Research 215 (2025) 3-14\n\nR. Wang and Z.S. Chen\n\nMoor, M., Banerjee, O., Abad, Z., Krumholz, H., Leskovec, J., Topol, E., Rajpurkar, P., 2023. Foundation models for generalist medical artificial intelligence. Nature 616, 259–265. https://doi.org/10.1038/s41586-023-05881-4.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk217",
      "text": "Moses, D.A., Metzger, S.L., Liu, J.R., Anumanchipalli, G.K., Makin, J.G., Sun, P.F., Chartier, J., Dougherty, M.E., Liu, P.M., Abrams, G.M., Tu-Chan, A., Ganguly, K., Chang, E.F., 2021. Neuroprosthesis for decoding speech in a paralyzed person with anarthria. N. Engl. J. Med. 385, 217–227. https://doi.org/10.1056/\n\nNEJMoa2027540.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk218",
      "text": "Naveed, H., Khan, A.U., Qiu, S., Saqib, M., Anwar, S., Usman, M., Akhtar, N., Barnes, N., Mian, A., 2023.A Comprehensive Overview of Large Language Models.10.48550/ arXiv.2307.06435.\n\nNishimoto, S., Vu, A.T., Naselaris, T., Benjamini, Y., Yu, B., Gallant, J.L., 2011. Reconstructing visual experiences from brain activity evoked by natural movies. Curr. Biol. 21, 1641–1646. https://doi.org/10.1016/j.cub.2011.08.031.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk219",
      "text": "Ozcelik, F., VanRullen, R., 2023.Natural Scene Reconstruction from Fmri Signals Using Generative Latent Diffusion.10.48550/arXiv.2303.05334.\n\nPan, S.J., Yang, Q., 2010. A survey on transfer learning. IEEE Trans. Knowl. Data Eng. 22, 1345–1359. https://doi.org/10.1109/TKDE.2009.191.\n\nPellicer, L.F.A.O., Ferreira, T.M., Costa, A.H.R., 2023. Data augmentation techniques in natural language processing. Appl. Soft Comput. 132, 109803 https://doi.org/ 10.1016/j.asoc.2022.109803.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk220",
      "text": "Pereira, T., Shaevitz, J., Murthy, M., 2020. Quantifying behavior to understand the brain. Nat. Neurosci. 23, 1537–1549. https://doi.org/10.1038/s41593-020-00734-z.\n\nPeterson, S.M., Steine-Hanson, Z., Davis, N., Rao, R.P.N., Brunton, B.W., 2021. Generalized neural decoders for transfer learning across participants and recording modalities. J. Neural Eng. 18, 026014 https://doi.org/10.1088/1741-2552/abda0b.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk221",
      "text": "Poldrack, R., Mumford, J., Schonberg, T., Kalar, D., Barman, B., T, Y., 2012. Discovering relations between mind, brain, and mental disorders using topic mapping. PLoS\n\nComput. Biol. 8, e1002707 https://doi.org/10.1371/journal.pcbi.1002707.\n\nQu, Y., Jian, X., Che, W., Du, P., Fu, K., Liu, Q., 2022.Transfer Learning to Decode Brain States Reflecting the Relationship between Cognitive Tasks.10.48550/ arXiv.2206.03950.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk222",
      "text": "Rafiei, M.H., Gauthier, L.V., Adeli, H., Takabi, D., 2022. Self-supervised learning for electroencephalography. IEEE Trans. Neural Netw. Learn. Syst. https://doi.org/ 10.1109/TNNLS.2022.3190448.\n\nSoingern, N., Sinsamersuk, A., Chatnuntawech, I., Silpasuwanchai, C., 2023. Data augmentation forEEG motor imagery classification using diffusion model. First International Conference on Data Science and Artificial Intelligence (DSAI) Proceeedings). Springer, Berlin, pp. 111–126.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk223",
      "text": "Song, Y., Ermon, S., 2019. Generative modeling by estimating gradients of the data distribution. Adv. Neural Inf. Process. Syst. 32.\n\nSong, Y., Sohl-Dickstein, J., Kingma, D.P., Kumar, A., Ermon, S., Poole, B., 2021.Score- based generative modeling through stochastic differential equations, In: International Conference on Learning Representations.〈https://openreview.net/for um?id=PxTIG12RRHS〉.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk224",
      "text": "Speier, W., Arnold, C., Pouratian, N., 2016. Integrating language models into classifiers for BCI communication: a review. J. Neural Eng. 13, 031002 https://doi.org/ 10.1088/1741-2560/13/3/031002.\n\nSun, G., Zeng, F., McCartin, M., Zhang, Q., Xu, H., Liu, Y., Chen, Z.S., Wang, J., 2022. Closed-loop stimulation using a multi-region brain-machine interface has analgesic effects in rodents. Sci. Transl. Med. 14, eabm5868 https://doi.org/10.1126/ scitranslmed.abm5868.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk225",
      "text": "Takagi, Y., Nishimoto, S., 2023.High-Resolution Image Reconstruction with Latent Diffusion Models from Human Brain Activity, In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 14453-14463.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk226",
      "text": "Tang, S., Dunnmon, J., Saab, K.K., Zhang, X., Huang, Q., Dubost, F., Rubin, D., Lee- Messer, C., 2022.Self-supervised graph neural networks for improved electroencephalographic seizure analysis, In: International Conference on Learning Representations.〈https://openreview.net/forum?id=k9bx1EfHI_-〉.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk227",
      "text": "Tang, J., LeBel, A., Jain, S., Huth, A.G., 2023. Semantic reconstruction of continuous language from non-invasive brain recordings. Nat. Neurosci. 26, 858–866. https:// doi.org/10.1038/s41593-023-01304-9.\n\nThomas, A.W., R´e, C., Poldrack, R.A., 2022. Self-supervised learning of brain dynamics from broad neuroimaging data. In: Oh, A.H., Agarwal, A., Belgrave, D., Cho, K. (Eds.), Advances in Neural Information Processing Systems. 〈https://openreview. net/forum?id=lMrpZ-ycIaT〉.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk228",
      "text": "Tong, X., Xie, H., Fonzo, G., Zhao, K., Theodore, D., Satterthwaite, T.D., Carlisle, N., Zhang, Y., 2021.Dissecting symptom-linked dimensions of resting-state electroencephalographic functional connectivity in austim with contrastive learning. bioRxiv preprint 10.1101/2023.05.22.541841.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk229",
      "text": "Reed, S., Zolna, K., Parisotto, E., Colmenarejo, S.G., Novikov, A., Barth-maron, G., Gim´enez, M., Sulsky, Y., Kay, J., Springenberg, J.T., Eccles, T., Bruce, J., Razavi, A., Edwards, A., Heess, N., Chen, Y., Hadsell, R., Vinyals, O., Bordbar, M., de Freitas, N., 2022.A generalist agent.Transactions on Machine Learning Research 〈https://open review.net/forum?id=1ikK0kHjvj〉.\n\nVahdat, A., Kreis, K., Kautz, J., 2021. Score-based generative modeling in latent space.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk230",
      "text": "Adv. Neural Inf. Process. Syst. 34.\n\nVanRullen, R., Reddy, L., 2019. Reconstructing faces from fMRI patterns using deep generative neural networks. Commun. Biol. 2, 193. https://doi.org/10.1038/\n\ns42003-019-0438-y.\n\nRichards, B.A., Lillicrap, T.P., Beaudoin, P., Bengio, Y., Bogacz, R., Christensen, A., Clopath, C., Costa, R.P., de Berker, A., Ganguli, S., et al., 2019. A deep learning framework for neuroscience. Nat. Neurosci. 22, 1761–1770. https://doi.org/\n\n10.1038/s41593-019-0520-2.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk231",
      "text": "Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B., 2022.High-Resolution Image Synthesis with Latent Diffusion Models, In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.10.1109/CVPR52688.2022\n\n.01042.\n\nRubin, T., Koyejo, O., Gorgolewski, K., Jones, M., Poldrack, R., T, Y., 2017. Decoding brain activity using a large-scale probabilistic functional-anatomical atlas of human cognition. PLoS Comput. Biol. 13, e1005649 https://doi.org/10.1371/journal.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk232",
      "text": "pcbi.1005649.\n\nRussakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L., 2015. ImageNet large scale visual recognition challenge. Int. J. Comput. Vis. 115, 211–252. https://doi. org/10.1007/s11263-015-0816-y.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk233",
      "text": "Sadtler, P.T., Quick, K.M., Golub, M.D., Chase, S.M., Ryu, S.I., Tyler-Kabara, E.C., Yu, B. M., Batista, A.P., 2014. Neural constraints on learning. Nature 512, 423–426. https://doi.org/10.1038/nature13665.\n\nSaxe, A., Nelli, S., Summerfield, C., 2021. If deep learning is the answer, what is the question? Nat. Rev. Neurosci. 22, 55–67. https://doi.org/10.1038/s41583-020-\n\n00395-8.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk234",
      "text": "Schneider, S., Baevski, A., Collobert, R., Auli, M., 2019.wav2vec: Unsupervised pre- training for speech recognition.arXiv:1904.05862.\n\nSchneider, S., Lee, J., Mathis, M., 2023. Learnable latent embeddings for joint behavioural and neural analysis. Nature 617, 360–368. https://doi.org/10.1038/\n\ns41586-023-06031-6.\n\nSchubert, P.J., Dorkenwald, S., Januszewski, M., Jain, V., Kornfeld, J., 2019. Learning cellular morphology with neural networks. Nat. Commun. 10, 2736. https://doi.org/",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk235",
      "text": "10.1038/s41467-019-10836-3.\n\nSeeliger, K., Güçlü, U., Ambrogioni, L., Güçlütürk, Y., van Gerven, M., 2018. Generative adversarial networks for reconstructing natural images from brain activity, 775–785–1790 Neuroimage 181. https://doi.org/10.1016/j.\n\nneuroimage.2018.07.043.\n\nShanechi, M., 2019. Brain-machine interfaces from motor to mood. Nat. Neurosci. 22, 1554–1564. https://doi.org/10.1038/s41593-019-0488-y.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk236",
      "text": "Shen, G., Horikawa, T., Majima, K., Kamitani, Y., 2019. Deep image reconstruction from human brain activity. PLoS Comput. Biol. 15, e1006633 https://doi.org/10.1371/\n\njournal.pcbi.1006633.\n\nShi, J., Tripp, B., Shea-Brown, E., Mihalas, S., Buice, M.A., 2022. MouseNet: a biologically constrained convolutional neural network model for the mouse visual cortex. PLoS Comput. Biol. 18, e1010427 https://doi.org/10.1371/journal.\n\npcbi.1010427.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk237",
      "text": "Singhal, K., Azizi, S., Tu, T., et al., 2023. Large language models encode clinical knowledge. Nature 620, 172–180. https://doi.org/10.1038/s41586-023-06291-2.\n\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł., Polosukhin, I., Attention is all you need, 2017.In: Advances in Neural Information Processing Systems.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk238",
      "text": "Wagh, N., Wei, J., Rawal, S., Berry, B., Barnard, L., Brinkmann, B., Worrell, G., Jones, D., Varatharajah, Y., 2021. Domain-guided self-supervision of eeg data improves downstream classification performance and generalizability. In: Roy, S., Pfohl, S., Rocheteau, E., Tadesse, G.A., Oala, L., Falck, F., Zhou, Y., Shen, L., Zamzmi, G., Mugambi, P., Zirikly, A., McDermott, M.B.A., Alsentzer, E. (Eds.), Proceedings of Machine Learning for Health, pp. 130–142. In: 〈https://proceedings.mlr.press/",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk239",
      "text": "v158/wagh21a.html〉 (PMLR).\n\nWang, R., Chen, X., Khalilian-Gourtani, A., Chen, Z., Yu, L., Flinker, A., Wang, Y., 2020. Stimulus speech decoding from human cortex with generative adversarial network transfer learning. Proc. IEEE 17th International Symposium on Biomedical Imaging (ISBI). IEEE, pp. 390–394, 10.1109/ISBI45749.2020.9098589.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk240",
      "text": "Wang, R., Chen, X., Khalilian-Gourtani, A., Yu, L., Dugan, P., Friedman, D., Doyle, W., Devinsky, O., Wang, Y., Flinker, A., 2023. Distributed feedforward and feedback processing across perisylvian cortex supports human speech. Proc. Natl. Acad. Sci.\n\nUSA 120, e2300255120. https://doi.org/10.1073/pnas.2300255120.\n\nWang, Z., Guet, C., 2022. Self-consistent learning of neural dynamical systems from noisy time series. IEEE Trans. Emerg. Top. Comput. Intell. 6, 1103–1112. https://doi.org/",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk241",
      "text": "10.1109/TETCI.2022.3146332.\n\nWillett, F.R., Avansino, D.T., Hochberg, L.R., Henderson, J.M., Shenoy, K.V., 2021. High- performance brain-to-text communication via handwriting. Nature 593, 249–254.\n\nhttps://doi.org/10.1038/s41586-021-03506-2.\n\nWillett, F.R., Kunz, E.M., Fan, C., Avansino, D.T., Wilson, G.H., Choi, E.Y., Kamdar, F., Glasser, M.F., Hochberg, L.R., Druckmann, S., et al., 2023. A high-performance speech neuroprosthesis. Nature 1–6. https://doi.org/10.1038/s41586-023-06377-x.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk242",
      "text": "Wolfram, S., 2023. What is ChatGPT doing… and Why Does it Work? Wolfram Media Inc. Yamins, D., DiCarlo, J., 2016. Using goal-driven deep learning models to understand sensory cortex. Nat. Neurosci. 19, 356–465. https://doi.org/10.1038/nn.4244.\n\nYamins, D., Hong, H., F, C.C., Solomon, E.A., Seibert, D., DiCarlo, J., 2014. Performance- optimized hierarchical models predict neural responses in higher visual cortex. Proc.\n\nNatl. Acad. Sci. USA 111, 8619–8624. https://doi.org/10.1073/pnas.1403112111.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk243",
      "text": "Yang, C., Xiao, C., Westover, M.B., Sun, J., 2023. Self-supervised electroencephalogram representation learning for automatic sleep staging: model development and\n\nevaluation study. JMIR AI 2, e46769. https://doi.org/10.2196/46769.\n\nYe, J., Pandarinath, C., 2021.Representation Learning for Neural Population Activity with Neural Data Transformers.10.48550/arXiv.2108.01210.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk244",
      "text": "Yoon, J., Jarrett, D., van der Schaar, M., 2019. Time-series generative adversarial networks. Adv. Neural Inf. Process. Syst. 5508–5518.\n\nYosinski, J., Clune, J., Bengio, Y., Lipson, H., 2014. How transferable are features in deep neural networks? Adv. Neural Inf. Process. Syst. 3320–3328.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk245",
      "text": "Zhang, Q., Hu, S., Talay, R., Xiao, Z., Rosenberg, D., Liu, Y., Sun, G., Li, A., Caravan, B., Singh, A., Gould, J.D., Chen, Z.S., Wang, J., 2023. A prototype closed-loop brain- machine interface for the study and treatment of pain. Nat. Biomed. Eng. 7, 533–545. https://doi.org/10.1038/s41551-021-00736-7.\n\n13\n\nR. Wang and Z.S. Chen\n\nNeuroscience Research 215 (2025) 3-14\n\nR. Wang and Z.S. Chen",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk246",
      "text": "Zhang, K., Robinson, N., Lee, S.W., Guan, C., 2021. Adaptive transfer learning for eeg motor imagery classification with deep convolutional neural network. Neural Netw. 136, 1–10. https://doi.org/10.1016/j.neunet.2020.12.013.\n\nZhang, A., Xing, L., Zou, J., Wu, J.C., 2022. Shifting machine learning for healthcare from development to deployment and from models to data. Nat. Biomed. Eng. 6, 1330–1345. https://doi.org/10.1038/s41551-022-00898-y.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk247",
      "text": "Z., Liu, P., Nie, J.Y., Wen, J.R., 2023.A survey of large language models.10.48550/ arXiv.2303.18223.\n\nZhu, Q., Zhao, X., Zhang, J., Gu, Y., Weng, C., Hu, Y., 2023.EEG2vec: Self-Supervised Electroencephalographic Representation Learning.10.48550/arXiv.2305.13957.\n\nZhuang, P., Schwing, A.G., Koyejo, S., 2019.fMRI Data Augmentation Via Synthesis.arXiv preprint 10.48550/arXiv.1907.06134.",
      "source": "p2.pdf"
    },
    {
      "id": "p2.pdf_chunk248",
      "text": "Zhao, W.X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., Min, Y., Zhang, B., Zhang, J., Dong, Z., Du, Y., Yang, C., Chen, Y., Chen, Z., Jiang, J., Ren, R., Li, Y., Tang, X., Liu,\n\n14",
      "source": "p2.pdf"
    },
    {
      "id": "p3.pdf_chunk0",
      "text": "Neuroscience Research 214 (2025) 56-61\n\nELSEVIER\n\nContents lists available at ScienceDirect\n\nNeuroscience Research\n\njournal homepage: www.sciencedirect.com/journal/neuroscience-research\n\nReview article\n\nA chemogenetic technology using insect Ionotropic Receptors to stimulate target cell populations in the mammalian brain\n\nCheck for iw",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk1",
      "text": "Yoshio Iguchi a, Richard Benton b, Kazuto Kobayashi a,*\n\na Department of Molecular Genetics, Institute of Biomedical Sciences, Fukushima Medical University School of Medicine, 1 Hikarigaoka, Fukushima 960-1295, Japan b Center for Integrative Genomics, Faculty of Biology and Medicine, University of Lausanne, Lausanne CH-1015, Switzerland\n\nA R T I C L E I N F O\n\nA B S T R A C T\n\nKeywords: Chemogenetic tool Ionotropic Receptors IR84a/IR8a complex Phenylacetic acid Prodrug system",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk2",
      "text": "Chemogenetics uses artificially-engineered proteins to modify the activity of cells, notably neurons, in response to small molecules. Although a common set of chemogenetic tools are the G protein-coupled receptor-based DREADDs, there has been great hope for ligand-gated, ion channel-type chemogenetic tools that directly impact neuronal excitability. We have devised such a technology by exploiting insect Ionotropic Receptors (IRs), a highly divergent subfamily of ionotropic glutamate receptors",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk3",
      "text": "that evolved to detect diverse environmental chemicals. Here, we review a series of studies developing and applying this “IR-mediated neuronal activation” (IRNA) technology with the Drosophila melanogaster IR84a/IR8a complex, which detects phenyl-containing li- gands. We also discuss how variants of IRNA could be produced by modifying the composition of the IR complex, using natural or engineered subunits, which would enable artificial activation of different cell populations in the brain in",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk4",
      "text": "response to distinct chemicals.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk5",
      "text": "1. Introduction",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk6",
      "text": "A central question in neuroscience is how sensation, movement, emotion, and cognition emerge from the activity of complex neural circuits formed by different cell populations in the nervous system. Elucidating the principles of brain function is not only of fundamental interest: in humans, this knowledge might help understand the patho- physiology of – and promote development of treatments for – psychi- atric/neurological disorders. The identification and characterization of brain cell types is",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk7",
      "text": "highly advanced, thanks to extensive anatomical labelling studies, molecular profiling using single-cell transcriptomics (Marx, 2021; Ofengeim et al., 2017; Zeng and Sanes, 2017), and elec- trophysiological and optical imaging analysis of their activities. How- ever, to understand the functions of defined cell populations and the circuits in which they are embedded, it also important to examine their necessity and sufficiency through loss- and gain-of-function perturba- tions, respectively",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk8",
      "text": "(Sternson and Bleakman, 2020; Tonegawa et al.,",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk9",
      "text": "2015).\n\nTo analyze a causal relationship between neural activity and behavior, optogenetic (Deisseroth, 2015, 2021; Kim et al., 2017) and chemogenetic (Atasoy and Sternson, 2018; Roth, 2016; Sternson and\n\nRoth, 2014) approaches have been instrumental. Optogenetic tools can",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk10",
      "text": "reversibly perturb the activity of a target cell population under spatio- temporally restricted conditions by providing light stimulation of channelopsins. However, this approach is often highly invasive, espe- cially in mammals, since an optical fiber must be implanted in the brain (Matsubara and Yamashita, 2021; Poth et al., 2021; Pouliopoulos et al., 2022). Chemogenetic tools induce a reversible perturbation in the target cell population triggered by the binding of specific ligands to the",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk11",
      "text": "designated exogenous receptor. After the ligand is introduced into the body, the animal can be left to move freely, allowing remote manipu- lation of the target neuron activity. However, the onset and offset of the effect are difficult to control tightly (Poth et al., 2021; Sternson and",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk12",
      "text": "Roth, 2014).",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk13",
      "text": "To help circumvent some of the disadvantages of current chemo- genetic tools, we have recently developed a chemogenetic technology that uses Ionotropic Receptors (IRs) from the chemosensory system of the fruit fly Drosophila melanogaster (Fukabori et al., 2020; Iguchi et al., 2024). Here, we describe this system and compare to other chemo- genetic tools, then present its applications for analyzing the neural mechanisms controlling emotional memory (Fukabori et al., 2020) and drug-induced",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk14",
      "text": "behavior (Iguchi et al., 2024).",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk15",
      "text": "* Corresponding author.\n\n* Corresponding author.\n\nE-mail address: kazuto@fmu.ac.jp (K. Kobayashi).\n\nE-mail address: kazuto@fmu.ac.jp (K. Kobayashi).",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk16",
      "text": "https://doi.org/10.1016/j.neures.2024.11.003\n\nReceived 12 July 2024; Received in revised form 31 October 2024; Accepted 1 November 2024\n\nReceived 12 July 2024; Received in revised form 31 October 2024; Accepted 1 November 2024\n\nAvailable online 10 November 2024\n\n0168-0102/© 2024 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC license (http://creativecommons.org/licenses/by- nc/4.0/).\n\nY. Iguchi et al.\n\n2. Use of ligand-gated ion channels in chemogenetics",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk17",
      "text": "The most common class of chemogenetic tool are DREADDs (designer receptor exclusively activated by designer drugs) (Armbruster et al., 2007; Roth, 2016). These comprise a wide assortment of engi- neered G protein-coupled receptors (GPCRs) activated by distinct li- gands (Nakajima and Wess, 2012; Vardy et al., 2015) that have high affinity and low off-target effects (Chen et al., 2015; Nagai et al., 2020). However, DREADDs work by manipulating endogenous G protein-signaling in the target cells,",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk18",
      "text": "potentially leading to cellular re- sponses beyond experimenters’ expectations (Goossens et al., 2021; Pati et al., 2019; Van Steenbergen and Bareyre, 2021). Thus, there has long been a desire to develop chemogenetic approaches employing ligand-gated ion channels (LGICs), which do not require intracellular signaling pathways to manipulate neuronal activity (Atasoy and Stern-",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk19",
      "text": "son, 2018; Iguchi et al., 2024).",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk20",
      "text": "LGICs are generally classified into the Cys-loop, P2X, and ionotropic glutamate receptor (iGluR) families. Of these, Cys-loop receptor- dependent approaches have been well-studied, including both a neuronal silencing technology employing glutamate/ivermectin-gated chloride channels derived from C. elegans (Lerchner et al., 2007; Lin et al., 2011) and a neuronal activation technology employing an ivermectin-sensitive glycine receptor mutant endowed with cation permeability (Islam et al., 2016).",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk21",
      "text": "Moreover, chimeric receptors have been developed in which the ligand-binding domain of Cys-loop LGICs (pharmacologically-selective actuator modules) transplanted to a transmembrane ion pore domain of other members of Cys-loop LGICs are activated by synthetic ligands (pharmacologically-selective effector molecules) (Atasoy and Sternson, 2018; Magnus et al., 2011, 2019). Although an ATP-sensitive P2X2-based technology has been reported in invertebrates (Lima and Miesenb¨ock, 2005), P2X2 knockout",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk22",
      "text": "background is required for application in mammals (Lima and Miesenb¨ock, 2005; Zemelman et al., 2003). Until recently, chemogenetic tools using the iGluR family were unknown, and our interest in exploiting this family of receptors emerged through the discovery of a variant class of iGluR, as described in the next section.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk23",
      "text": "3. Insect IRs: a functionally-diverse chemosensory family of\n\niGluRs",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk24",
      "text": "As in all animals, insects detect chemical cues to extract information from the environment through olfaction and gustation (Benton, 2022; Montell, 2021; Shrestha and Lee, 2023). One important family of insect chemosensory receptors are the related Odorant Receptors (ORs) and Gustatory Receptors (GRs). Unlike most mammalian chemosensory re- ceptors, which are GPCRs (Fulton et al., 2024; Spehr and Munger, 2009), insect ORs and GRs are ligand-gated ion channels (Benton, 2015; Joseph and Carlson,",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk25",
      "text": "2015), and represent the founder members of the seven transmembrane domain ion channel superfamily (7TMICs) (Benton and Himmel, 2023; Himmel et al., 2023).",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk26",
      "text": "Insects have a second family of chemosensory receptors to detect odors and tastants, the Ionotropic Receptors (IRs), best-characterized in Drosophila melanogaster (Benton et al., 2009; Koh et al., 2014; Montell, 2021; S´anchez-Alca˜niz et al., 2018). IRs are derived from iGluRs, which are well-known for roles in mediating excitatory neurotransmission at synapses. However, IRs are distinguished by the large size of the repertoire in many insect species (for example, ~60 in D. melanogaster) and",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk27",
      "text": "their high divergence in sequence, particularly within the extra- cellular ligand-binding domain (Croset et al., 2010; Rytz et al., 2013). Analogous to iGluRs, IRs are thought to assemble into heterotetrameric complexes to form cation channels gated by chemical ligands (Abuin et al., 2011, 2019). The vast majority of IRs are expressed in specific populations of peripheral sensory neurons, where they localize to cili- ated sensory dendrites to detect specific environmental chemicals, mainly (but",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk28",
      "text": "not only) acids, aldehydes and amines (Silbering et al.,",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk29",
      "text": "2011; Yao et al., 2005). IR complexes are composed of tuning receptor\n\n57\n\nNeuroscience Research 214 (2025) 56-61",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk30",
      "text": "subunits, which define ligand specificity (Abuin et al., 2011; Ni, 2020; van Giesen and Garrity, 2017) together with 1–2 co-receptors, which appear to provide structural stability to the complex as well as contributing to forming the channel pore (Abuin et al., 2011, 2019). One of the best-characterized D. melanogaster IR complexes is that containing the IR8a co-receptor and the IR84a tuning receptor, which recognizes the food-derived odors phenylacetic acid and phenylacetaldehyde, and controls",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk31",
      "text": "male courtship behavior (Grosjean et al., 2011). The IR84a/IR8a complex can be functionally reconstituted both in other sensory neuron types in D. melanogaster and in Xenopus oocytes; in the + + latter, it is permeable mainly to monovalent cations (Na /K ), with only low Ca2+ permeability (Abuin et al., 2011).",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk32",
      "text": "4. IR-mediated neuronal activation (IRNA) of mammalian\n\nneurons",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk33",
      "text": "The autonomous function of IR84a/IR8a in heterologous cells led us to investigate whether these IRs could be used as a novel type of che- mogenetic tool for ligand-evoked activation of specific neuron types in the mammalian brain (Fukabori et al., 2020). To this end, we generated a transgenic mouse line expressing IR84a/IR8a in the catecholamine-containing cells. Patch clamp recording performed on acute brain slices of the locus coeruleus of these mice revealed excitatory responses of the",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk34",
      "text": "IR84a/IR8a-expressing locus coeruleus neurons to phenylacetic acid. Furthermore, through a multifaceted analyses, including in vivo extracellular recording of the locus coeruleus neurons, in vivo microdialysis for norepinephrine release in the terminal region (the anterior cingulate cortex and basolateral amygdala), and mea- surement of norepinephrine-related behavioral effects, we demon- strated that the IR84a/IR8a-expressing locus coeruleus neurons exhibit",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk35",
      "text": "a phenylacetic acid-dependent activation (Fig. 1).",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk36",
      "text": "A key factor for any chemogenetic system is minimizing activation of the designated exogenous receptor when a cognate ligand is not exter- nally applied. Previous studies have shown that a low level of phenyl- acetic acid is present in rodent brain and human cerebrospinal fluid (Durden and Boulton, 1982; Sandler et al., 1982). However, we found no significant differences in the basal firing frequency of the locus coeru- leus neurons and basal extracellular norepinephrine concentration in the",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk37",
      "text": "terminal region between the IR84a/IR8a-expressing mice and wild-type littermate controls (Fukabori et al., 2020). These observations indicate that endogenous phenylacetic acid has negligible effect on IR84a/IR8a activation.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk38",
      "text": "The mammalian brain is protected from exposure to harmful sub- stances circulating in the blood by the blood-brain barrier (Daneman and Prat, 2015), making it challenging to transfer efficiently phenyl- acetic acid from the peripheral bloodstream into the brain. In the above-mentioned in vivo experiments, phenylacetic acid was adminis- tered directly into the brains of mice through a surgically implanted\n\nCr acid se ry) se 4 > a Activating target cell populations",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk39",
      "text": "Fig. 1. Activation of mammalian neurons expressing IR84a/IR8a in the brain. Transgenic expression of IR84a/IR8a in a target neuronal population in the mammalian brain confers novel activation upon microinjection of the cognate\n\nligand, phenylacetic acid.\n\nY. Iguchi et al.\n\nNeuroscience Research 214 (2025) 56-61",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk40",
      "text": "cannula. To overcome this highly invasive delivery method, we sought to establish a prodrug strategy in which a chemically modified inert form of phenylacetic acid is peripherally injected into the bloodstream from which it could be transferred into the brain (Iguchi et al., 2024). We hypothesized that a methyl ester form of phenylacetic acid might readily crosses the blood-brain barrier through passive diffusion thanks to its lipophilic properties and then be converted to active phenylacetic",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk41",
      "text": "acid by esterase activity in the brain (Shukuri et al., 2011; Suzuki et al., 2004; Takashima-Hirano et al., 2010, Fig. 2). Indeed, phenylacetic acid methyl ester administered intravenously into the lateral tail vein in- creases central noradrenergic activity in IR84a/IR8a-expressing mice, as measured by an increase in the firing frequency of the locus coeruleus neurons and an elevation in norepinephrine release in the anterior cingulate cortex. These results indicate that the",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk42",
      "text": "IR84a/IR8a-expressing cells in the mammalian brain can be remotely activated by peripheral administration of phenylacetic acid methyl ester and support a prodrug",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk43",
      "text": "strategy for chemogenetic approaches.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk44",
      "text": "Finally, we employed the striatum of rats as a model to examine whether IRNA could be applied to non-catecholamine-containing cells in other mammalian species (Iguchi et al., 2024). The striatum controls behavior through the activity distributed across two subpopulations of GABAergic spiny projection neurons (SPNs), which express distinct dopamine receptor subtypes that have opposing responses to dopamine: direct SPNs (dSPNs) express type 1 receptors projecting to the substantia nigra pars",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk45",
      "text": "reticulata and entopeduncular nucleus; indirect SPN (iSPNs) express type 2 receptors projecting to the external segment of the globus pallidus (Alexander and Crutcher, 1990; Gerfen and Bolam, 2016). We employed Drd2-Cre transgenic rats that express the Cre recombinase predominantly in iSPNs (Nonomura et al., 2018). A lentiviral vector pseudotyped with vesicular stomatitis virus glycoprotein (VSV-G, Kato et al., 2007) was constructed to express IR84a and IR8a (gene sizes of 1851 bp and 2760 bp,",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk46",
      "text": "respectively) in a Cre-dependent manner (the flip-excision switch system: FLEX, Kato et al., 2007; Matsushita et al., 2023) and then microinjected into the dorsal striatum of the Drd2-Cre rats. Immunohistochemistry found an efficient and specific expression of IR84a and IR8a in the striatal iSPNs, and patch-clamp recordings per- formed on acute brain slices of the vector-treated striatum revealed excitatory responses of the IR84a/IR8a-expressing iSPNs to phenylacetic",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk47",
      "text": "acid.\n\n5. Application of IRNA to the analysis of the neural mechanisms\n\nof behavior",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk48",
      "text": "We successfully developed IRNA as a novel chemogenetic approach to stimulate neuronal types of interest, laying the foundation to study open questions in mammalian neuroscience. Here, we present two ex- amples in which IRNA-based gain-of-function perturbation was applied to the central noradrenergic system and emotional memory processing (Fukabori et al., 2020), and a specific type of striatal projection neurons and drug-induced movement (Iguchi et al., 2024).",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk49",
      "text": "The roles of the central noradrenergic system in the acquisition, consolidation, and reconsolidation of the memory conditioned to a cue that signals the occurrence of a biologically significant event (Pavlovian conditioned stimulus: CS) have been suggested by many studies (Ferry et al., 2015; LaLumiere et al., 2003; Villain et al., 2016). However, whether the noradrenergic system plays a role in the retrieval process was unclear (Miranda et al., 2007; Murchison et al., 2004). We sought to use",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk50",
      "text": "IRNA to determine if the retrieval of the Pavlovian aversive memory conditioned to a flavor CS is affected by activating the noradrenergic system originating from the locus coeruleus. Mice were allowed to intake a sucrose solution as CS and then received an intraperitoneal injection of lithium chloride, which induced gastric illness (Garcia et al., 1955). Mice usually like sucrose, but they acquired an aversion to the CS solution through the conditioning, resulting in rejection responses to the",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk51",
      "text": "CS presented forcibly and intraorally during testing (Yasoshima and Shimura, 2017). We found that IR84a/IR8a-expressing mice showed a reduced latency for the rejection responses to the CS when they were microinjected with phenylacetic acid into the bilateral locus coeruleus immediately before the CS test compared to control conditions (Fukabori et al., 2020). This finding suggests that activation of the norepinephrine cells in the locus coeruleus accelerated the retrieval of the aversive memory",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk52",
      "text": "associated with the CS. Furthermore, adrenergic receptor antagonism in the basolateral amygdala blocked the facilitation of the taste aversion memory retrieval (Fukabori et al., 2020), suggest- ing that the locus coeruleus-basolateral amygdala noradrenergic",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk53",
      "text": "pathway mediates the enhanced aversive memory retrieval.\n\nDisorders of contraversive movement by the lesion in each brain hemisphere have been extensively studied in neurological patients (Heilman et al., 1985; Karnath et al., 2002). Unilateral lesions of the\n\nnigro-striatal dopaminergic system cause profound asymmetries in\n\n| IR84a ree Phenylacetic acid methyl ester OCHs Or Sip oy —— Brain Ay, Activating target cell populations Phenylacetic or’ & ‘ esterase cae & IR84a IR8a",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk54",
      "text": "Fig. 2. A working model of the prodrug strategy for IRNA. The lipophilic phenylacetic acid methyl ester, a chemically-modified inert form of phenylacetic acid, is administered peripherally, readily crosses the blood-brain barrier through passive diffusion, and then converted to the active phenylacetic acid ligand by esterase\n\nactivity in the brain.\n\n58\n\nY. Iguchi et al.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk55",
      "text": "motor performance (Bj¨orklund and Dunnett, 2019). In rodents, this manifests as an asymmetrical body posture, sensorimotor disorientation, and impaired use of the contralateral forelimb, which are widely used as an experimental model to mimic the loss of dopamine neurons seen in Parkinson’s disease (Dunnett and Torres, 2011). More recently, the role of the two basal ganglia pathways originating in dSPNs and iSPNs in behavioral phenotypes of the rodent model has been investigated. For instance,",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk56",
      "text": "several studies reported that unilateral activations of striatal iSPNs by optogenetics (Grimm et al., 2021; Kravitz et al., 2010; Lee et al., 2016) or DREADD-based chemogenetics (Alcacer et al., 2017) induce spontaneous ipsiversive rotations in mice, suggesting that iSPNs play an inhibitory role in spontaneous motor control. By contrast, in the dopaminergic drug-induced condition, selective ablation of the iSPNs in the unilateral striatum generates an ipsiversive rotation (Sano et al., 2003),",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk57",
      "text": "implying that iSPNs facilitate the motor activation induced by drug administration. To further test the possibility, we induced IR84a/IR8a expression in the iSPNs of the unilateral striatum using the FLEX viral vector in combination with the Drd2-Cre rats described above. We then injected phenylacetic acid methyl ester intraperitoneally to induce unilateral activation of the iSPNs and examined whether a systemic cocaine administration would bias the rotation behavior in a specific direction",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk58",
      "text": "(Iguchi et al., 2024). The results showed that animals exhibit more contraversive rotation to the unilateral striatum in which the iSPNs are activated, confirming the role of iSPNs in facilitating drug-induced motor activation.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk59",
      "text": "6. Conclusions and perspectives",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk60",
      "text": "We have devised a new LGIC-based chemogenetic technology, IRNA, which uses iGluR-related IRs from insects (Benton et al., 2009) to induce ligand-evoked activation in target cell populations in the mammalian brain (Fukabori et al., 2020; Iguchi et al., 2024). We show how IRNA can be used to activate several types of neurons in mice and rats, empha- sizing the likely general applicability of this approach. We also devel- oped a prodrug system that allows remote, peripheral administration of a",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk61",
      "text": "ligand precursor, which is transferred to the central nervous system to",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk62",
      "text": "activate the IR-expressing target cells.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk63",
      "text": "As with any new method, further technical improvements and de- velopments are required. Phenylacetic acid activates the IR84a/IR8a complex expressed in the target neurons in the mammalian brain at a higher concentration range than the DREADDs ligands, leading to concern about non-specific effects. However, we found no significant change in the norepinephrine release when phenylacetic acid was microinjected into the locus coeruleus of the control animals at the concentrations that induced a",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk64",
      "text": "significant behavioral effect in the IR84a/ IR8a-expressing mice (Fukabori et al., 2020), suggesting that a single dose of phenylacetic acid does not impair normal cellular function, at least in the short-term. The possibility of cytotoxic effects of phenyl- acetic acid by repeated administration has not yet been examined. This chemical also has a unique odor, so that it is necessary to establish appropriate control conditions for behavioral experiments. Identifying a more efficient (and",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk65",
      "text": "possibly less volatile) actuator for the IR84a/IR8a complex that overcomes these issues should enhance the specificity and",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk66",
      "text": "usefulness of IRNA.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk67",
      "text": "Despite these caveats, successful application of IRNA to the analysis of the neural mechanisms controlling emotional memory and drug- induced behavior provides new biological insights: first, that the locus coeruleus–basolateral amygdala noradrenergic pathway could be a therapeutic target in psychiatric disorders with abnormal control of aversive memory, and second, that the function of iSPNs in the behav- ioral control change between spontaneous and drug-induced conditions. Thus, IRNA can",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk68",
      "text": "stimulate new research and clarifying previously unre- solved issues. IRNA might also form the basis for future chemogenetic- based treatment of psychiatric/neurological disorders (Sternson and Bleakman, 2020; Urban and Roth, 2015; Walker and Kullmann, 2020).",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk69",
      "text": "We also envisage creating variations of IRNA beyond the IR84a/\n\n59\n\nNeuroscience Research 214 (2025) 56-61",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk70",
      "text": "IR8a-phenylacetic acid receptor-ligand pairing. For example, a com- plex of IR75a and IR8a is activated by propionic acid, rather than phe- nylacetic acid (Abuin et al., 2011; Benton et al., 2009). Here, the potential is enormous: hundreds, if not thousands, functionally-distinct IRs are encoded in insect genomes (Croset et al., 2010; Rytz et al., 2013), any of which are theoretically exploitable for artificial activation of mammalian neurons. Increased understanding of the molecular basis of",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk71",
      "text": "ligand binding specificity of IRs (e.g., Prieto-Go- dino et al., 2021) could also enable custom-design of IRs with novel ligand-recognition properties. Similarly, insect OR and GR ligand-gated ion channels, which are arguably even better understood mechanisti- cally than IRs (e.g. Butterwick et al., 2018; del M´armol et al., 2021; Frank et al., 2024; Gomes et al., 2024; Ma et al., 2024), could serve as the basis for other chemogenetic tools. By expressing different ion channels in distinct",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk72",
      "text": "neuronal types under cell-type specific promoters – or by combining IRNA with DREADDs – it is conceivable to indepen- dently control the activity of two or more neuron populations with different ligands. of",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk73",
      "text": "CRediT authorship contribution statement\n\nYoshio Iguchi: Conceptualization, Funding acquisition, Writing – original draft, Writing – review & editing. Richard Benton: Conceptu- alization, Funding acquisition, Writing – review & editing. Kazuto Kobayashi: Conceptualization, Funding acquisition, Writing – original draft, Writing – review & editing.\n\nDeclaration of Competing Interest\n\nThe authors declare no competing interests.\n\nAcknowledgments",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk74",
      "text": "This study was supported by Grants-in-Aid for Scientific Research on Innovative Areas \"Adaptive Circuit Shift\" (Ministry of Education, Cul- ture, Sports, Science and Technology: MEXT, Japan, 26112002 to K.K.), for Transformative Research Areas \"Adaptive Circuit Census\" (MEXT, 21H05244 to K.K.), for Challenging Research (Exploratory, Japan So- ciety for the Promotion of Science: JSPS, 22K19363 to K.K.), for Scien- tific Research (C, JSPS, 24K06623 to Y.I.); by Takeda Science Foundation (2020 to",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk75",
      "text": "Y.I. and 2021 to K.K.); by Sekisui Chemical Grant Program for Research on Manufacturing Based on Learning from Nature (2023 to Y.I.); by European Research Council Consolidator and Advanced Grants (Grant 615094 and 533548 to R.B.); by a Human Frontier Science Program Young Investigator Award (Grant RGY0073/ 2011 to R.B.); by the Swiss National Science Foundation Nano-Tera",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk76",
      "text": "Envirobot Project (20NA21_143082 to R.B.).",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk77",
      "text": "References\n\nReferences\n\nAbuin, L., Bargeton, B., Ulbrich, M.H., Isacoff, E.Y., Kellenberger, S., Benton, R., 2011. Functional architecture of olfactory ionotropic glutamate receptors. Neuron 69, 44–60. https://doi.org/10.1016/j.neuron.2010.11.042.\n\nAbuin, L., Prieto-Godino, L.L., Pan, H., Gutierrez, C., Huang, L., Jin, R., Benton, R., 2019. In vivo assembly and trafficking of olfactory ionotropic receptors. BMC Biol. 17, 34.\n\nhttps://doi.org/10.1186/s12915-019-0651-7.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk78",
      "text": "Alcacer, C., Andreoli, L., Sebastianutto, I., Jakobsson, J., Fieblinger, T., Cenci, M.A., 2017. Chemogenetic stimulation of striatal projection neurons modulates responses to Parkinson’s disease therapy. J. Clin. Invest. 127, 720–734. https://doi.org/ 10.1172/JCI90132.\n\nAlexander, G.E., Crutcher, M.D., 1990. Functional architecture of basal ganglia circuits: neural substrates of parallel processing. Trends Neurosci. 13, 266–271. https://doi. org/10.1016/0166-2236(90)90107-l.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk79",
      "text": "Armbruster, B.N., Li, X., Pausch, M.H., Herlitze, S., Roth, B.L., 2007. Evolving the lock to fit the key to create a family of G protein-coupled receptors potently activated by an inert ligand. Proc. Natl. Acad. Sci. U. S. A. 104, 5163–5168. https://doi.org/ 10.1073/pnas.0700293104.\n\nAtasoy, D., Sternson, S.M., 2018. Chemogenetic tools for causal cellular and neuronal biology. Physiol. Rev. 98, 391–418. https://doi.org/10.1152/physrev.00009.2017.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk80",
      "text": "Benton, R., 2015. Multigene family evolution: perspectives from insect chemoreceptors. Trends Ecol. Evol. 30, 590–600. https://doi.org/10.1016/j.tree.2015.07.009.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk81",
      "text": "Y. Iguchi et al.\n\nBenton, R., 2022. Drosophila olfaction: past, present and future. Proc. Biol. Sci. 289, 20222054. https://doi.org/10.1098/rspb.2022.2054.\n\nBenton, R., Himmel, H.J., 2023. Structural screens identify candidate human homologs of insect chemoreceptors and cryptic Drosophila gustatory receptor-like proteins. Elife 12, e85537. https://doi.org/10.7554/eLife.85537.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk82",
      "text": "Benton, R., Vannice, K.S., Gomez-Diaz, C., Vosshall, L.B., 2009. Variant ionotropic glutamate receptors as chemosensory receptors in Drosophila. Cell 136, 149–162. https://doi.org/10.1016/j.cell.2008.12.001.\n\nBj¨orklund, A., Dunnett, S.B., 2019. The amphetamine induced rotation test: a re- assessment of its use as a tool to monitor motor impairment and functional recovery in rodent models of Parkinson’s disease. J. Park. Dis. 9, 17–29. https://doi.org/\n\n10.3233/JPD-181525.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk83",
      "text": "Butterwick, J.A., del M´armol, J., Kim, K.H., Kahlson, M.A., Rogow, J.A., Walz, T., Ruta, V., 2018. Cryo-EM structure of the insect olfactory receptor Orco. Nature 560, 447–452. https://doi.org/10.1038/s41586-018-0420-8.\n\nChen, X., Choo, H., Huang, X.P., Yang, X., Stone, O., Roth, B.L., Jin, J., 2015. The first structure-activity relationship studies for designer receptors exclusively activated by designer drugs. ACS Chem. Neurosci. 6, 476–484. https://doi.org/10.1021/\n\ncn500325v.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk84",
      "text": "Croset, V., Rytz, R., Cummins, S.F., Budd, A., Brawand, D., Kaessmann, H., Gibson, T.J., Benton, R., 2010. Ancient protostome origin of chemosensory ionotropic glutamate receptors and the evolution of insect taste and olfaction. PLoS Genet. 6, e1001064. https://doi.org/10.1371/journal.pgen.1001064.\n\nDaneman, R., Prat, A., 2015. The blood-brain barrier. Cold Spring Harb. Perspect. Biol. 7, a020412. https://doi.org/10.1101/cshperspect.a020412.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk85",
      "text": "Deisseroth, K., 2015. Optogenetics: 10 years of microbial opsins in neuroscience. Nat. Neurosci. 18, 1213–1225. https://doi.org/10.1038/nn.4091.\n\nDeisseroth, K., 2021. From microbial membrane proteins to the mysteries of emotion. Cell 184, 5279–5285. https://doi.org/10.1016/j.cell.2021.08.018.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk86",
      "text": "Dunnett, S.B., Torres, E.E., 2011. EM Rotation in the 6-OHDA lesioned rat. In: Lane, E.L., Dunnett, S.B. (Eds.), Animal Models of Movement Disorders: Volume I. Neuromethods, 61. Springer/Humana, New York, pp. 299–315.\n\nDurden, D.A., Boulton, A.A., 1982. Identification and distribution of phenylacetic acid in the brain of the rat. J. Neurochem. 38, 1532–1536. https://doi.org/10.1111/j.1471- 4159.1982.tb06629.x.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk87",
      "text": "Ferry, B., Parrot, S., Marien, M., Lazarus, C., Cassel, J.C., McGaugh, J.L., 2015. Noradrenergic influences in the basolateral amygdala on inhibitory avoidance memory are mediated by an action on α2-adrenoceptors. Psychoneuroendocrinolgy 51, 68–79. https://doi.org/10.1016/j.psyneuen.2014.09.010.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk88",
      "text": "Frank, H.M., Walujkar, S., Walsh, R.M., Jr, Laursen, W.J., Theobald, D.L., Garrity, P.A., Gaudet, R., 2024. Structural basis of ligand specificity and channel activation in an insect gustatory receptor. Cell Rep. 43, 114035. https://doi.org/10.1016/j.\n\ncelrep.2024.114035.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk89",
      "text": "Fukabori, R., Iguchi, Y., Kato, S., Takahashi, K., Eifuku, S., Tsuji, S., Hazama, A., Uchigashima, M., Watanabe, M., Mizuma, H., Cui, Y., Onoe, H., Hikishima, K., Yasoshima, Y., Osanai, M., Inagaki, R., Fukunaga, K., Nishijo, T., Momiyama, T., Benton, R., Kobayashi, K., 2020. Enhanced retrieval of taste associative memory by chemogenetic activation of locus coeruleus norepinephrine neurons. J. Neurosci. 40, 8367–8385. https://doi.org/10.1523/JNEUROSCI.1720-20.2020.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk90",
      "text": "Fulton, K.A., Zimmerman, D., Samuel, A., Vogt, K., Datta, S.R., 2024. Common principles for odour coding across vertebrates and invertebrates. Nat. Rev. Neurosci. 25, 453–472. https://doi.org/10.1038/s41583-024-00822-0.\n\nGarcia, J., Kimeldorf, D.J., Koelling, R.A., 1955. Conditioned aversion to saccharin resulting from exposure to gamma radiation. Science 122, 157–158. https://doi.org/ 10.1126/science.122.3160.157.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk91",
      "text": "Gerfen, C.R., Bolam, J.P., 2016. Chapter 1 - The Neuroanatomical organization of the basal ganglia. In: Steiner, H., Tseng, K.Y. (Eds.), Handbook of Behavioral Neuroscience, 24. Elsevier, pp. 3–32.\n\nvan Giesen, L., Garrity, P.A., 2017. More than meets the IR: the expanding roles of variant Ionotropic Glutamate Receptors in sensing odor, taste, temperature and\n\nmoisture. F1000Res 6, 1753. https://doi.org/10.12688/f1000research.12013.1.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk92",
      "text": "Gomes, J.V., Singh-Bhagania, S., Cenci, M., Cordon, C.C., Singh, M., Butterwick, J.A., 2024. The molecular basis of sugar detection by an insect taste receptor. Nature 629, 228–234. https://doi.org/10.1038/s41586-024-07255-w.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk93",
      "text": "Goossens, M.G., Larsen, L.E., Vergaelen, M., Wadman, W., Van den Haute, C., Brackx, W., Proesmans, S., Desloovere, J., Christiaen, E., Craey, E., Vanhove, C., Vonck, K., Boon, P., Raedt, R., 2021. Level of hM4D(Gi) DREADD expression determines inhibitory and neurotoxic effects in the hippocampus. eNeuro 8. https://doi.org/\n\n10.1523/ENEURO.0105-21.2021.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk94",
      "text": "Grimm, C., Fr¨assle, S., Steger, C., von Ziegler, L., Sturman, O., Shemesh, N., Peleg- Raibstein, D., Burdakov, D., Bohacek, J., Stephan, K.E., Razansky, D., Wenderoth, N., Zerbi, V., 2021. Optogenetic activation of striatal D1R and D2R cells differentially engages downstream connected areas beyond the basal ganglia. Cell Rep. 37, 110161. https://doi.org/10.1016/j.celrep.2021.110161.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk95",
      "text": "Grosjean, Y., Rytz, R., Farine, J.P., Abuin, L., Cortot, J., Jefferis, G.S., Benton, R., 2011. R An olfactory receptor for food-derived odours promotes male courtship in Drosophila. Nature 478, 236–240. https://doi.org/10.1038/nature10428.\n\nHeilman, K.M., Bowers, D., Coslett, H.B., Whelan, H., Watson, R.T., 1985. Directional hypokinesia: prolonged reaction times for leftward movements in patients with right hemisphere lesions and neglect. Neurology 35, 855–859. https://doi.org/10.1212/",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk96",
      "text": "wnl.35.6.855.\n\nHimmel, N.J., Moi, D., Benton, R., 2023. Remote homolog detection places insect chemoreceptors in a cryptic protein superfamily spanning the tree of life. Curr. Biol. 33, 5023–5033. https://doi.org/10.1016/j.cub.2023.10.008.\n\nIguchi, Y., Fukabori, R., Kato, S., Takahashi, K., Eifuku, S., Maejima, Y., Shimomura, K., Mizuma, H., Mawatari, A., Doi, H., Cui, Y., Onoe, H., Hikishima, K., Osanai, M.,\n\n60\n\nNeuroscience Research 214 (2025) 56-61",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk97",
      "text": "Nishijo, T., Momiyama, T., Benton, R., Kobayashi, K., 2024. Chemogenetic activation of mammalian brain neurons expressing insect Ionotropic Receptors by systemic ligand precursor administration. Commun. Biol. 7, 547. https://doi.org/10.1038/ s42003-024-06223-4.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk98",
      "text": "Islam, R., Keramidas, A., Xu, L., Durisic, N., Sah, P., Lynch, J.W., 2016. Ivermectin- activated, cation-permeable glycine receptors for the chemogenetic control of neuronal excitation. ACS Chem. Neurosci. 7, 1647–1657. https://doi.org/10.1021/\n\nacschemneuro.6b00168.\n\nJoseph, R.M., Carlson, J.R., 2015. Drosophila chemoreceptors: a molecular interface between the chemical world and the brain. Trends Genet. 31, 683–695. https://doi. org/10.1016/j.tig.2015.09.005.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk99",
      "text": "Karnath, H.O., Himmelbach, M., Rorden, C., 2002. The subcortical anatomy of human spatial neglect: putamen, caudate nucleus and pulvinar. Brain 125, 350–360. https://doi.org/10.1093/brain/awf032.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk100",
      "text": "Kato, S., Inoue, K., Kobayashi, K., Yasoshima, Y., Miyachi, S., Inoue, S., Hanawa, H., Shimada, T., Takada, M., Kobayashi, K., 2007. Efficient gene transfer via retrograde transport in rodent and primate brains using a human immunodeficiency virus type 1-based vector pseudotyped with rabies virus glycoprotein. Hum. Gene Ther. 18, 1141–1151. https://doi.org/10.1089/hum.2007.082.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk101",
      "text": "Kim, C.K., Adhikari, A., Deisseroth, K., 2017. Integration of optogenetics with complementary methodologies in systems neuroscience. Nat. Rev. Neurosci. 18, 222–235. https://doi.org/10.1038/nrn.2017.15.\n\nKoh, T., He, Z., Gorur-Shandilya, S., Menuz, K., Larter, N.K., Stewart, S., Carlson, J.R., 2014. The Drosophila IR20a clade of ionotropic receptors are candidate taste and pheromone receptors. Neuron 83, 850–865. https://doi.org/10.1016/j.\n\nneuron.2014.07.012.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk102",
      "text": "Kravitz, A.V., Freeze, B.S., Parker, P.R., Kay, K., Thwin, M.T., Deisseroth, K., Kreitzer, A. C., 2010. Regulation of parkinsonian motor behaviours by optogenetic control of basal ganglia circuitry. Nature 466, 622–626. https://doi.org/10.1038/\n\nnature09159.\n\nLaLumiere, R.T., Buen, T.V., McGaugh, J.L., 2003. Post-training intra-basolateral amygdala infusions of norepinephrine enhance consolidation of memory for contextual fear conditioning. J. Neurosci. 23, 6754–6758. https://doi.org/10.1523/",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk103",
      "text": "JNEUROSCI.23-17-06754.2003.\n\nLee, H.J., Weitz, A.J., Bernal-Casas, D., Duffy, B.A., Choy, M., Kravitz, A.V., Kreitzer, A. C., Lee, J.H., 2016. Activation of direct and indirect pathway medium spiny neurons drives distinct brain-wide responses. Neuron 91, 412–424. https://doi.org/10.1016/\n\nj.neuron.2016.06.010.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk104",
      "text": "Lerchner, W., Xiao, C., Nashmi, R., Slimko, E.M., van Trigt, L., Lester, H.A., Anderson, D. J., 2007. Reversible silencing of neuronal excitability in behaving mice by a genetically targeted, ivermectin-gated Cl- channel. Neuron 54, 35–49. https://doi. org/10.1016/j.neuron.2007.02.030.\n\nLima, S.Q., Miesenb¨ock, G., 2005. Remote control of behavior through genetically targeted photostimulation of neurons. Cell 121, 141–152. https://doi.org/10.1016/\n\nj.cell.2005.02.004.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk105",
      "text": "Lin, D., Boyle, M.P., Dollar, P., Lee, H., Lein, E.S., Perona, P., Anderson, D.J., 2011. Functional identification of an aggression locus in the mouse hypothalamus. Nature 470, 221–226. https://doi.org/10.1038/nature09736.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk106",
      "text": "Ma, D., Hu, M., Yang, X., Liu, Q., Ye, F., Cai, W., Wang, Y., Xu, X., Chang, S., Wang, R., Yang, W., Ye, S., Su, N., Fan, M., Xu, H., Guo, J., 2024. Structural basis for sugar perception by Drosophila gustatory receptors. Science 383, eadj2609. https://doi. org/10.1126/science.adj2609.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk107",
      "text": "Magnus, C.J., Lee, P.H., Atasoy, D., Su, H.H., Looger, L.L., Sternson, S.M., 2011. Chemical and genetic engineering of selective ion channel-ligand interactions. Science 333, 1292–1296. https://doi.org/10.1126/science.1206606.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk108",
      "text": "Magnus, C.J., Lee, P.H., Bonaventura, J., Zemla, R., Gomez, J.L., Ramirez, M.H., Hu, X., Galvan, A., Basu, J., Michaelides, M., Sternson, S.M., 2019. Ultrapotent chemogenetics for research and potential clinical applications. Science 364, eaav5282. https://doi.org/10.1126/science.aav5282.\n\ndel M´armol, J., Yedlin, M.A., Ruta, V., 2021. The structural basis of odorant recognition in insect olfactory receptors. Nature 597, 126–131. https://doi.org/10.1038/\n\ns41586-021-03794-8.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk109",
      "text": "Marx, V., 2021. 2021. Method of the Year: spatially resolved transcriptomics. Nat. Methods 18, 9–14. https://doi.org/10.1038/s41592-020-01033-y.\n\nMatsubara, T., Yamashita, T., 2021. Remote optogenetics using up/down-conversion phosphors. Front. Mol. Biosci. 8, 771717. https://doi.org/10.3389/\n\nfmolb.2021.771717.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk110",
      "text": "Matsushita, N., Kato, S., Nishizawa, K., Sugawara, M., Takeuchi, K., Miyasaka, Y., Mashimo, T., Kobayashi, K., 2023. Highly selective transgene expression through the flip-excision switch system by using a unilateral spacer sequence. Cell Rep. Methods 3, 100393. https://doi.org/10.1016/j.crmeth.2022.100393.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk111",
      "text": "Miranda, M.A., Ferry, B., Ferreira, G., 2007. Basolateral amygdala noradrenergic activity is involved in the acquisition of conditioned odor aversion in the rat. Neurobiol. Learn. Mem. 88, 260–263. https://doi.org/10.1016/j.nlm.2007.04.008.\n\nMontell, C., 2021. Drosophila sensory receptors-a set of molecular Swiss Army Knives. Genetics 217, 1–34. https://doi.org/10.1093/genetics/iyaa011.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk112",
      "text": "Murchison, C.F., Zhang, X.Y., Zhang, W.P., Ouyang, M., Lee, A., Thomas, S.A., 2004. A distinct role for norepinephrine in memory retrieval. Cell 117, 131–143. https://\n\ndoi.org/10.1016/s0092-8674(04)00259-4.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk113",
      "text": "Nagai, Y., Miyakawa, N., Takuwa, H., Hori, Y., Oyama, K., Ji, B., Takahashi, M., Huang, X.P., Slocum, S.T., DiBerto, J.F., Xiong, Y., Urushihata, T., Hirabayashi, T., Fujimoto, A., Mimura, K., English, J.G., Liu, J., Inoue, K.I., Kumata, K., Sek, C., Ono, M., Shimojo, M., Zhang, M.R., Tomita, Y., Nakahara, J., Suhara, T., Takada, M., Higuchi, M., Jin, J., Roth, B.L., Minamimoto, T., 2020. Deschloroclozapine, a potent and selective chemogenetic actuator enables rapid neuronal and behavioral",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk114",
      "text": "Y. Iguchi et al.\n\nmodulations in mice and monkeys. Nat. Neurosci. 23, 1157–1167. https://doi.org/ 10.1038/s41593-020-0661-3.\n\nNakajima, K., Wess, J., 2012. Design and functional characterization of a novel, arrestin- biased designer G protein-coupled receptor. Mol. Pharmacol. 82, 575–582. https:// doi.org/10.1124/mol.112.080358.\n\nNi, L., 2020. The structure and function of ionotropic receptors in Drosophila. Front. Mol. Neurosci. 13, 638839. https://doi.org/10.3389/fnmol.2020.638839.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk115",
      "text": "Nonomura, S., Nishizawa, K., Sakai, Y., Kawaguchi, Y., Kato, S., Uchigashima, M., Watanabe, M., Yamanaka, K., Enomoto, K., Chiken, S., Sano, H., Soma, S., Yoshida, J., Samejima, K., Ogawa, M., Kobayashi, K., Nambu, A., Isomura, Y., Kimura, M., 2018. Monitoring and updating of action selection for goal-directed behavior through the striatal direct and indirect pathways. Neuron 99, 1302–1314. e5. https://doi.org/10.1016/j.neuron.2018.08.002.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk116",
      "text": "Ofengeim, D., Giagtzoglou, N., Huh, D., Zou, C., Yuan, J., 2017. J Single-cell RNA sequencing: unraveling the brain one cell at a time. Trends Mol. Med. 23, 563–576. https://doi.org/10.1016/j.molmed.2017.04.006.\n\nPati, S., Salvi, S.S., Kallianpur, M., Vaidya, B., Banerjee, A., Maiti, S., Clement, J.P., Vaidya, V.A., 2019. Chemogenetic activation of excitatory neurons alters hippocampal neurotransmission in a dose-dependent manner. eNeuro 6. https://doi. org/10.1523/ENEURO.0124-19.2019.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk117",
      "text": "Poth, K.M., Texakalidis, P., Boulis, N.M., 2021. Chemogenetics: beyond lesions and electrodes. Neurosurgery 89, 185–195. https://doi.org/10.1093/neuros/nyab147.\n\nPouliopoulos, A.N., Murillo, M.F., Noel, R.L., Batts, A.J., Ji, R., Kwon, N., Yu, H., Tong, C. K., Gelinas, J.N., Araghy, D.K., Hussaini, S.A., Konofagou, E.E., 2022. Non-invasive optogenetics with ultrasound-mediated gene delivery and red-light excitation. Brain Stimul. 15, 927–941. https://doi.org/10.1016/j.brs.2022.06.007.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk118",
      "text": "Prieto-Godino, L.L., Schmidt, H.R., Benton, R., 2021. Molecular reconstruction of recurrent evolutionary switching in olfactory receptor specificity (DOI:). Elife 10, e69732. https://doi.org/10.7554/eLife.69732.\n\nRoth, B.L., 2016. DREADDs for neuroscientists. Neuron 89, 683–694. https://doi.org/ 10.1016/j.neuron.2016.01.040.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk119",
      "text": "Rytz, R., Croset, V., Benton, R., 2013. Ionotropic receptors (IRs): chemosensory ionotropic glutamate receptors in Drosophila and beyond. Insect Biochem. Mol. Biol. 43, 888–897. https://doi.org/10.1016/j.ibmb.2013.02.007.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk120",
      "text": "S´anchez-Alca˜niz, J.A., Silbering, A.F., Croset, V., Zappia, G., Sivasubramaniam, A.K., Abuin, L., Sahai, S.Y., Münch, D., Steck, K., Auer, T.O., Cruchet, S., Neagu-Maier, G. L., Sprecher, S.G., Ribeiro, C., Yapici, N., Benton, R., 2018. An expression atlas of variant ionotropic glutamate receptors identifies a molecular basis of carbonation sensing. Nat. Commun. 9, 4252. https://doi.org/10.1038/s41467-018-06453-1.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk121",
      "text": "Sandler, M., Ruthven, C.R., Goodwin, B.L., Lees, A., Stern, G.M., 1982. Phenylacetic acid in human body fluids: high correlation between plasma and cerebrospinal fluid concentration values. J. Neurol. Neurosurg. Psychiatry 45, 366–368. https://doi.\n\norg/10.1136/jnnp.45.4.366.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk122",
      "text": "Sano, H., Yasoshima, Y., Matsushita, N., Kaneko, T., Kohno, K., Pastan, I., Kobayashi, K., 2003. Conditional ablation of striatal neuronal types containing dopamine D2 receptor disturbs coordination of basal ganglia function. J. Neurosci. 23, 9078–9088.\n\nhttps://doi.org/10.1523/JNEUROSCI.23-27-09078.2003.\n\nShrestha, B., Lee, Y., 2023. Molecular sensors in the taste system of Drosophila. Genes Genom. 45, 693–707. https://doi.org/10.1007/s13258-023-01370-0.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk123",
      "text": "Shukuri, M., Takashima-Hirano, M., Tokuda, K., Takashima, T., Matsumura, K., Inoue, O., Doi, H., Suzuki, M., Watanabe, Y., Onoe, H., 2011. In vivo expression of cyclooxygenase-1 in activated microglia and macrophages during neuroinflammation visualized by PET with 11C-ketoprofen methyl ester. J. Nucl.\n\nMed. 52, 1094–1101. https://doi.org/10.2967/jnumed.110.084046.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk124",
      "text": "Silbering, A.F., Rytz, R., Grosjean, Y., Abuin, L., Ramdya, P., Jefferis, G.S., Benton, R., 2011. R Complementary function and integrated wiring of the evolutionarily distinct\n\n61\n\nNeuroscience Research 214 (2025) 56-61\n\nDrosophila olfactory subsystems. J. Neurosci. 31, 13357–13375. https://doi.org/ 10.1523/JNEUROSCI.2360-11.2011.\n\nSpehr, M., Munger, S.D., 2009. Olfactory receptors: G protein-coupled receptors and beyond. J. Neurochem. 109, 1570–1583. https://doi.org/10.1111/j.1471-",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk125",
      "text": "4159.2009.06085.x.\n\nSternson, S.M., Bleakman, D., 2020. Chemogenetics: drug-controlled gene therapies for neural circuit disorders. Cell Gene Ther. Insights 6, 1079–1094. https://doi.org/\n\n10.18609/cgti.2020.112.\n\nSternson, S.M., Roth, B.L., 2014. Chemogenetic tools to interrogate brain functions. Annu. Rev. Neurosci. 37, 387–407. https://doi.org/10.1146/annurev-neuro- 071013-014048.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk126",
      "text": "Suzuki, M., Doi, H., Hosoya, T., Långstr¨om, B., Watanabe, Y., 2004. Rapid methylation on carbon frameworks leading to the synthesis of a PET tracer capable of imaging a novel CNS-type prostacyclin receptor in living human brain. TrAC Trends Anal. Chem. 23, 595–607. https://doi.org/10.1016/j.trac.2004.06.003.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk127",
      "text": "Takashima-Hirano, M., Shukuri, M., Takashima, T., Goto, M., Wada, Y., Watanabe, Y., Onoe, H., Doi, H., Suzuki, M., 2010. General method for the 11C-labeling of 2-aryl- propionic acids and their esters: construction of a PET tracer library for a study of biological events involved in COXs expression. Chemistry 16, 4250–4258. https://\n\ndoi.org/10.1002/chem.200903044.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk128",
      "text": "Tonegawa, S., Liu, X., Ramirez, S., Redondo, R., 2015. Memory engram cells have come of age. Neuron 87, 918–931. https://doi.org/10.1016/j.neuron.2015.08.002.\n\nUrban, D.J., Roth, B.L., 2015. DREADDs (designer receptors exclusively activated by designer drugs): chemogenetic tools with therapeutic utility. Annu. Rev. Pharmacol. Toxicol. 55, 399–417. https://doi.org/10.1146/annurev-pharmtox-010814-124803.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk129",
      "text": "Van Steenbergen, V., Bareyre, F.M., 2021. Chemogenetic approaches to unravel circuit wiring and related behavior after spinal cord injury. Exp. Neurol. 345, 113839. https://doi.org/10.1016/j.expneurol.2021.113839.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk130",
      "text": "Vardy, E., Robinson, J.E., Li, C., Olsen, R.H.J., DiBerto, J.F., Giguere, P.M., Sassano, F.M., Huang, X.P., Zhu, H., Urban, D.J., White, K.L., Rittiner, J.E., Crowley, N.A., Pleil, K. E., Mazzone, C.M., Mosier, P.D., Song, J., Kash, T.L., Malanga, C.J., Krashes, M.J., Roth, B.L., 2015. A new DREADD facilitates the multiplexed chemogenetic interrogation of behavior. Neuron 86, 936–946. https://doi.org/10.1016/j.\n\nneuron.2015.03.065.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk131",
      "text": "Villain, H., Benkahoul, A., Drougard, A., Lafragette, M., Muzotte, E., Pech, S., Bui, E., Brunet, A., Birmes, P., Roullet, P., 2016. Effects of propranolol, a β-noradrenergic antagonist, on memory consolidation and reconsolidation in mice. Front. Behav. Neurosci. 10, 49. https://doi.org/10.3389/fnbeh.2016.00049.\n\nWalker, M.C., Kullmann, D.M., 2020. Optogenetic and chemogenetic therapies for epilepsy. Neuropharmacology 168, 107751. https://doi.org/10.1016/j.\n\nneuropharm.2019.107751.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk132",
      "text": "Yao, C.A., Ignell, R., Carlson, J.R., 2005. Chemosensory coding by neurons in the coeloconic sensilla of the Drosophila antenna. J. Neurosci. 25, 8359–8367. https://\n\ndoi.org/10.1523/JNEUROSCI.2432-05.2005.\n\nYasoshima, Y., Shimura, T., 2017. Midazolam impairs the retrieval of conditioned taste aversion via opioidergic transmission in mice. Neurosci. Lett. 636, 64–69. https://\n\ndoi.org/10.1016/j.neulet.2016.10.055.",
      "source": "p3.pdf"
    },
    {
      "id": "p3.pdf_chunk133",
      "text": "Zemelman, B.V., Nesnas, N., Lee, G.A., Miesenb¨ock, G., 2003. Photochemical gating of heterologous ion channels: remote control over genetically designated populations of neurons. Proc. Natl. Acad. Sci. U. S. A. 100, 1352–1357. https://doi.org/10.1073/\n\npnas.242738899.\n\nZeng, H., Sanes, J.R., 2017. Neuronal cell-type classification: challenges, opportunities and the path forward. Nat. Rev. Neurosci. 18, 530–546. https://doi.org/10.1038/ nrn.2017.85.",
      "source": "p3.pdf"
    },
    {
      "id": "p4.pdf_chunk0",
      "text": "Behavioural Brain Research 420 (2022) 113704\n\nELSEVIER\n\nContents lists available at ScienceDirect\n\nBehavioural Brain Research\n\njournal homepage: www.elsevier.com/locate/bbr\n\nAI ethics in computational psychiatry: From the neuroscience of consciousness to the ethics of consciousness\n\nCheck for aie",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk1",
      "text": "Wanja Wiese a,*, Karl J. Friston b\n\na Institute of Philosophy II, Ruhr University Bochum, Universit¨atsstraße 150, 44780 Bochum, Germany\n\nb Wellcome Centre for Human Neuroimaging, University College London, 12 Queen Square, London WC1N 3AR, UK\n\nA R T I C L E I N F O\n\nA B S T R A C T\n\nKeywords: AI ethics Computational psychiatry Consciousness Ethics of consciousness Mental disorders\n\nSchizophrenia",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk2",
      "text": "Methods used in artificial intelligence (AI) overlap with methods used in computational psychiatry (CP). Hence, considerations from AI ethics are also relevant to ethical discussions of CP. Ethical issues include, among others, fairness and data ownership and protection. Apart from this, morally relevant issues also include potential transformative effects of applications of AI—for instance, with respect to how we conceive of autonomy and privacy. Similarly, successful applications of CP may",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk3",
      "text": "have transformative effects on how we categorise and classify mental disorders and mental health. Since many mental disorders go along with disturbed conscious experiences, it is desirable that successful applications of CP improve our understanding of disorders involving disruptions in conscious experience. Here, we discuss prospects and pitfalls of transformative effects that CP may have on our understanding of mental disorders. In particular, we examine the concern that even successful",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk4",
      "text": "applications of CP may fail to take all aspects of disordered conscious experiences into account.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk5",
      "text": "1. Introduction",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk6",
      "text": "Methods used in computational psychiatry (CP) [1-7], such as deep learning, Bayesian modelling, or reinforcement learning, overlap with methods used in artificial intelligence [8]. Although the methods may be used for different aims, they can raise similar ethical issues. Hence, considerations from AI ethics are also relevant to CP. For instance, al- gorithms may produce unfair outcomes if their training data are biased [9] and the possibility to collect and analyse personal data using algo-",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk7",
      "text": "rithms raises issues of data ownership and protection [10,11]. Further- more, many applications of AI are not explicable, i.e., it is often difficult or impossible to determine why an AI system yields a given outcome or who is accountable for the particular way in which an AI system works [12]. Such immediate ethical concerns arise for applications of AI in general, but also for applications in mental healthcare and CP in particular [13-15].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk8",
      "text": "In addition to such immediate concerns, applications of AI can have morally relevant transformative effects. We use the term “transformative effects” broadly, in the sense of persistent changes that significantly impact human well-being related to at least some aspects of life and society. These changes need not be extreme or radical (in the sense of",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk9",
      "text": "preferences (in the sense of transformative experience, [17]). Trans- formative effects can still be far-reaching and substantial, for instance, by affecting the way we conceive of autonomy and privacy, or by transforming our way of living through AI applications that permeate daily life [18]. Similarly, successful applications of CP may transform how we classify and define mental disorders [1,3,19,7], which can have direct and indirect consequences for the well-being of affected persons [20].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk10",
      "text": "Many mental disorders are characterised by disturbed conscious experience. We shall refer to such disorders as “disorders of",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk11",
      "text": "consciousness.”",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk12",
      "text": "The term “disorder of consciousness” is often reserved for disordered global states of consciousness, such as unresponsive wakefulness syn- drome, minimally conscious state, or coma [21,22]. In these conditions, wakefulness and awareness are either diminished (minimally conscious state), partially absent (unresponsive wakefulness) or jointly absent (coma). Here, we use the term in a broader sense, which also covers disorders involving a disruption of the contents or the structure or form of",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk13",
      "text": "conscious processes (including their spatiotemporal continuity, see [23]). Examples include hallucinations in psychosis [24], deviant time- and self-consciousness in major depressive disorder [25], depersonali- sation [26], and derealisation in schizophrenia [27]. These conditions",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk14",
      "text": "transformative AI, [16]), nor need they fundamentally change personal\n\nneed not go along with diminished levels of wakefulness or awareness;\n\n* Corresponding author.\n\nE-mail address: Wanja.Wiese@rub.de (W. Wiese).\n\nE-mail address: Wanja.Wiese@rub.de (W. Wiese).\n\nhttps://doi.org/10.1016/j.bbr.2021.113704\n\nReceived 31 August 2021; Received in revised form 25 November 2021; Accepted 29 November 2021",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk15",
      "text": "0166-4328/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\n\nBehavioural Brain Research 420 (2022) 113704\n\nW. Wiese and K.J. Friston\n\nstill, they are characterised by disruptions of conscious processing. For this reason, it will be useful to refer to them as disorders of consciousness\n\nin this paper.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk16",
      "text": "By “consciousness” we mean phenomenal consciousness, i.e., mental states for which there is something it is like to be in [28]. These quali- tative aspects can include consciously experienced positive or negative affect, suffering, bodily feelings, cognitive phenomenology, as well as temporal, spatial, and other perceptual qualities. In disorders of con- sciousness, such aspects of consciousness are disrupted in a way that negatively affects the subject’s well-being.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk17",
      "text": "2. What is computational psychiatry?",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk18",
      "text": "Computational psychiatry (CP) [2,4-6] seeks to translate fin- dings—and techniques—from computational neuroscience to clinical psychiatry [41], in order to enable a deeper understanding of mental disorders [42], to improve diagnostics, to enable precise and reliable prognostics and therapy prediction and, ideally, to develop new thera- peutic approaches. Apart from these, a long-term goal of CP is to improve diagnostic categories by leveraging, nuancing or replacing symptom-based nosologies",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk19",
      "text": "[1,3,7,19].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk20",
      "text": "Although we are all intimately familiar with consciousness from a subjective, first-person perspective, the scientific study of consciousness is less definitive [29,30], and many empirical theories of consciousness make competing claims [31]. Still, our theoretical and empirical un- derstanding of consciousness has improved significantly during the past decades [32-36]. With its close link to computational neuroscience, CP can benefit from such progress through translational neuromodelling. This",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk21",
      "text": "highlights the potential of CP in deepening the understanding and improving the treatment of disorders of consciousness (in the general",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk22",
      "text": "sense).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk23",
      "text": "Successful applications of CP may thus reshape how we conceive of disorders of consciousness and thereby also affect our understanding of ‘normal’ conscious experiences. Changing our conception of normal and disordered conscious experiences might reduce or reinforce stigma and increase or limit treatment options. The potential transformative effects of CP are therefore morally relevant. In particular, they may reduce or increase the well-being of persons suffering from mental disorders. For this",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk24",
      "text": "reason, they are also relevant from the point of view of an ethics of",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk25",
      "text": "A key assumption within CP is that computational models can be used to define computational (endo)phenotypes [43]. Ideally, this will not only provide valid characterisations of mental health and illness, but also a bridge between molecular and behavioural findings [4]. In the long run, this can enable precise, mechanistically grounded and effective therapeutic interventions and thereby improve outcomes for patients\n\n[44].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk26",
      "text": "It is common to distinguish between two branches (or ‘cultures,’ [45]) of computational psychiatry: data-driven and theory-driven ap- proaches [44,46].1 Data-driven approaches use machine learning to analyse and label data. This can enable classifications and predictions of—among others—treatment responses [47] or the trajectories of mental disorders (e.g., of major depressive disorder, [48]). Apart from some exceptions, theory-driven approaches use generative models to model the causes of data.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk27",
      "text": "In contrast to discriminative models (which can only be used to classify data and their likely causes), generative models embody hypotheses about how observed outcomes have been generated; this also enables simulations and evidence-based comparison between hypotheses, through Bayesian model selection [49].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk28",
      "text": "consciousness [37-39].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk29",
      "text": "In this paper, we discuss potential transformative effects on the concept of mental illness that successful clinical applications of CP may have—even if researchers do not intentionally pursue the goal of revising existing (symptom-based) diagnostic categories. In particular, we address the worry that this type of research might reinforce a bio- logical reductionist view of mental disorders [40], at the risk of ignoring sociocultural factors and changes in conscious experience associated with",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk30",
      "text": "mental disorders [20].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk31",
      "text": "The paper is structured as follows. First, we provide a succinct description of computational psychiatry and ethical issues in AI. After that, we explore some prospects and pitfalls of CP in the following three steps:\n\n● Thesis: Computational psychiatry is tendentious; many branches of CP have a focus on brain function. This may reinforce a biological\n\nreductionism, ignoring psychosocial aspects of mental disorders.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk32",
      "text": "● Antithesis: Computational psychiatry is neutral with respect to metaphysical questions about mental disorders; computational models can take all aspects of mental disorders into account and therefore need not presuppose a definition of mental disorder that\n\nonly considers, say, biological variables.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk33",
      "text": "A generative model is a probabilistic model of (observable) data and their hidden (unobservable) causes. Such models or hypotheses can be used to infer the underlying mechanisms of symptoms, behavioural signs, or measurements (e.g., obtained using fMRI, [51,52]) or, indeed, conventional symptom-based diagnoses [1]. Ideally, this can facilitate differential diagnoses for individual patients; in this context, generative models are also called computational assays [7]. If successful, they could",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk34",
      "text": "allow for more precise and reliable diagnoses and therapy predictions, which is already a morally praiseworthy aim (provided the same effects cannot be brought about in a less expensive or less time-consuming way). In addition to this, computational assays promise to improve purely data-driven approaches. For instance, computational assays may improve machine-learning-based stratification (i.e., clustering into specific subgroups) by generative embedding [53-55] in at least two ways. First,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk35",
      "text": "generative embedding reduces the dimensionality of data by fitting a generative model with interpretable parameters; this allows representing data from subjects by a small number of features, which can also improve the performance of algorithms. Second, this can pro- vide information about why patients are divided into certain subgroups by a machine learning algorithm, because the features used by the al-",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk36",
      "text": "gorithm are mechanistically interpretable [54,56].\n\n● Synthesis: Computational models can increase our understanding of psychosocial aspects; but computational models can also fail to take them into account. Hence, to maximise its benefits, CP should be aware of the risk of unintentionally marginalising subjective experi- ence. Otherwise, the potential impact of research in CP on clinical practice may fail to be fully realised or may even be partially\n\ndetrimental.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk37",
      "text": "We illustrate the remaining worry in the synthesis with a case study. We conclude that CP can and should—at least in the long run—provide a better understanding of what a ‘good,’ ‘normal,’ and ‘pathological’ conscious experience is. The ethics of computational psychiatry will\n\nthen also be an ethics of consciousness [37-39].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk38",
      "text": "In contrast to approaches using generative models, data-driven ap- proaches need not make their assumptions explicit in the form of a generative model. To a certain extent, this means one can let the “data […] ‘speak for themselves’” ([57], p. 223). However, this does not mean that decisions made by researchers do not affect the outcomes of data analysis and prediction. On the contrary, specific care has to be taken, in order to avoid outcomes that are biased or do not generalise, due to",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk39",
      "text": "decisions regarding, e.g., data collection and data pre-processing ([58], p. 72). In particular, this means that applications should be validated in",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk40",
      "text": "independent samples.\n\nModel parameters in machine learning are not usually interpretable. In spite of this, even ‘black-box’ algorithms can have high predictive\n\n1 Gauld et al. [50] even speak of three ‘cultures,’ with digital psychiatry as a\n\nfurther, distinct branch of CP.\n\nBehavioural Brain Research 420 (2022) 113704\n\nW. Wiese and K.J. Friston",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk41",
      "text": "accuracy ([59], p. 254). Such methods can therefore still be highly useful for various purposes in psychiatry, for instance, for predicting future alcohol misuse or suicidality [60,61].\n\nNevertheless, non-interpretable (data-driven) approaches can be problematic when errors occur, and patients are harmed. This brings us to ethical problems in computational psychiatry.\n\n3. AI ethics and computational psychiatry",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk42",
      "text": "The goals of CP have direct ethical implications, due to their po- tential to serve patient well-being and because of the risks involved. Most ethical issues associated with CP’s main goals are already known, in similar form, in biomedical ethics [62], neuroethics [63,64], and AI ethics [65]. Examples include the handling of incidental findings [66], the possibility of improved early detection of disease risks [67], conse- quences for our self-image as autonomous, self-effective agents [68], or",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk43",
      "text": "problems of data protection [69] and algorithmic biases [18]. For a discussion of such problems in the context of computational psychiatry,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk44",
      "text": "see [13,15].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk45",
      "text": "Such problems should not conceal the potential benefits of CP. Mental illnesses are globally among the leading causes of disability- adjusted life years (i.e., years lived with disability plus years of life lost, [70]). At the same time, access to mental health care is often severely restricted, both in low-income countries and high-income countries [71]. For instance, in 2015 a study found that the median duration of untreated psychosis in community clinics in the US was 74 weeks [72]. This",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk46",
      "text": "shows that mental illness itself is a global morally relevant problem because it goes along with suffering and is in most cases not adequately treated. Refining diagnostics and treatments, in order to improve patient outcomes, is therefore a morally praiseworthy",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk47",
      "text": "goal.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk48",
      "text": "The ethical issues associated with applications of AI in psychiatry, and of CP in particular, can more systematically be described by dis- tinguishing the different domains of applications (e.g., early detection, diagnosis, and treatment, see [40]) and by reference to (biomedical) ethical principles, such as beneficence, non-maleficence, respect for autonomy, and justice [62]. For AI applications, there is a further fundamental principle: explicability [12], also called transparency or",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk49",
      "text": "explainability, which has a normative and an epistemic aspect. An AI application is explicable in the epistemic sense if it is intelligible how the system works, e.g., if it is transparent why it classifies a given input in a particular way. It is explicable in the normative sense if one can deter- mine who is responsible for the way the system works and who is accountable for its outcomes. This is especially relevant when an application fails to work in the intended way or if it has undesirable",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk50",
      "text": "consequences. Examples include applications with racist or other biases",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk51",
      "text": "[73].\n\nThe project of developing computational assays is especially inter- esting from an ethical point of view, because it can lead to interpretable results (see above). More generally, certain projects within theory- driven CP (as opposed to purely data-driven CP) promise to enable explainable applications, thereby circumventing the black-box problem\n\nknown from AI ethics [74].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk52",
      "text": "Apart from the huge potential benefits of CP, there is the concern that most approaches in CP are too narrow, in that they tend to focus on biological properties and fail to take psychosocial factors into due consideration [40]. In particular, one might worry that CP shares problems of the ‘third wave of biological psychiatry’ [75], according to which mental disorders are either brain disorders or can be diagnosed and treated without paying much attention to psychosocial factors. This, however,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk53",
      "text": "would mean that central aspects of mental disorders are ignored [20], thereby leading to suboptimal treatments (at least potentially); in particular, this cannot do justice to disorders of",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk54",
      "text": "consciousness.\n\nThese considerations make CP particularly interesting from the point\n\nof view of an ethics of consciousness [37-39]. On the one hand, CP bears\n\nthe prospect of alleviating suffering, which, in most cases, is morally praiseworthy. On the other hand, it bears the risk of ignoring, and failing to treat, crucial aspects of disordered conscious experience, which would be morally blameworthy.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk55",
      "text": "Taking AI ethics as a starting point may be especially useful in this context because there can be a tendency to think that a purely technical solution will be found [76], or that thorny problems such as unfairness of AI applications can be fixed by achieving complete AI fairness [77]. Similarly, it addresses the specious belief that any improvement of CP applications will dissolve or mitigate any ethical concerns. Drawing on insights from the more general debate on AI ethics could therefore",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk56",
      "text": "help avoid similar problems or misconceptions in the context of CP.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk57",
      "text": "In the remainder of this paper, we probe the concern that CP might promote tendentious views of mental disorders, thereby impeding ef- forts to realise CP’s full potential. After considering arguments in sup- port of this concern, as well as counter-arguments, we try to do justice to both side of the debate, by distiling the key aspects of the concern that remain, even after considering objections. The central remaining worry is that even successful applications of CP can, in the long run, fail",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk58",
      "text": "to adequately treat all aspects of disordered conscious experience. This concern should not be regarded as an objection to approaches in CP, but as a chance to maximise the benefits of CP: computational approaches have the required resources and should therefore be leveraged to ac- count for even subtle and puzzling aspects of (disordered) conscious experience.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk59",
      "text": "4. Thesis: Computational psychiatry is metaphysically tendentious",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk60",
      "text": "Superficially, it may seem that CP does not presuppose any assumption about the nature of mental disorders. In particular, CP is not committed to the claim that mental disorders are brain disorders. For instance, Adams et al. [49] stress that “Computational Psychiatry […] can unite many levels of description in a mechanistic and rigorous fashion, while avoiding biological reductionism and artificial catego- risation.” ([49], p. 53). In a similar vein, Huys et al. [44] assert:",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk61",
      "text": "“[W]e emphasise that illnesses are complex phenomena defying simplistic aetiological or mechanistic accounts […]. Indeed, research has identified contributions to the syndromes we identify as disorders arising at different levels from genetics to neural circuits, psychological processes, and social or societal factors. From a broad computational view, all of these factors lead to a mismatch between the brain’s computational ability, and the environmental or situational demands placed upon it.”",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk62",
      "text": "([44], p. 3).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk63",
      "text": "This highlights the fact that computational models are, in principle, metaphysically neutral. In particular, computational models need not focus on neural data, but can also take subjective reports and even social interactions into account ([78], p. 549). This suggests that it is at least an open question whether a future nosology, based on successful clinical applications of CP, will construe mental disorders as, for instance, dis- orders of the brain [79], as mechanistic property clusters",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk64",
      "text": "[80], or, more",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk65",
      "text": "specifically, as symptom networks [81,82].\n\nIn practice, however, many approaches in CP tend to focus on brain function ([2], p. 148; [4], pp. 72–73; [5], p. 22; [7], p. 85). In an\n\ninfluential landmark paper, Montague et al. [4] claim:",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk66",
      "text": "“[T]he brain is the organ that generates, sustains and supports mental function, and modern psychiatry seeks the biological basis of mental illnesses. This approach has been a primary driver behind the development of generations of anti-psychotic, anti-depressant, and anti- anxiety drugs that enjoy widespread clinical use. Despite this progress, biological psychiatry and neuroscience face an enormous explanatory gap. […] We believe that advances in human neuroscience can bridge parts of the",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk67",
      "text": "explanatory gap. […] It is the computational revolution in cognitive neuroscience that underpins this opportunity and argues strongly for the application of computational approaches to psychiatry.” ([4], pp. 72–73, bold emphasis added).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk68",
      "text": "Behavioural Brain Research 420 (2022) 113704\n\nW. Wiese and K.J. Friston\n\nIf CP merely contributes to understanding how neural processes can be changed using drugs,2 then it is to be expected that such research will reinforce the view that mental disorders are disorders of the brain. This focus is too narrow, for at least four reasons.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk69",
      "text": "First, the concept of a mental disorder is a normative concept. Of course, certain types of neural activity can also be regarded as aberrant forms of information processing (e.g., as inferences based on suboptimal models, [83])—i.e., CP itself often uses normative concepts. But the norms of optimal information processing and the norms of mental health can diverge ([84], p. 453). For instance, social anxiety reduces positive self-referential bias [85,86]. Hence, mental disorders cannot simply be",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk70",
      "text": "identified with suboptimal information processing.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk71",
      "text": "mental disorders are massively multifactorial in their causal back- ground; (2) many mechanisms that sustain disorders are transdiagnostic; and (3) mental disorders require pluralist explanatory accounts” ([82], p. 3)In particular, the network approach assumes that, once symptoms have been activated (due to external conditions or internal dysfunction), they can cause other symptoms (for instance, insomnia may cause fa- tigue) and may stabilise one another, even when the external cause is no",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk72",
      "text": "longer present ([82], p. 4). Furthermore, the way symptoms interact often depends on sociocultural context ([82], pp. 7–8). Defining mental disorders as symptom networks therefore offers the chance “to integrate the biological, psychological, behavioural, and environmental mecha- nisms that create causal relations between symptoms” ([82], p. 11).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk73",
      "text": "Second, disorders that involve mental states with illusory or false contents (e.g., hallucinations or paranoid beliefs) essentially depend on the subject’s environment: whether a belief is true or false, for instance, cannot be determined by looking at the subject’s brain. Borsboom et al.\n\nprovide the following example:",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk74",
      "text": "CP, on the other hand, has at least a tendency to ignore psychological and environmental mechanisms. It thereby misses the chance (offered by the network approach) to integrate multiple relevant factors, which\n\nwould lead to a comprehensive understanding of mental disorders.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk75",
      "text": "“Elizabeth and Bob may both believe that they are persecuted by the CIA, and this belief may be instantiated in the exact same way in their brains. Depending on the external circumstances, however, this belief may count as a symptom or not – for instance, when the belief is veridical for Elizabeth (who is actually a Russian spy) but finds no grounding in reality for Bob.” ([87], p. 49).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk76",
      "text": "Even assuming that the content of a belief can be understood in terms of neural properties, it does not follow that a model of neural mecha- nisms allows one to determine whether the belief is true or false, which would be required to distinguish pathological from non-pathological\n\nbeliefs or inference.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk77",
      "text": "Third, as emphasised by 4E approaches [88], many mental states are embodied, embedded, enactive, and extended. Therefore, it is unlikely that mental phenomena (whether pathological or healthy) can be\n\nidentified with neural states and processes [75].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk78",
      "text": "Fourth, even if conscious experience is an exception to the former point and can be reductively explained in terms of neural properties, there is the risk that applications of CP will ignore consciousness and lead to a “Zombie-psychology” [89]. As Huys et al. put it: “People pay for psychiatric help partly because internal subjective experiences have external objective correlates: because they cannot work or look after their children, not just because they feel sad” ([78], p. 545).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk79",
      "text": "Zombie-psychology may take care of external objective correlates and help patients become ‘functional’ again (which is, of course, fine), but disorders of conscious experience may persist.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk80",
      "text": "To the extent that CP focuses on the brain, it therefore presupposes problematic assumptions about mental disorders. These assumptions may reinforce overly narrow conceptions of mental disorders, limit treatment options, and increase stigmata associated with mental disor- ders [90]. This can decrease the probability that affected persons will\n\nseek help [68].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk81",
      "text": "Instead of regarding mental disorders as brain disorders, it has been theoretically fruitful to regard mental disorders as mechanistic property clusters (MPCs) [80]. MPCs are clusters of causal mechanisms that can interact and mutually sustain one another. Crucially, mental disorders typically involve many different causal mechanisms and mental disor- ders are multiply realisable ([80], p. 1148); this precludes mono-causal explanations of mental disorders [91].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk82",
      "text": "A specific version of the MPC view is the symptom-network approach [81,82]. Here, the idea is not to define mental disorders in terms of clusters of underlying causes of symptoms, but as causal networks of\n\nsymptoms. The approach starts from the following assumptions: “(1)",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk83",
      "text": "5. Antithesis: Computational psychiatry is metaphysically\n\nneutral\n\nIt is correct that some approaches within computational psychiatry focus on neural mechanisms. However, this does not mean that computational psychiatry is tendentious or that it is committed to ignoring psychosocial factors. In fact, many applications of machine learning in psychiatry include a diverse set of data in their analysis. Let us just give two examples to illustrate this point.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk84",
      "text": "In a longitudinal study with a large sample of adolescents, Whelan et al. [61] investigated factors that can be used to predict current and future alcohol abuse. Crucially, the data reflected “brain structure and function, individual personality and cognitive differences, environ- mental factors (including gestational cigarette and alcohol exposure), life experiences, and candidate genes” ([61], p. 185). Such approaches are therefore not committed to a narrow focus on a particular type of data",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk85",
      "text": "(e.g., neural data).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk86",
      "text": "A more recent study by Koutsouleris et al. [60] used machine learning to predict psychosis in patients with clinical high-risk states. The data included clinical-neurocognitive, genetic, and structural im- aging data. It turned out that risk predictors based on clinical-neurocognitive data could explain most of the variance in the sample, followed by predictors based on genetic and structural imaging data. Since data from clinical interviews include information about psychosocial factors, the",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk87",
      "text": "data considered were quite comprehensive. What is more, this study also illustrates an advantage of data-driven approaches: rather than deciding a priori which variables should be taken into account, such approaches provide a rigorous way of testing to what extent the different factors are relevant.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk88",
      "text": "Although these are just two examples, it should be obvious that a commitment to computational methods does not entail a commitment to using only certain types of data. By contrast, data-driven approaches are flexible enough so as to consider diverse data sets, thereby “allowing the data to ‘speak for themselves’” ([57], p. 223).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk89",
      "text": "Similarly, approaches using generative models can take interactions between the brain and external processes into consideration. Smith et al. [92] provide a compelling illustration of how this can be used to inte- grate and extend models of major depressive disorder. Far from identi- fying mental illness with ‘pathological’ biological mechanisms, their model construes major depression as arising from nested feedback loops spanning brain, body, and the social environment. Because of the",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk90",
      "text": "comprehensive nature of this approach, it not only enables hypotheses about the aetiology and heterogeneity of major depressive disorder, but also regarding pharmacological and psychotherapeutic treatment",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk91",
      "text": "2 By this, we do not wish to understate the importance of pharmacological interventions (and other interventions, such as cognitive behavioural therapy). In some cases, such as alcohol use disorder, they may even be more important than ‘folk-psychological wisdom’ would have us think. We thank Matteo\n\nColombo for emphasising this point in personal correspondence.\n\nmechanisms.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk92",
      "text": "Let us now address the more specific concerns raised above. Recall that these concerns refer to (1) the normativity of mental health and pathology, (2) the role of the environment, (3) the relevance of 4E ap-\n\nproaches to understanding mental disorders, and (4) the risk of\n\nBehavioural Brain Research 420 (2022) 113704\n\nW. Wiese and K.J. Friston\n\nneglecting conscious experience.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk93",
      "text": "(1) It is correct that the norms of mental health cannot be identified with the norms of optimal information processing—in particular, because some disorders reduce certain biases [84]. But such ‘optimisa- tion’ will go along with other disadvantages, which can, e.g., be un- derstood in terms of suboptimal models [83]. These can be ‘suboptimal’ due to changes in the model parameters of the (generative) models pa- tients use to make sense of their world [93]. Furthermore, at least some",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk94",
      "text": "(statistical) norms of mental health can be clarified with normative models that quantify the extent to which individuals deviate from a statistical norm [94].",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk95",
      "text": "examples, see [24,98–110]). Hence, it is not the case that CP must ignore, or cannot be applied to, disorders of conscious experiences.\n\nOn the contrary, CP has the potential to improve existing diagnostic categories for disorders of consciousness, by incorporating correlates of consciousness. As Henrik Walter puts it:",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk96",
      "text": "“Because every mental state has a correlate in the brain, we should be able to find at least in principle neurobiological correlates of any mental state, pathological or not. So the question is not, whether there is a neurocognitive correlate or mechanism, but whether it is pathological, how it came into being, whether it is persistent, whether and how it can be influenced, and so forth.” ([75], p. 5; see also [111], p. 86).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk97",
      "text": "The deeper point seems to be that computational psychiatry cannot disentangle itself from existing diagnostic categories and norms, but must embrace them. To the extent that approaches in CP deny this point,\n\nthey are doomed to fail.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk98",
      "text": "Although important, this point overlooks the fact that work in CP can build on existing categories (with their implicit norms), without reifying them. For instance, an important goal is to enable more fine-grained diagnoses by dissecting spectrum disorders ([95], p. 727). A more radical and straightforward approach is to consider existing categories as the product of a measurement process—and test generative models of how these diagnostic measurements were generated in terms of patho- physiology",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk99",
      "text": "and psychopathology [1]. Moreover, CP promises to improve prevention, prognoses, and treatment predictions, but none of these goals requires ignoring existing categories and norms. Still, CP offers the potential to improve diagnostic categories—which, almost by definition, is ethically desirable. The same holds for improving treatments and predictions.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk100",
      "text": "Findings about neural correlates of mental states provide further data that can inform diagnostics, prognostics, treatment decisions, and nosology. This does not presuppose that neural correlates reveal everything there is to know about a condition. In particular, a neural correlate itself does not tell us whether the accompanying mental state is pathological or not. It does not replace subjective assessments of well- being. However, this—in and of itself—does not preclude leveraging",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk101",
      "text": "neuro-computational findings in a therapeutic setting.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk102",
      "text": "This suggests that a focus on brain function is, in itself, meta- physically neutral. For the relevant question is not whether research in CP focuses on brain function, or also takes psychosocial factors into account. The relevant question is how findings about neural and computational correlates of pathological mental states and symptoms inform the way mental disorders are categorised and classified. Even if, for instance, a computational model is used to infer the neuronal mechanisms",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk103",
      "text": "underlying pathological symptoms, it is possible to regard neuronal mechanisms as just one factor among many that jointly",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk104",
      "text": "(2) Hallucinations or delusional beliefs cannot be understood exhaustively in terms of neural properties: the veracity of many beliefs depends on the environment. However, the deeper source of suffering is not the lack of veracity of a particular belief or hallucination, but the tendency to form such pathological mental states in the first place. In fact, one could even argue that not individual beliefs, but rather the ways in which beliefs are formed and updated (a.k.a. inference), can be",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk105",
      "text": "regarded as pathological. Although the difference between a sincerely- held false belief and a true belief is not something that can be captured by a model of neural processes, the internal dysfunction leading to a failure of adjusting one’s beliefs can be modelled in this way. More specifically, hallucinations and delusions can be modelled in terms of aberrant belief-updating [24,93,96]. These positive symptoms of psychosis correspond to a particular type of false inference: inferring something",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk106",
      "text": "is there when it is not. The complementary second type of false inference is inferring that something is not there when it is (e.g.,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk107",
      "text": "various neglect and agnosia syndromes).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk108",
      "text": "(3) The third concern emphasises that mental states are embodied, embedded, enactive, and extended [88]. This suggests that mental phenomena (whether pathological or healthy) cannot be identified with neural states and processes [75], but it does not mean that under- standing brain function is irrelevant to understanding mental states. For instance, Miller et al. [97] draw on computational models to develop an ecological-enactive account of addiction. Although the authors take computational",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk109",
      "text": "models of how addiction affects midbrain dopaminergic systems into account, they do not construe addiction as a brain disease. Instead, they argue that addiction should be regarded as an embodied phenomenon, which is ultimately not simply a disease of the brain, but a problem of living. This shows that computational approaches in psy- chiatry leave room for interpretation and do not presuppose contentious",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk110",
      "text": "constitute or cause the observed symptoms ([112], p. 35).\n\nThis also speaks to the notion of mental disorders as mechanistic property clusters [80]—or, in particular, as symptom networks [81,82]. Such approaches may have the potential to integrate multiple relevant factors and foster a comprehensive understanding of mental disorders, but one can make the case that they should be complemented by computational modelling ([112], p. 36).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk111",
      "text": "For instance, although correlations between symptoms and signs can be revealing, it will ultimately be expedient to investigate causal re- lations between the mechanism underlying measurements (including\n\nsubjective reports). Friston et al. [1] illustrate this point as follows:",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk112",
      "text": "“[T]here is a fundamental distinction between a measurement (e.g., a temperature of 38.2 ◦ C) and the causes of that measurement (e.g., bacterial infection). It is almost self-evident that to generate the (profile of) measurements available to a clinician, it is necessary to model their latent causes, whether or not they are ontologically well-defined. […] [W]e should try to identify the causal (network) architecture among the symptoms’ latent causes: namely, the best generative model. Both",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk113",
      "text": "symptom network analysis [113] and generative modelling eschew the common-cause framework—namely, the assumption that symptoms and",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk114",
      "text": "signs can be uniquely attributed to a common cause.” ([1], p. 19).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk115",
      "text": "In addition to making a distinction between measurements and their causes, it may also be necessary (and illuminating) to make a distinction between data and symptoms. As Fellowes [114] argues in the context of autism spectrum disorder, symptoms must be inferred on the basis of data and may even be, in some sense, constructed. In the network approach, this becomes manifest in the fact that network analyses will yield different results, depending on whether they are conducted on the basis of a",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk116",
      "text": "DSM/ICD taxonomy, or, for instance, on the basis of the",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk117",
      "text": "Research Domain Criteria ([112], p. 36).\n\nmetaphysical assumptions about the nature of mental disorders.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk118",
      "text": "(4) The charge that CP runs the risk of ignoring subjective experience can easily be dispelled. Disorders of consciousness are among the symptoms of many mental disorders, e.g., hallucinations in psychosis [24], or deviant time- and self-consciousness in major depressive dis- order [25], depersonalisation disorder [26], and schizophrenia [27]. The relevance of computational approaches to understanding aspects of\n\ndisturbed consciousness has already been demonstrated (for a few",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk119",
      "text": "Furthermore, computational modelling approaches can be useful for understanding correlations between different types of symptoms. For instance, there is a correlation between psychiatric disorders and im- mune responses [115]. Bhat et al. [116] show how hypotheses about the nature of this connection can be computationally modelled and explored through simulations in silico. There are thus many ways in which CP can\n\n(and should) augment network approaches.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk120",
      "text": "More generally, CP can furnish a mechanistic understanding of\n\nMore generally, CP can furnish a mechanistic understanding of\n\nBehavioural Brain Research 420 (2022) 113704\n\nW. Wiese and K.J. Friston",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk121",
      "text": "relationships between psychological, biological, and social variables. As Smith et al. [117] show with respect to health and social support, neu- rocomputational approaches can go beyond investigating correlations, by formulating and exploring implications of testable hypotheses about how such variables are causally related. In particular, this also involves investigating how biological, psychological, and social processes are regulated within individual brains. Hence, as the authors point out,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk122",
      "text": "there is a sense in which “all the major elements of the biopsychosocial model are […] already present within any complete biomedical model”",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk123",
      "text": "([117], p. 141).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk124",
      "text": "Since the focus of this paper is on disorders of consciousness, it should be noted that it can sometimes be useful, or even necessary, to ignore some aspects of conscious experience. Consider the problem of predicting the risk for suicidal behaviour. Data for predictors of suici- dality typically include subjective reports of suicidal ideation, because suicidal ideation has for a long time been regarded as a central index for suicidality [118]. However, suicide attempts need not be preceded by",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk125",
      "text": "suicidal ideation [119], and some persons may be unwilling to report suicidal ideation. For these reasons, it is especially useful that compu- tational approaches can be used to predict suicidal behaviour without having to rely on reports of suicidal ideation [120].3 In this case, ignoring conscious thoughts (suicidal ideation) is not just acceptable, but even desirable, because it can help make predictors more accurate.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk126",
      "text": "of coping with a condition), but it could also have harmful effects (e.g.,\n\nby increasing stigmata).\n\nA remaining worry is that successful applications of CP might still fail to fully take psychosocial factors into account. The worry is not that this will happen intentionally, or because CP has an inherent tendency to ignore such factors—the rebuttals in the antithesis should have clarified that work in CP can and often does incorporate data on psychosocial\n\nfactors.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk127",
      "text": "Still, the risk that CP may fail to properly address disorders of conscious experience should be taken seriously. Note that the problem is not that CP lacks the concepts or methods to take features of disordered conscious experiences into account. As indicated above, existing work speaks against this suspicion [24,98–110]. Rather, the problem is that some features of scientific progress may drive CP into a trajectory that converges on diagnostic criteria that fail to include at least some",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk128",
      "text": "aspects of disordered consciousness.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk129",
      "text": "In what follows, we shall describe two ways in which CP might, in the long run, lead to a revision of diagnostic categories that ignores important features of disorders of consciousness. The two possibilities described are to some extent speculative, but should be taken into consideration as part of an ‘ethical risk assessment’ of computational psychiatry. We do not believe that the potential harms entailed by these risks outweigh the potential benefits of successful applications of CP. However,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk130",
      "text": "we do believe that being mindful of these risks can help maximise the benefits of CP.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk131",
      "text": "6. Synthesis\n\nIn this section, we take stock, by highlighting CP’s potential for progress, while acknowledging remaining concerns. We restrict the discussion to the transformative potential of CP, focusing in particular\n\non the prospects of an improved nosology.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk132",
      "text": "One line of argument—presented in the thesis above—has it that many CP approaches focus on brain function, which is ultimately too narrow to be successful. In the antithesis, this argument was countered by pointing out that (i) many approaches in CP are much broader and (ii) it can often be useful to restrict the focus (without presupposing that mental disorders are brain disorders). Thus, there is currently no reason to believe that CP will not be able to realise its potential because of an",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk133",
      "text": "alleged narrow focus. Still, one should beware of tendencies to view computational approaches merely as a means of developing more effective pharmacotherapy. That is, it should be acknowledged that successful applications of CP may improve diverse types of therapeutic approaches and foster a comprehensive understanding of mental illness; but individual results could be instrumentalised to pursue a more narrow-minded agenda—for instance, Starke et al. [15] raise the worry that “lobbying by",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk134",
      "text": "pharmaceutical companies might have an interest to split psychiatric disorders into many distinct categories to gain advan-",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk135",
      "text": "6.2. Why should the risk of discounting consciousness be taken seriously?",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk136",
      "text": "The first reason why crucial aspects of disorders of consciousness might end up being ignored is methodological. Developing and vali- dating generative models for spectrum disorders such as schizophrenia is a complex task, requiring longitudinal studies with many participants. Focusing on biological features reduces the complexity of the task, without simplifying it: even if a complete understanding of a mental disorder also requires taking psychosocial factors into account, biolog- ical",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk137",
      "text": "approaches can paint an important part of the picture. As Huys et al. put it: “From a broad computational view, all of these factors lead to a mismatch between the brain’s computational ability, and the environ- mental or situational demands placed upon it.”([44], p. 3). The mismatch will not be understood without considering the environmental or situational context, but at least the brain’s computational ability can ideally be assessed by narrow (biological) approaches in CP. Apart from this,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk138",
      "text": "there can be economic incentives to focus on biological variables and the development of medical interventions (in particular, therapeutic",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk139",
      "text": "drugs).\n\ntages in the approval of new drugs.”\n\n6.1. Transformative effects of computational psychiatry\n\n6.1. Transformative effects of computational psychiatry",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk140",
      "text": "One can add that even models with a restricted focus need not affect views about the nature of mental illness. For instance, even if halluci- nations and delusions are modelled as aberrant belief-updating [24,96], this does not mean that the brain literally processes information in this way. Instead, one can interpret such models instrumentally, suggesting that it can be useful to view (some) mental disorders or symptoms in this way, without presupposing that mental disorders are brain",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk141",
      "text": "disorders. In particular, models in CP need not claim to provide the only way in which a mental disorder can be conceived. Nevertheless, such models can have profound effects. For instance, Colombo and Fabry suggest they may “re-shape people’s image of delusion, and possibly impact the nature of delusional experience itself.” ([98], p. 22). Changing people’s images of",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk142",
      "text": "Incidentally, even George Engel, the pioneer of the biopsychosocial model, suggested that excluding certain aspects of mental illness can be reasonable [121]. However, he added that this exclusion can become problematic in the long run: “[I]t becomes counterproductive when such strategy becomes policy and the area originally put aside for practical reasons is permanently excluded, if not forgotten altogether. The greater the success of the narrow approach the more likely is this to happen.”",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk143",
      "text": "([121], p. 131). To what extent can it be counterproductive to adopt a narrow approach in CP, and how can it be problematic, if it is successful? The answer is that success can be partial. For instance, a narrow approach may improve prognoses and treatment predictions for some symptoms (e.g., in severe cases). This could count as a success and could motivate efforts to refine existing treatments and further improve pre- dictions, without even addressing other symptoms (which may be less severe",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk144",
      "text": "or more difficult to assess). In the long run, some aspects of a subject’s ailments will be cured, but other aspects that are harder to measure may persist. Below, we illustrate this point with a case study.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk145",
      "text": "delusion and other symptoms can be beneficial (e.g., if it provides a way\n\n3 We thank Ren´e Baston for pointing us to this study.\n\nThe second way in which biological approaches within CP may fail to take features of disturbed conscious experiences into account is moti- vated by a suggestion in the antithesis, according to which even a focus\n\non brain function can be regarded as metaphysically neutral. Conscious\n\nBehavioural Brain Research 420 (2022) 113704\n\nW. Wiese and K.J. Friston",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk146",
      "text": "experiences—whether pathological or not—have neural correlates ([75], p. 5); biological approaches in CP can complement research on neural correlates by shedding some light on computational correlates of consciousness [122]. Furthermore, there may be characteristic cognitive or behavioural correlates. Investigating such correlations can advance the understanding of mental disorders.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk147",
      "text": "A potential problem is that some of these correlates may receive more attention than the features of consciousness with which they correlate—because behavioural and biological variables can be easier to measure and may enable a more reliable categorisation. Of course, reliable diagnostic categories are desirable, but this should not be at the cost of other relevant variables.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk148",
      "text": "Crucially, a shift to behavioural and biological factors, at the neglect of psychological factors, can be motivated by initiatives like the RDoC approach [123]. Although RDoC’s units of analysis include self-reports as one unit among seven, there is a clear emphasis on biological in- dicators [124,125]. This can create the impression that biological factors are more fundamental [126]. Furthermore, the RDoC initiative explic- itly fosters attempts to discount subjective reports of psychological",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk149",
      "text": "problems, by replacing them with data that speak to the mechanisms underlying the reported psychopathology: “Ultimately, if the RDoC initiative proves successful, psychobiological mechanisms might usurp the telltale role of self-reported experiences in a renovated diagnostic system.” ([127], p. 933). A potential risk is that even successful appli- cations may target only some of the underlying mechanisms, thereby leaving important aspects of some mental disorders unaddressed. To prevent this,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk150",
      "text": "considering subjective reports remains indispensable. For it would be premature to expect that computational methods will reveal the neural or computational underpinnings of subjective well-being. That is, when it comes to evaluating to what extent not only individ- ual symptoms, but also a patient’s overall condition has improved, the",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk151",
      "text": "fluids that expanded when they were heated. Following Middleton [134], Chang [128] calls such devices thermoscopes. In contrast to quantitative thermometers, the former only have ordinal scales. Devel- oping thermometers with cardinal scales requires fixed points, such as the freezing and boiling of water. Once fixed points were found (which is non-trivially, without already having a reliable thermometer), numeri- cal thermometers could be created, which enabled quantitative mea- surements of",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk152",
      "text": "temperature. This also enabled theoretical advances:",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk153",
      "text": "“By means of numerical thermometers, meaningful calculations involving temperature and heat could be made and thermometric ob- servations became possible subjects for mathematical theorising. Where such theorising was successful, that constituted another source of vali- dation for the new numerical thermometric standard.” ([128], p. 48).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk154",
      "text": "However, epistemic iteration does not stop here. The boiling point was only one candidate for a fixed point; a competing candidate was the “steam point,” and the latter eventually replaced the boiling point, because it was more stable and was supported by theory ([128], p. 48). Further iterative refinements and extensions of thermometry took place, involving an interplay between theoretical and empirical advances.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk155",
      "text": "Colombo [128] applies this concept to the role reinforcement learning plays in the study of alcohol use disorder. As the starting point for the scientific study of alcohol use disorder, Colombo identifies phenomenological observations, clinical experience, and patients’ needs. Based on these, correlations between phenomenological obser- vations, risk factors, environmental cues, and behavioural and biological symptoms can be investigated using empirical studies. “Fixed points” are “implicitly or",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk156",
      "text": "explicitly employed—such as, for example, a definition of substance use disorders grounded in heavy use over time [135]—for triangulation and probing the reliability and validity of these correla- tions” ([130], p. 15). Colombo notes that computational explanations in psychiatry can take different forms, including aetiological and consti-",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk157",
      "text": "primary authority remains the patient themself.\n\ntutive explanations.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk158",
      "text": "This is not just a potential problem of the RDoC approach, but of progress in psychiatry more generally. Subjective reports can be ambiguous and unreliable. For this reason, there will always be some pressure to refine methods that tap into the ‘objective’ factors of mental disorders. To the extent that such efforts are successful, the subjective factors of mental disorders can be discounted, because they have already been accounted for in terms of other, more reliable variables—or so one might",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk159",
      "text": "argue.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk160",
      "text": "We can apply this to the scientific study of schizophrenia. For the purpose of this paper, the starting point can be identified with a defi- nition of schizophrenia in terms of a set of positive and negative symptoms and signs (as in DSM-V). This brushes over many historical complexities (e.g., the ‘neo-Kraepelinian revolution’ constituted by drastic changes in the transition from DSM-II to DSM-III, see [136]). However, our focus is on how epistemic iteration may play out in the future, not on",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk161",
      "text": "how it may have been at work in the past.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk162",
      "text": "6.3. Potential side effects of progress in psychiatry",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk163",
      "text": "We shall now consider this possible dynamics of progress in psy- chiatric research in a bit more detail. To this end, it will be instructive to see how progress in other disciplines has replaced subjective measures with more reliable, objective measures. In particular, we shall see that this is a potential outcome of what Chang [128] calls epistemic iteration (see also [129]). After briefly introducing this concept, we shall review a recent application to psychiatry by Colombo [130], who applies",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk164",
      "text": "the concept to research on alcohol use disorder. Afterwards, we show how the concept can be applied to research on schizophrenia (see also [131]), and suggest that a potential side effect of epistemic iteration is the neglect of certain aspects of conscious experience.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk165",
      "text": "Chang defines the notion of epistemic iteration as follows: “Epistemic iteration is a process in which successive stages of knowledge, each building on the preceding one, are created in order to enhance the achievement of certain epistemic goals.” ([128], p. 45). Epistemic iter- ation is thus a particular type of scientific progress, and it need not involve theory falsification, as in Popper’s hypothetico-deductive model [132], nor scientific revolutions in the sense of Kuhn [133]. Chang de-",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk166",
      "text": "velops this concept in the context of the history of thermometry, i.e., the measurement of temperature.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk167",
      "text": "“Fixed points” for the study of schizophrenia are given by particular types of symptoms (e.g., auditory hallucinations or delusions). Since schizophrenia is a spectrum disorder, these fixed points are far from perfect, but nevertheless useful as starting points. Moreover, this also illustrates why iterative refinements (in the sense of epistemic iteration) are particularly useful in the context of schizophrenia. Empirical studies reveal correlations between behavioural and neurophysiological",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk168",
      "text": "vari- ables. Computational models can be used to explore hypotheses and derive predictions, which can be tested by adapting the cognitive tasks used in empirical studies. Crucially, this is where iteration occurs, assigning a central role to computational modelling. Deserno et al. characterise this process as follows (in the context of negative symptoms of schizophrenia): “cognitive tasks studying reinforcement learning and decision-making have been shown to be associated with negative symptom",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk169",
      "text": "severity with at least some consistency. This can be improved by mutually refining learning and decision-making tasks and computa-",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk170",
      "text": "tional models” ([137], p. 52).\n\nOf course, we can only speculate what concrete results this process of epistemic iteration will yield in the near future. However, we can make a guess that is consistent with some aims of computational psychiatry. A mid-term result may be that machine learning is used to make a per- sonalised treatment prediction for individual patients. As an illustration, consider the following hypothetical example by Starke et al. (involving a",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk171",
      "text": "Even before thermometers were invented, temperature could be measured—albeit imprecisely and non-reliably—by bodily sensations.\n\nMore reliable measurements could be obtained using devices containing\n\nfictional patient ‘T’):\n\n“T is diagnosed with a first episode of schizophrenia based on a\n\nclinical interview. To choose the most effective drug for his individual\n\nBehavioural Brain Research 420 (2022) 113704\n\nW. Wiese and K.J. Friston",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk172",
      "text": "situation, his psychiatrist recommends a newly approved routine employing functional MRI during a reward-learning task. Based on T’s brain activity and a plethora of other available information, from de- mographic data to his clinical records, the ML algorithm suggests one specific anti-psychotic drug as ideal for T’s specific situation. Following the automated recommendation, the psychiatrist prescribes the drug to her patient.” ([15], p. 3, bold emphasis added).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk173",
      "text": "In this case, machine learning is used for personalised treatment prediction, but the diagnosis is still based on a clinical interview. As a long-term result, we can imagine that the entire clinical interview [138], or at least the diagnosis resulting from it, will be treated as a yet another data point. Together with further measurements, it is fed to an algo- rithm, or informs the choice of a generative model, which is then used to infer the underlying mechanisms, on the basis of which the",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk174",
      "text": "final diag- nosis is made [1]. The diagnostic categories used will be more fine-grained than the ones used in DSM-V (and ICD-10), while at the same time ignoring the categorical boundaries between disorders implied by neo-Kraepelinian nosologies. This enables not just a more reliable and precise diagnosis, but also more accurate treatment",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk175",
      "text": "it, they cannot navigate… Me, it’s the time I do not have… I’m like blind to time… but I cannot explain it better… I try to find out how to talk about it… but I can’t manage to explain. It may be the most important thing to understand…” ([140], p. 3).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk176",
      "text": "These statements are highly remarkable: AF has a “rare ability” to describe his problems in some detail, but still struggles to find the right words. At the same time, these problems are extremely important to him. They may be “the most important thing to understand” and yet it is\n\nalmost impossible for him to explain them.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk177",
      "text": "The case study illustrates at least two things. First, even successful treatments can fail to address crucial aspects of disordered conscious experience. Approaches in CP that mainly seek to dissect spectrum dis- orders and provide individual treatment predictions are unlikely to improve this situation. Second, there is transformative potential for approaches in CP that seek to account for aspects of disordered conscious experience (as suggested by [98]). If research in CP is beware of ignoring",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk178",
      "text": "subtle features of subjective experiences, there is thus a chance that it will realise its full potential.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk179",
      "text": "predictions.\n\n7. Conclusion\n\nAt the same time, subjective reports may become less relevant to diagnoses, in line with goals of the RDoC approach ([127], p. 933). Just as the development of quantitative thermometers rendered subjective sensations of warmth and cold superfluous as measures of temperature (at least for scientific and diagnostic purposes), a reliable blood test [139] or computational assays [55] for schizophrenia might make sub-\n\njective reports more or less dispensable.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk180",
      "text": "The analogy with thermometry illustrates how CP can successfully promote progress in research on schizophrenia that results in tangible applications. At the same time, it highlights the risk of neglecting aspects of disordered conscious experience. For there is also a key disanalogy: thermometry was never meant to yield an understanding of subjective sensations of heat; it was meant to yield reliable, quantitative mea- surements of properties of external objects and processes. In the case of",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk181",
      "text": "disorders of consciousness, this is different. There is thus always the possibility that objective measurements fail to capture all aspects of the disorder to which subjective reports point.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk182",
      "text": "6.4. A case study involving disturbed temporal experience",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk183",
      "text": "In order to make this more concrete, consider the following case study by Martin et al. [140]. The case study shows that successful treatments can be partial: even if some symptoms of a condition have disappeared or are alleviated, other—perhaps more subtle—symptoms may persist. What is more, these residual symptoms need not be negli- gible, but can instead constitute a significant disruption of conscious experience. This illustrates that applications of CP might succeed in, for instance,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk184",
      "text": "developing effective personalised treatment recommenda- tions, while at the same time failing to improve patient outcomes in other crucial respects. Martin et al. [140] cite reports by a young man,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk185",
      "text": "What revisions of nosology will be suggested by successful clinical applications of computational psychiatry, and by applications of AI in psychiatry? This question is especially relevant because existing research more or less leaves this question open. For instance, Winter et al. [141] propose an “AI ecosystem” to address “fundamental issues regarding sample size, model construction, evaluation practice, and the conceptualization of mental disorders” ([141], p. 4, bold emphasis added). However,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk186",
      "text": "the way in which mental disorders should be re-conceptualized is not further specified by Winter et al. [141]—apart from the suggestion to use normative models [94] to quantify the extent to which individuals deviate from a statistical norm. In particular, it remains undetermined to what extent normative variables (in terms of which deviances are measured) should include not just biological, but also psychological and social variables.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk187",
      "text": "Given methodological constraints, it seems that biological (including neuronal) variables can be measured most easily. Therefore, one might worry that this will reinforce a biological reductionism [40]. However, we argued above that even a focus on biological variables need not lead to a view according to which mental disorders are identical with brain disorders. A more important risk is that biologistic tendencies may ignore important psychosocial factors, such as some features of the conscious",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk188",
      "text": "experience of patients—although many mental disorders are, to a large extent, disorders of consciousness. Developing normative models that quantify deviances from a statistical norm should therefore also specify what a normal conscious experience is. This could then provide a further “fixed point” for quantitative measures in terms of normal conscious experience—at least in the long run; in the foreseeable future, fixed points may have to be construed in terms of pathological",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk189",
      "text": "symptoms or endophenotypes of mental illness.\n\nAF, who had previously been diagnosed with schizophrenia:\n\n“When we encountered AF, functional impairments persisted, i.e., difficulty in social and professional integration, but there was no longer any obvious behavioural symptomatology […]. The patient voiced two major complaints. The first concerned the feeling of being oneself, and\n\nthe second his experience of time.” ([140], p. 2).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk190",
      "text": "Although AF’s condition had—to some extent—been successfully treated, not all symptoms had disappeared. Furthermore, and most centrally, the authors explicitly mention that “AF has a rare ability to describe his self and time difficulties” ([140], p. 1). This suggests that most other patients may not even be able to describe remaining symp- toms, after the most obvious symptoms have successfully been treated. AF describes his remaining symptoms as follows:",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk191",
      "text": "“I do not feel the time,” […] “You see, I can use a metaphor to explain to you… Birds, they have a sense that allows them to orient them- selves… a kind of magnetism… It is an innate thing… If they do not have",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk192",
      "text": "We saw that scientific progress in psychiatry can be regarded as an improvement even when psychosocial factors are ignored. Depending on how “improvement” is defined, however, this can still be ethically problematic. For instance, a reasonable requirement would be that an improvement increase the reliability and validity of diagnostic cate- gories in such a way as to make psychiatric treatments more effective (see [5], p. 20). However, as Barron [138] points out, “there is no consensus on how to",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk193",
      "text": "measure treatment outcome in psychiatry [142]. For example, would antipsychotic treatment be ‘successful’ if patient R’s hallucinations decrease by 50%? By 90%?” ([138], p. 2). Apart from this, there remains the problem that CP might promote a tendency to exclusively focus on those factors of mental disorders that can be measured, using methods of computational neuroscience, without hav- ing to take subjective reports and sociocultural factors into account. Given the status quo in psychiatry,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk194",
      "text": "one might argue that any improve- ment—no matter how marginal or restricted—should be regarded as",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk195",
      "text": "Behavioural Brain Research 420 (2022) 113704\n\nW. Wiese and K.J. Friston\n\nbeneficial and desirable, even if central aspects of an ailment remain untreated. However, this should not lead to, for instance, an exclusive focus on developing more effective or personalised therapeutic drugs.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk196",
      "text": "The worries expressed above should be construed as worries about long-term, not short-term effects of CP. In particular, to the extent that translating results of computational neuroscience to clinical practice is successful, one can expect that this will have an impact on how mental disorders are construed. If complemented by research on disturbances of conscious experiences associated with mental disorders, CP may have transformative effects on conceptions of mental disorders that support not",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk197",
      "text": "overly narrow, but richer and broader views. In particular, it could lead to a deeper understanding of normal and pathological conscious",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk198",
      "text": "experiences.\n\nIn order to reap the benefits of the metaphysical neutrality of computational models, CP should —at least in the long run—be com- plemented by research on the computational correlates [122] of conscious experiences that go along with mental disorders. This also raises the question what a ‘good,’ ‘normal,’ or ‘pathological’ conscious experience is. Consequently, the ethics of computational psychiatry will also be an ethics of consciousness.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk199",
      "text": "[3] Q.J.M. Huys, Computational psychiatry series, Biol. Psychiatry.: Cogn. Neurosci. Neuroimaging 5 (9) (2020) 835–836, https://doi.org/10.1016/j. bpsc.2019.11.009.\n\n[4] P.R. Montague, R.J. Dolan, K.J. Friston, P. Dayan, Computational psychiatry, Trends Cogn. Sci. 16 (1) (2012) 72–80, https://doi.org/10.1016/j. tics.2011.11.018.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk200",
      "text": "[5] A.D. Redish, J.S. Gordon, Breakdowns and failure modes: an engineer’s view, in: A.D. Redish, J.S. Gordon (Eds.), Computational Psychiatry: New Perspectives on Mental Illness, MIT Press, 2016, pp. 15–29.\n\n[6] P. Series (Ed.), Computational Psychiatry: A Primer, MIT Press, 2020.\n\n[7] K.E. Stephan, C. Mathys, Computational approaches to psychiatry, Curr. Opin. Neurobiol. 25 (2014) 85–92, https://doi.org/10.1016/j.conb.2013.12.007.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk201",
      "text": "[8] S. Russell, P. Norvig. Artificial Intelligence: A Modern Approach, 3rd ed., Prentice Hall,, 2009.\n\n[9] R. Binns, Fairness in machine learning: lessons from political philosophy, in: S. A. Friedler, C. Wilson (Eds.), Proceedings of the 1st Conference on Fairness, Accountability and Transparency, Vol. 81, PMLR, 2018, pp. 149–159, in: 〈http:// proceedings.mlr.press/v81/binns18a.html〉.\n\n[10] K. Macnish, The Ethics of Surveillance: An Introduction, Routledge, 2017.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk202",
      "text": "[11] B. Roessler, X—privacy as a human right, Proc. Aristot. Soc. 117 (2017) 187–206, https://doi.org/10.1093/arisoc/aox008.\n\n[12] L. Floridi, J. Cowls, M. Beltrametti, R. Chatila, P. Chazerand, V. Dignum, C. Luetge, R. Madelin, U. Pagallo, F. Rossi, B. Schafer, P. Valcke, E. Vayena, AI4People—an ethical framework for a good AI society: opportunities, risks, principles, and recommendations, Minds Mach. 28 (4) (2018) 689–707, https:// doi.org/10.1007/s11023-018-9482-5.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk203",
      "text": "At present, we are far from having a formal account of conscious experience. As mentioned in the introduction, many empirical theories of consciousness make competing claims, and there is still much un- certainty about the neural mechanisms that underwrite ordinary conscious processes (let alone psychopathology). Hence, the suggestion to foster research on the computational correlates of disordered conscious experiences should not be regarded as an invitation to ignore subjective reports. The",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk204",
      "text": "patient’s perspective will continue to be central for normatively assessing their experienced condition. Computational models offer constructs to better describe and understand elusive aspects of a disordered conscious experience, but the patient will remain the primary authority on whether they are suffering from their condition. Mitigating a disorder may be aided by understanding the neural and computational underpinnings. In this sense, successful applications of CP can be desirable from the",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk205",
      "text": "point of view of an ethics of consciousness (and the lack of required knowledge about consciousness can be seen as ethically problematic). But such knowledge will not by itself yield a consciousness-ethical account of what a ‘good’, ‘normal’, or ‘patholog- ical’ conscious experience is. Rather, it must build on normative judg- ments, in order to refine our understanding of disordered conscious",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk206",
      "text": "experiences.\n\n[13] G. Christophe, M.-F. Jean-Arthur, D. Guillaume, Comment on starke et al.: ‘Computing schizophrenia: Ethical challenges for machine learning in psychiatry’: from machine learning to student learning: Pedagogical challenges for psychiatry, Psychol. Med. (2020) 1–3, https://doi.org/10.1017/ S0033291720003906.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk207",
      "text": "[14] S.C. Guntuku, D.B. Yaden, M.L. Kern, L.H. Ungar, J.C. Eichstaedt, Detecting depression and mental illness on social media: an integrative review, Curr. Opin. Behav. Sci. 18 (2017) 43–49, https://doi.org/10.1016/j.cobeha.2017.07.005.\n\n[15] G. Starke, E. De Clercq, S. Borgwardt, B.S. Elger, Computing schizophrenia: ethical challenges for machine learning in psychiatry, Psychol. Med. (2020) 1–7,\n\nhttps://doi.org/10.1017/S0033291720001683.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk208",
      "text": "[16] Gruetzemacher, R., & Whittlestone, J. (2021). The transformative potential of artificial intelligence. 〈http://arxiv.org/abs/1912.00747〉.\n\n[17] L.A. Paul, Transformative Experience, Oxford University Press, 2014.\n\n[18] B.D. Mittelstadt, P. Allo, M. Taddeo, S. Wachter, L. Floridi, The ethics of algorithms: mapping the debate, Big Data Soc. 3 (2) (2016) 1–21, https://doi.org/ 0.1177/2053951716679679.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk209",
      "text": "[19] C. Mathys, How could we get nosology from computation? in: A.D. Redish, J. S. Gordon (Eds.), Computational Psychiatry: New Perspectives on Mental Illness MIT Press, 2016, pp. 121–135.\n\n[20] S. Tekin, Psychiatric taxonomy: at the crossroads of science and ethics, J. Med. Ethics 40 (8) (2014) 513–514, https://doi.org/10.1136/medethics-2014-102339.\n\n[21] J.L. Bernat, Chronic disorders of consciousness, Lancet 367 (9517) (2006) 8–14, https://doi.org/10.1016/S0140-6736(06)68508-5.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk210",
      "text": "[22] A. Thibaut, N. Schiff, J. Giacino, S. Laureys, O. Gosseries, Therapeutic interventions in patients with prolonged disorders of consciousness, Lancet Neurol. 18 (6) (2019) 600–614, https://doi.org/10.1016/S1474-4422(19)30031-\n\n6.\n\nCRediT authorship contribution statement\n\nWanja Wiese: Conceptualisation, Writing- Original draft prepara-\n\ntion and Editing. Karl J. Friston: Writing- Reviewing and Editing.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk211",
      "text": "[23] G. Northoff, What the brain’s intrinsic activity can tell us about consciousness? A tri-dimensional view, Neurosci. Biobehav. Rev. 37 (4) (2013) 726–738, https://\n\ndoi.org/10.1016/j.neubiorev.2012.12.004.\n\n[24] P. Sterzer, R.A. Adams, P. Fletcher, C. Frith, S.M. Lawrie, L. Muckli, P. Petrovic, P. Uhlhaas, M. Voss, P.R. Corlett, The predictive coding account of psychosis, Biol. Psychiatry 84 (9) (2018) 634–643, https://doi.org/10.1016/j.\n\nbiopsych.2018.05.015.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk212",
      "text": "Acknowledgements\n\nAcknowledgements\n\nWe thank Ren´e Baston, Matteo Colombo, Sabrina Coninx, Laura Convertino, Roy Dings, Leonard Dung, Regina Fabry, Noor Sajid, Ronald Sladky, Ryan Smith, Alfredo Vernazzani, and Julia Wolf for feedback on an earlier version of this paper. The funding was provided to Karl J. Friston (Wellcome Principal Fellowship, grant ID: 088130/Z/09/Z).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk213",
      "text": "[25] M. Ratcliffe, Varieties of temporal experience in depression, J. Med. Philos. 37 (2) (2012) 114–138, https://doi.org/10.1093/jmp/jhs010.\n\n[26] A. Ciaunica, J. Charlton, H. Farmer, When the window cracks: transparency and the fractured self in depersonalisation, Phenomenol. Cogn. Sci. (2020) 1–19,\n\nhttps://doi.org/10.1007/s11097-020-09677-z.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk214",
      "text": "[27] A. Giersch, L. Lalanne, P. Isope, Implicit timing as the missing link between neurobiological and self disorders in schizophrenia? Front Hum. Neurosci. 10\n\n(2016) 303, https://doi.org/10.3389/fnhum.2016.00303.\n\n[28] T. Nagel, What is it like to be a bat? Philos. Rev. 83 (4) (1974) 435–450, https://\n\ndoi.org/10.2307/2183914.\n\n[29] W. Wiese, Toward a mature science of consciousness, Front. Psychol. 9 (2018) 693, https://doi.org/10.3389/fpsyg.2018.00693.\n\nDeclarations of interest\n\nNone.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk215",
      "text": "References\n\n[1] K.J. Friston, A.D. Redish, J.A. Gordon, Computational nosology and precision psychiatry, Comput. Psychiatry 1 (2017) 2–23, https://doi.org/10.1162/CPSY_a_\n\n00001.\n\n[2] K. Friston, K.E. Stephan, R. Montague, R.J. Dolan, Computational psychiatry: the brain as a phantastic organ, Lancet Psychiatry 1 (2) (2014) 148–158, https://doi.\n\norg/10.1016/S2215-0366(14)70275-5.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk216",
      "text": "[30] W. Wiese, The science of consciousness does not need another theory, it needs a minimal unifying model, Neurosci. Conscious. 2020 (1) (2020), https://doi.org/\n\n10.1093/nc/niaa013.\n\n[31] A. Doerig, A. Schurger, M.H. Herzog, Hard criteria for empirical theories of consciousness, Cogn. Neurosci. (2020) 1–22, https://doi.org/10.1080/\n\n17588928.2020.1772214.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk217",
      "text": "[32] D.J. Chalmers, How can we construct a science of consciousness? in: M. Gazzaniga (Ed.), The Cognitive Neurosciences III MIT Press, 2004,\n\npp. 1111–1119.\n\n[33] M. Michel, D. Beck, N. Block, H. Blumenfeld, R. Brown, D. Carmel, M. Carrasco, M. Chirimuuta, M. Chun, A. Cleeremans, S. Dehaene, S.M. Fleming, C. Frith, P. Haggard, B.J. He, C. Heyes, M.A. Goodale, L. Irvine, M. Kawato, R. Kentridge, J.R. King, R.T. Knight, S. Kouider, V. Lamme, D. Lamy, H. Lau, S. Laureys,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk218",
      "text": "Behavioural Brain Research 420 (2022) 113704\n\nW. Wiese and K.J. Friston\n\nJ. LeDoux, Y.T. Lin, K. Liu, S.L. Macknik, S. Martinez-Conde, G.A. Mashour, L. Melloni, L. Miracchi, M. Mylopoulos, L. Naccache, A.M. Owen, R.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk219",
      "text": "E. Passingham, L. Pessoa, M. Peters, D. Rahnev, T. Ro, D. Rosenthal, Y. Sasaki, C. Sergent, G. Solovey, N.D. Schiff, A. Seth, C. Tallon-Baudry, M. Tamietto, F. Tong, S. van Gaal, A. Vlassova, T. Watanabe, J. Weisberg, K. Yan, M. Yoshida, Opportunities and challenges for a maturing science of consciousness, Nat. Hum. Behav. 3 (2) (2019) 104–107, https://doi.org/10.1038/s41562-019-0531-8.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk220",
      "text": "[34] G. Northoff, V. Lamme, Neural signs and mechanisms of consciousness: is there a potential convergence of theories of consciousness in sight? Neurosci. Biobehav. Rev. 118 (2020) 568–587, https://doi.org/10.1016/j.neubiorev.2020.07.019.\n\n[35] S. Sarasso, A.G. Casali, S. Casarotto, M. Rosanova, C. Sinigaglia, M. Massimini, Consciousness and complexity: a consilience of evidence, Neurosci. Conscious. (2021), https://doi.org/10.1093/nc/niab023 niab023.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk221",
      "text": "[36] A.K. Seth, Consciousness: the last 50 years (and the next), Brain Neurosci. Adv. 2 (2018) 1–6, https://doi.org/10.1177/2398212818816019.\n\n[37] S.B. Fink, Commentary: The concept of a Bewusstseinskultur, Front. Psychol. 9 (2018) 732, https://doi.org/10.3389/fpsyg.2018.00732.\n\n[38] T. Metzinger, The Ego Tunnel, Basic Books, 2009.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk222",
      "text": "[58] N. Tandon, R. Tandon, Using machine learning to explain the heterogeneity of schizophrenia. Realizing the promise and avoiding the hype, Schizophr. Res. 214 (2019) 70–75, https://doi.org/10.1016/j.schres.2019.08.032.\n\n[59] D. Bzdok, J.P.A. Ioannidis, Exploration, inference, and prediction in neuroscience and biomedicine, Trends Neurosci. 42 (4) (2019) 251–262, https://doi.org/ 10.1016/j.tins.2019.02.001.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk223",
      "text": "[60] N. Koutsouleris, D.B. Dwyer, F. Degenhardt, C. Maj, M.F. Urquijo-Castro, R. Sanfelici, D. Popovic, O. Oeztuerk, S.S. Haas, J. Weiske, A. Ruef, L. Kambeitz- Ilankovic, L.A. Antonucci, S. Neufang, C. Schmidt-Kraepelin, S. Ruhrmann, N. Penzel, J. Kambeitz, T.K. Haidl, M. Rosen, K. Chisholm, A. Riecher-R¨ossler, L. Egloff, A. Schmidt, C. Andreou, J. Hietala, T. Schirmer, G. Romer, P. Walger, M. Franscini, N. Traber-Walker, B.G. Schimmelmann, R. Flückiger, C. Michel, W. R¨ossler, O. Borisov,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk224",
      "text": "P.M. Krawitz, K. Heekeren, R. Buechler, C. Pantelis, P. Falkai, R. Salokangas, R. Lencer, A. Bertolino, S. Borgwardt, M. Noethen, P. Brambilla, S.J. Wood, R. Upthegrove, F. Schultze-Lutter, A. Theodoridou, E. Meisenzahl, for the PRONIA Consortium, Multimodal machine learning workflows for prediction of psychosis in patients with clinical high-risk syndromes and recent-onset depression, JAMA Psychiatry 78 (2) (2021) 195–209,",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk225",
      "text": "[39] W. Wiese, Von der KI-Ethik zur Bewusstseinsethik: Ethische Aspekte der Computational Psychiatry, Psychiatr. Prax. 48 (S 01) (2021) S21–S25, https:// doi.org/10.1055/a-1369-2824.\n\n[40] Uusitalo, S., Ma, J.T., & Arstila, V. , 2020. Mapping out the philosophical questions of AI and clinical practice in diagnosing and treating mental disorders. 7.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk226",
      "text": "[41] M. Browning, C.S. Carter, C. Chatham, H. Den Ouden, C.M. Gillan, J.T. Baker, A. M. Chekroud, R. Cools, P. Dayan, J. Gold, R.Z. Goldstein, C.A. Hartley, A. Kepecs, R.P. Lawson, J. Mourao-Miranda, M.L. Phillips, D.A. Pizzagalli, A. Powers, D. Rindskopf, M. Paulus, Realizing the clinical potential of computational psychiatry: report from the banbury center meeting, february 2019, Biol. Psychiatry 88 (2020) e5–e10, https://doi.org/10.1016/j.biopsych.2019.12.026.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk227",
      "text": "[42] M. Colombo, A. Heinz, Explanatory integration, computational phenotypes, and dimensional psychiatry: the case of alcohol use disorder, Theory Psychol. 29 (5) (2019) 697–718, https://doi.org/10.1177/0959354319867392.\n\nhttps://doi.org/10.1001/jamapsychiatry.2020.3604.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk228",
      "text": "[61] R. Whelan, R. Watts, C.A. Orr, R.R. Althoff, E. Artiges, T. Banaschewski, G. J. Barker, A.L. Bokde, C. Büchel, F.M. Carvalho, P.J. Conrod, H. Flor, M. Fauth- Bühler, V. Frouin, J. Gallinat, G. Gan, P. Gowland, A. Heinz, B. Ittermann, C. Lawrence, K. Mann, J.L. Martinot, F. Nees, N. Ortiz, M.L. Paill`ere-Martinot, T. Paus, Z. Pausova, M. Rietschel, T.W. Robbins, M.N. Smolka, A. Str¨ohle, G. Schumann, H. Garavan, C. IMAGEN, Neuropsychosocial profiles of current and future adolescent alcohol",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk229",
      "text": "misusers, Nature 512 (7513) (2014) 185–189, https:// doi.org/10.1038/nature13402.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk230",
      "text": "[62] T.L. Beauchamp, J.F. Childress. Principles of Biomedical Ethics, 8th ed., Oxford University Press, 2019.\n\n[63] J. Illes, Neuroethics in a new era of neuroimaging, Am. J. Neuroradiol. 24 (2003) 1739–1741.\n\n[64] A. Roskies, Neuroethics for the new millenium, Neuron 35 (1) (2002) 21–23, https://doi.org/10.1016/S0896-6273(02)00763-8.\n\n[43] X.-J. Wang, J.H. Krystal, Computational psychiatry, Neuron 84 (3) (2014) 638–654, https://doi.org/10.1016/j.neuron.2014.10.018.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk231",
      "text": "[44] Q.J.M. Huys, M. Browning, M.P. Paulus, M.J. Frank, Advances in the computational understanding of mental illness, Neuropsychopharmacology 46 (1) (2021) 3–19, https://doi.org/10.1038/s41386-020-0746-4.\n\n[45] D. Bennett, S.M. Silverstein, Y. Niv, The two cultures of computational psychiatry, JAMA Psychiatry 76 (6) (2019) 563–564, https://doi.org/10.1001/\n\njamapsychiatry.2019.0231.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk232",
      "text": "[46] Q.J.M. Huys, Advancing clinical improvements for patients using the theory- driven and data-driven branches of computational psychiatry, JAMA Psychiatry 75 (3) (2018) 225–226, https://doi.org/10.1001/jamapsychiatry.2017.4246.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk233",
      "text": "[47] A.M. Chekroud, R.J. Zotti, Z. Shehzad, R. Gueorguieva, M.K. Johnson, M. H. Trivedi, T.D. Cannon, J.H. Krystal, P.R. Corlett, Cross-trial prediction of treatment outcome in depression: a machine learning approach, Lancet Psychiatry 3 (3) (2016) 243–250, https://doi.org/10.1016/S2215-0366(15) 00471-X.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk234",
      "text": "[48] L. Schmaal, A.F. Marquand, D. Rhebergen, M.-J. Tol, H.G. van, Ruh´e, N.J.A. Wee, D.J. van der, Veltman, B.W.J.H. Penninx, Predicting the naturalistic course of major depressive disorder using clinical and multimodal neuroimaging information: a multivariate pattern recognition study, Biol. Psychiatry 78 (4) (2015) 278–286, https://doi.org/10.1016/j.biopsych.2014.11.018.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk235",
      "text": "[49] R.A. Adams, Q.J. Huys, J.P. Roiser, Computational psychiatry: towards a mathematically informed understanding of mental illness, J. Neurol. Neurosurg. Psychiatry 87 (1) (2016) 53–63, https://doi.org/10.1136/jnnp-2015-310737.\n\n[50] C. Gauld, G. Dumas, ´E. Fakra, J. Mattout, J.-A. Micoulaud-Franchi, Les trois cultures de la psychiatrie computationnelle, Ann. M´edico-Psychol. Rev. Psychiatr. 179 (1) (2021) 63–71, https://doi.org/10.1016/j.amp.2020.11.011.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk236",
      "text": "[51] R.J. Moran, M. Symmonds, K.E. Stephan, K.J. Friston, R.J. Dolan, An in vivo assay of synaptic function mediating human cognition, Curr. Biol. 21 (15) (2011) 1320–1325, https://doi.org/10.1016/j.cub.2011.06.053.\n\n[52] K.E. Stephan, T. Baldeweg, K.J. Friston, Synaptic plasticity and dysconnection in schizophrenia, Biol. Psychiatry 59 (10) (2006) 929–939, https://doi.org/ 10.1016/j.biopsych.2005.10.005.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk237",
      "text": "[53] K.H. Brodersen, L. Deserno, F. Schlagenhauf, Z. Lin, W.D. Penny, J.M. Buhmann, K.E. Stephan, Dissecting psychiatric spectrum disorders by generative embedding, Neuroimage Clin. 4 (2014) 98–111, https://doi.org/10.1016/j.nicl.2013.11.002.\n\n[65] N. Bostrom, E. Yudkowsky, The ethics of artificial intelligence, in: K. Frankish, W. M. Ramsey (Eds.), The Cambridge Handbook of Artificial Intelligence, Vol. 1, Cambridge University Press, 2014, pp. 316–334.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk238",
      "text": "[66] C. Cole, L.E. Petree, J.P. Phillips, J.M. Shoemaker, M. Holdsworth, D.L. Helitzer, ‘Ethical responsibility’ or ‘a whole can of worms’: differences in opinion on incidental finding review and disclosure in neuroimaging research from focus group discussions with participants, parents, IRB members, investigators, physicians and community members, J. Med. Ethics 41 (10) (2015) 841–847, https://doi.org/10.1136/medethics-2014-102552.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk239",
      "text": "[67] J. Illes, E. Racine, Imaging or imagining? A neuroethics challenge informed by genetics, Am. J. Bioeth. 5 (2) (2005) 5–18, https://doi.org/10.1080/ 15265160590923358.\n\n[68] T. Fuchs, Ethical issues in neuroscience, Curr. Opin. Psychiatry 19 (6) (2006)\n\n600–607.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk240",
      "text": "[69] M. Christen, J. Domingo-Ferrer, B. Draganski, T. Spranger, H. Walter, On the compatibility of big data driven research and informed consent: the example of the human brain project, in: B.D. Mittelstadt, L. Floridi (Eds.), The Ethics of Biomedical Big Data, Springer International Publishing, 2016, pp. 199–218, https://doi.org/10.1007/978-3-319-33525-4_9.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk241",
      "text": "[70] Murray, C.J. L., Vos, T., Lozano, R., Naghavi, M., Flaxman, A.D., Michaud, C., Ezzati, M., Shibuya, K., Salomon, J.A., Abdalla, S., et al., 2012. Disability- adjusted life years (DALYs) for 291 diseases and injuries in 21 regions, 1990–2010: A systematic analysis for the global burden of disease study 2010. The Lancet, 380(9859), 2197–2223. https://doi.org/10.1016/S0140–6736(12)\n\n61689–4.\n\n[71] Mental health atlas 2017, World Health Organization, 2018.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk242",
      "text": "[72] J. Addington, R.K. Heinssen, D.G. Robinson, N.R. Schooler, P. Marcy, M. F. Brunette, C.U. Correll, S. Estroff, K.T. Mueser, D. Penn, J.A. Robinson, R. A. Rosenheck, S.T. Azrin, A.B. Goldstein, J. Severe, J.M. Kane, Duration of untreated psychosis in community treatment settings in the united states, Psychiatr. Serv. 66 (7) (2015) 753–756, https://doi.org/10.1176/appi.\n\nps.201400124.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk243",
      "text": "[73] Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S. , 2021. On the dangers of stochastic parrots: Can language models be too big? 列 Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency,\n\n610–623. https://doi.org/10.1145/3442188.3445922.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk244",
      "text": "[54] K.H. Brodersen, T.M. Schofield, A.P. Leff, C.S. Ong, E.I. Lomakina, J.M. Buhmann, K.E. Stephan, Generative embedding for model-based classification of fMRI data, PLoS Comput. Biol. 7 (6) (2011), e1002079, https://doi.org/10.1371/journal.\n\npcbi.1002079.\n\n[74] A. Adadi, M. Berrada, Peeking inside the black-box: a survey on explainable artificial intelligence (XAI), IEEE Access 6 (2018) 52138–52160.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk245",
      "text": "[75] H. Walter, The third wave of biological psychiatry, Front. Psychol. 4 (2013) 582, https://doi.org/10.3389/fpsyg.2013.00582.\n\n[55] K.E. Stephan, F. Schlagenhauf, Q.J.M. Huys, S. Raman, E.A. Aponte, K. H. Brodersen, L. Rigoux, R.J. Moran, J. Daunizeau, R.J. Dolan, K.J. Friston, A. Heinz, Computational neuroimaging strategies for single patient predictions, Neuroimage 145 (Pt B) (2017) 180–199, https://doi.org/10.1016/j.\n\nneuroimage.2016.06.038.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk246",
      "text": "[56] K.E. Stephan, J. Siemerkus, M. Bischof, H. Haker, Hat computational psychiatry relevanz für die klinische praxis der psychiatrie? Z. Psychiatr. Psychol. Psychother. 65 (1) (2017) 9–19, https://doi.org/10.1024/1661-4747/a000296.\n\n[57] D. Bzdok, A. Meyer-Lindenberg, Machine learning for precision psychiatry: opportunities and challenges, Biol. Psychiatry Cogn. Neurosci. Neuroimaging 3 (3) (2018) 223–230, https://doi.org/10.1016/j.bpsc.2017.11.007.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk247",
      "text": "[76] T. Hagendorff, The ethics of ai ethics: an evaluation of guidelines, Minds Mach. 30 (1) (2020) 99–120, https://doi.org/10.1007/s11023-020-09517-8.\n\n[77] V. Dignum, The myth of complete ai-fairness, in: A. Tucker, P. Henriques Abreu, J. Cardoso, P. Pereira Rodrigues, D. Ria˜no (Eds.), Artificial Intelligence in Medicine, Springer International Publishing, 2021, https://doi.org/10.1007/978-\n\n3-030-77211-6_1 (Bd. 12721, S. 3-8).",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk248",
      "text": "[78] Q.J.M. Huys, M. Moutoussis, J. Williams, Are computational models of any use to psychiatry? Neural Netw. 24 (6) (2011) 544–551, https://doi.org/10.1016/j.\n\nneunet.2011.03.001.\n\n[79] T.R. Insel, P.S. Wang, Rethinking mental illness, J. Am. Med. Assoc. 303 (19) (2010) 1970–1971, https://doi.org/10.1001/jama.2010.555.\n\n10",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk249",
      "text": "Behavioural Brain Research 420 (2022) 113704\n\nW. Wiese and K.J. Friston\n\n[80] K.S. Kendler, P. Zachar, C. Craver, What kinds of things are psychiatric disorders? Psychol. Med. 41 (6) (2011) 1143–1150, https://doi.org/10.1017/ S0033291710001844.\n\n[81] D. Borsboom, A network theory of mental disorders, World Psychiatry 16 (2017) 5–13.\n\nexperience and of their disturbance in major depressive disorder. 〈http://phil sci-archive.pitt.edu/18377/〉.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk250",
      "text": "[108] A.K. Seth, K. Suzuki, H.D. Critchley, An interoceptive predictive coding model of conscious presence, Front. Psychol. 2 (395) (2012), https://doi.org/10.3389/ fpsyg.2011.00395.\n\n[82] D. Borsboom, A.O.J. Cramer, A. Kalis, Brain disorders? Not really: why network structures block reductionism in psychopathology research, Behav. Brain Sci. 42 (2019) 1–11, https://doi.org/10.1017/S0140525×17002266.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk251",
      "text": "[83] P. Schwartenbeck, T.H.B. FitzGerald, C. Mathys, R. Dolan, F. Wurst, M. Kronbichler, K. Friston, Optimal inference with suboptimal models: addiction and active bayesian inference, Med. Hypotheses 84 (2) (2015) 109–117, https:// doi.org/10.1016/j.mehy.2014.12.007.\n\n[84] S. Brugger, M. Broome, Computational psychiatry, in: M. Sprevak, M. Colombo (Eds.), The Routledge Handbook of the Computational Mind, Routledge, 2019, pp. 468–484.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk252",
      "text": "[85] K.S. Button, M. Browning, M.R. Munaf`o, G. Lewis, Social inference and social anxiety: evidence of a fear-congruent self-referential learning bias, J. Behav. Ther. Exp. Psychiatry 43 (4) (2012) 1082–1087, https://doi.org/10.1016/j.\n\njbtep.2012.05.004.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk253",
      "text": "[86] K.S. Button, D. Kounali, L. Stapinski, R.M. Rapee, G. Lewis, M.R. Munaf`o, Fear of negative evaluation biases social evaluation inference: evidence from a probabilistic learning task, PLoS One 10 (4) (2015), e0119456, https://doi.org/ 10.1371/journal.pone.0119456.\n\n[87] D. Borsboom, A.O.J. Cramer, A. Kalis, Authors’ response: Rreductionism in retreat, Behav. Brain Sci. 42 (2019) 44–53.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk254",
      "text": "[109] W. Wiese, Explaining the enduring intuition of substantiality: the phenomenal self as an abstract „Salience Object“, J. Conscious. Stud. 26 (3–4) (2019) 64–87.\n\n[110] W. Wiese, Breaking the self: radical disruptions of self-consciousness and impossible conscious experiences, Philos. Mind Sci. 1 (I) (2020) 1–27, https://doi. org/10.33735/phimisci.2020.I.32.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk255",
      "text": "[111] H. Walter, Description is not enough: the real challenge of enactivism for psychiatry, Philos. Psychiatry Psychol. 27 (1) (2020) 85–87, https://doi.org/ 10.1353/ppp.2020.0011.\n\n[112] A.D. Redish, R. Kazinka, A.B. Herman, Taking an engineer’s view: implications of network analysis for computational psychiatry, Behav. Brain Sci. 42 (2019), e24, https://doi.org/10.1017/S0140525×18001152.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk256",
      "text": "[113] D. Borsboom, A.O.J. Cramer, Network analysis: an integrative approach to the structure of psychopathology, Annu. Rev. Clin. Psychol. 9 (1) (2013) 91–121, https://doi.org/10.1146/annurev-clinpsy-050212-185608.\n\n[114] S. Fellowes, How autism shows that symptoms, like psychiatric diagnoses, are “constructed”: methodological and epistemic consequences, Synthese 199 (2021) 4499–4522, https://doi.org/10.1007/s11229-020-02988-3.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk257",
      "text": "[115] E. Nutma, H. Willison, G. Martino, S. Amor, Neuroimmunology – the past, present and future, Clin. Exp. Immunol. 197 (3) (2019) 278–293, https://doi.org/\n\n10.1111/cei.13279.\n\n[88] A. Newen, L. De Bruin, S. Gallagher, The Oxford Handbook of 4E Cognition, Oxford University Press, 2018.\n\n[89] M.R. Pawelzik, Commentary on Henrik Walter’s “the third wave of biological psychiatry”, Front. Psychol. 4 (2013) 832, https://doi.org/10.3389/\n\nfpsyg.2013.00832.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk258",
      "text": "[90] J. Read, N. Haslam, L. Sayce, E. Davies, Prejudice and schizophrenia: a review of the ‘mental illness is an illness like any other’ approach, Acta Psychiatr. Scand. 114 (5) (2006) 303–318, https://doi.org/10.1111/j.1600-0447.2006.00824.x.\n\n[116] A. Bhat, T. Parr, M. Ramstead, K. Friston, Immunoceptive inference: why are psychiatric disorders and immune responses intertwined? Biol. Philos. 36 (3)\n\n(2021) 27, https://doi.org/10.1007/s10539-021-09801-6.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk259",
      "text": "[117] R. Smith, K.L. Weihs, A. Alkozei, W.D.S. Killgore, R.D. Lane, An embodied neurocomputational framework for organically integrating biopsychosocial processes: an application to the role of social support in health and disease, Psychosom. Med. 81 (2) (2019) 125–145, https://doi.org/10.1097/\n\nPSY.0000000000000661.\n\n[91] K.S. Kendler, Explanatory models for psychiatric illness, Am. J. Psychiatry 165 (6) (2008) 695–702, https://doi.org/10.1176/appi.ajp.2008.07071061.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk260",
      "text": "[92] R. Smith, A. Alkozei, W.D.S. Killgore, R.D. Lane, Nested positive feedback loops in the maintenance of major depression: an integration and extension of previous models, Brain Behav. Immun. 67 (2018) 374–397, https://doi.org/10.1016/j. bbi.2017.09.011.\n\n[93] R.A. Adams, P. Vincent, D. Benrimoh, K.J. Friston, T. Parr, Everything is connected: inference and attractors in delusions, Schizophr. Res. (2021), https:// doi.org/10.1016/j.schres.2021.07.032.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk261",
      "text": "[94] A.F. Marquand, S.M. Kia, M. Zabihi, T. Wolfers, J.K. Buitelaar, C.F. Beckmann, Conceptualizing mental disorders as deviations from normative functioning, Mol. Psychiatry 24 (1010) (2019) 1415–1424, https://doi.org/10.1038/s41380-019- 0441-1.\n\n[118] H.G. Morgan, R. Stanton, Suicide among psychiatric in-patients in a changing clinical scene: suicidal ideation as a paramount index of short-term risk, Br. J. Psychiatry 171 (6) (1997) 561–563, https://doi.org/10.1192/bjp.171.6.561.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk262",
      "text": "[119] C.M. McHugh, A. Corderoy, C.J. Ryan, I.B. Hickie, M.M. Large, Association between suicidal ideation and suicide: meta-analyses of odds ratios, sensitivity, specificity and positive predictive value, BJPsych Open 5 (2) (2019), https://doi. org/10.1192/bjo.2018.88.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk263",
      "text": "[120] A. Horvath, M. Dras, C.C.W. Lai, S. Boag, Predicting suicidal behavior without asking about suicidal ideation: machine learning and the role of borderline personality disorder criteria, Suicide Life-Threat. Behav. (2020), https://doi.org/\n\n10.1111/sltb.12719.\n\n[121] G.E. Engel, The need for a new medical model: a challenge for biomedicine, Science 196 (4286) (1977) 129–136.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk264",
      "text": "[95] K.E. Stephan, S. Iglesias, J. Heinzle, A.O. Diaconescu, Translational perspectives for computational neuroimaging, Neuron 87 (4) (2015) 716–732, https://doi. org/10.1016/j.neuron.2015.07.008.\n\n[122] W. Wiese, K.J. Friston, The neural correlates of consciousness under the free energy principle: from computational correlates to computational explanation, Philos. Mind Sci. 2 (2021) 9, https://doi.org/10.33735/phimisci.2021.81.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk265",
      "text": "[96] T. Erdmann, C. Mathys, A generative framework for the study of delusions, Schizophr. Res. (2021), https://doi.org/10.1016/j.schres.2020.11.048.\n\nS0920996420306277.\n\n[97] M. Miller, J. Kiverstein, E. Rietveld, Embodying addiction: a predictive processing account, Brain Cogn. 138 (2020), 105495, https://doi.org/10.1016/j.\n\nbandc.2019.105495.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk266",
      "text": "[98] M. Colombo, R.E. Fabry, Underlying delusion: predictive processing, looping effects, and the personal/sub-personal distinction, Philos. Psychol. (2021) 1–27,\n\nhttps://doi.org/10.1080/09515089.2021.1914828.\n\n[99] P.R. Corlett, P.C. Fletcher, Computational psychiatry: a rosetta stone linking the brain to mental illness, Lancet Psychiatry 1 (5) (2014) 399–402, https://doi.org/\n\n10.1016/S2215-0366(14)70298-6.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk267",
      "text": "[100] G. Deane, M. Miller, S. Wilkinson, Losing ourselves: active inference, depersonalization, and meditation, Front. Psychol. (2020) 0, https://doi.org/\n\n10.3389/fpsyg.2020.539726.\n\n[101] M.J. Edwards, R.A. Adams, H. Brown, I. Pare´es, K.J. Friston, A bayesian account of “hysteria, Brain 135 (Pt 11) (2012) 3495–3512, https://doi.org/10.1093/ brain/aws129.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk268",
      "text": "[123] C.A. Sanislow, D.S. Pine, K.J. Quinn, M.J. Kozak, M.A. Garvey, R.K. Heinssen, P. S.-E. Wang, B.N. Cuthbert, Developing constructs for psychopathology research: research domain criteria, J. Abnorm. Psychol. 119 (4) (2010) 631–639, https://\n\ndoi.org/10.1037/a0020909.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk269",
      "text": "[124] T. Insel, B. Cuthbert, M. Garvey, R. Heinssen, D.S. Pine, K. Quinn, C. Sanislow, P. Wang, Research domain criteria (RDoC): toward a new classification framework for research on mental disorders, Am. J. Psychiatry 167 (7) (2010) 748–751, https://doi.org/10.1176/appi.ajp.2010.09091379.\n\n[125] S.O. Lilienfeld, M.T. Treadway, Clashing diagnostic approaches: DSM-ICD versus RDoC, Annu. Rev. Clin. Psychol. 12 (1) (2016) 435–463, https://doi.org/ 10.1146/annurev-clinpsy-021815-093122.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk270",
      "text": "[126] H. Berenbaum, Classification and psychopathology research, J. Abnorm. Psychol. 122 (3) (2013) 894–901, https://doi.org/10.1037/a0033096.\n\n[127] B.N. Cuthbert, M.J. Kozak, Constructing constructs for psychopathology: the NIMH research domain criteria, J. Abnorm. Psychol. 122 (3) (2013) 928–937,\n\nhttps://doi.org/10.1037/a0034028.\n\n[128] H. Chang, Inventing Temperature: Measurement and Scientific Progress, Oxford University Press, 2004.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk271",
      "text": "[102] R.E. Fabry, Into the dark room: a predictive processing account of major depressive disorder, Phenomenol. Cogn. Sci. 19 (4) (2020) 685–704, https://doi.\n\norg/10.1007/s11097-019-09635-4.\n\n[103] P.C. Fletcher, C.D. Frith, Perceiving is believing: a bayesian approach to explaining the positive symptoms of schizophrenia, Nat. Rev. Neurosci. 10 (1)\n\n(2009) 48–58, https://doi.org/10.1038/nrn2536.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk272",
      "text": "[129] H. Chang, Epistemic iteration and natural kinds: Realism and pluralism in taxonomy, in: K.S. Kendler, J. Parnas (Eds.), Philosophical Issues in Psychiatry: Classification of Psychiatric Illness IV, Oxford University Press, 2017, pp. 229–245.\n\n[130] M. Colombo Computational modelling for alcohol use disorder. (forthcoming). Submitted for publication.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk273",
      "text": "[104] P. Gerrans, Pain asymbolia as depersonalization for pain experience. An interoceptive active inference account, Front. Psychol. (2020) 0, https://doi.org/\n\n10.3389/fpsyg.2020.523710.\n\n[105] J. Kiverstein, M. Miller, E. Rietveld, How mood tunes prediction: a neurophenomenological account of mood and its disturbance in major depression, Neurosci. Conscious. 2020 (1) (2020), https://doi.org/10.1093/nc/niaa003 niaa003.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk274",
      "text": "[131] K.S. Kendler, Psychiatric nosology, epistemic iteration, and pluralism, in: K. S. Kendler, J. Parnas (Eds.), Philosophical Issues in Psychiatry: Classification of\n\nPsychiatric Illness IV, Oxford University Press, 2017, pp. 246–249.\n\n[132] K.R. Popper, Logik der Forschung (H. Keuth, Ed.; 11th ed.), 2005. Mohr Siebeck. (Original work published 1934).\n\n[133] T.S. Kuhn, The Structure of Scientific Revolutions, 5th ed., The University of Chicago Press,, 1974, 1970.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk275",
      "text": "[106] M. Miller, A. Clark, Happily entangled: prediction, emotion, and the embodied mind, Synthese 195 (6) (2018) 2559–2575, https://doi.org/10.1007/s11229-\n\n017-1399-7.\n\n[107] Ramstead, M.J. D., Wiese, W., Miller, M., & Friston, K.J. , 2020. Deep\n\nneurophenomenology: An active inference account of some features of conscious\n\n[134] W.E.K. Middleton, A History of the Thermometer and Its Use in Meteorology, Johns Hopkins Press, 1966.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk276",
      "text": "[135] J. Rehm, S. Marmet, P. Anderson, A. Gual, L. Kraus, D.J. Nutt, R. Room, A. V. Samokhvalov, E. Scafato, M. Trapencieris, R.W. Wiers, G. Gmel, Defining substance use disorders: do we really need more than heavy use? Alcohol. Alcohol. 48 (6) (2013) 633–640, https://doi.org/10.1093/alcalc/agt127.\n\n11\n\nW. Wiese and K.J. Friston\n\nBehavioural Brain Research 420 (2022) 113704\n\nW. Wiese and K.J. Friston",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk277",
      "text": "[136] W.M. Compton, S.B. Guze, The neo-kraepelinian revolution in psychiatric diagnosis, Eur. Arch. Psychiatry Clin. Neurosci. 245 (4) (1995) 196–201, https:// doi.org/10.1007/BF02191797.\n\n[139] C. Korth, H. Fangerau, Blood tests to diagnose schizophrenia: self-imposed limits in psychiatry, Lancet Psychiatry 7 (2020) 911–914, https://doi.org/10.1016/ S2215-0366(20)30058-4.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk278",
      "text": "[137] L. Deserno, A. Heinz, F. Schlagenhauf, Computational approaches to schizophrenia: a perspective on negative symptoms, Schizophr. Res. 186 (2017) 46–54, https://doi.org/10.1016/j.schres.2016.10.004.\n\n[140] B. Martin, N. Franck, M. Cermolacce, J.T. Coull, A. Giersch, Minimal self and timing disorders in schizophrenia: a case report, Front. Hum. Neurosci. (2018) 12, https://doi.org/10.3389/fnhum.2018.00132.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk279",
      "text": "[138] D.S. Barron, Commentary: The ethical challenges of machine learning in psychiatry: A focus on data, diagnosis, and treatment, Psychol. Med. (2021) 1–3, https://doi.org/10.1017/S0033291721001008.\n\n[141] N.R. Winter, M. Cearns, S.R. Clark, R. Leenings, U. Dannlowski, B.T. Baune, T. Hahn, From multivariate methods to an AI ecosystem, Mol. Psychiatry (2021) 1–5, https://doi.org/10.1038/s41380-021-01116-y.",
      "source": "p4.pdf"
    },
    {
      "id": "p4.pdf_chunk280",
      "text": "[142] M. Zimmermann, T.A. Morgan, K. Stanton, The severity of psychiatric disorders, World Psychiatry 17 (2018) 258–275, https://doi.org/10.1002/wps.20569.\n\n12",
      "source": "p4.pdf"
    },
    {
      "id": "p5.pdf_chunk0",
      "text": "Comment\n\nFairness metrics for health Al: we have a long way to go\n\n® Check for updates\n\nAmarachi B. Mbakwe,\" Ismini Lourentzou,“ Leo Anthony Celi,\" and Joy T. Wu\"",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk1",
      "text": "“Department of Computer Science, Virginia Tech, Blacksburg, VA 24061, USA “Institute of Medical Engineering and Science, Massachusetts Institute of Technology, Cambridge, MA 02139, “Department of Medicine, Beth Israel Deaconess Medical Center, Boston, MA 02215, USA Department of Biostatistics, Harvard T.H. Chan School of Public Health, Boston, MA 02115, USA “Department of Radiology, Stanford Medicine, Stanford University, Stanford, CA 94305, USA\n\nUSA",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk2",
      "text": "The use of Artificial Intelligence (AI) is on track to revolutionize healthcare, with performance in medical tasks such as clinical diagnosis often being compara- ble to expert-level accuracy, at least in the laboratory. AI can play a significant role in healthcare, enabling clinicians to make more accurate and timely di- agnoses and devise effective treatment plans. Howev- er, the amplification of pre-existing healthcare inequity with the use of AI models is a legitimate concern. Recent works",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk3",
      "text": "have shown that medical imaging AI models can easily encode and learn patient-sensitive characteristics’ and cause significant performance disparities between patient subgroups.’ Therefore, it is encouraging to see more attempts, such as from Glocker et al.,* that evaluate methods for assessing ow sensitive patient information, such as ethnicity and sex, are encoded and possibly used in model predictions. Unfortunately, for many diagnostic and prognostic clinical applications, the “ground truth”",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk4",
      "text": "used for fairness assessment metrics may already be embedded with biases and laced with suboptimal outcomes that are not explained by clinical features. As such, the medical Al community needs to go eyond solely evaluating the clinical readiness of A models with metrics that are predicated on potentially",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk5",
      "text": "iased and constantly shifting clinical ground truth.",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk6",
      "text": "A critical step towards addressing AI model bias and subgroup disparities is the establishment of common principles, guidelines, and standards that model de- velopers adhere to. These standards would need to emphasize the importance of fairness and transparency in AI systems’ design and deployment. Proper docu- mentation of model performance across patient sub- groups is a minimum requirement. Depending on the clinical use case, models should be designed and evalu- ated with additional impact",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk7",
      "text": "metrics that consider existing health inequities and possible harm for disadvantaged subgroups. Recent work by MEDFAIR,‘ a benchmark for building and evaluating fair medical imaging models, is a contribution towards this. An ideal guideline would need to cover requirements for appropriate debiasing",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk8",
      "text": "DOT of original article: https://doi.org/10.1016/j.ebiom.2023.104467 *Corresponding author.\n\nE-mail address: \\celi@mit.edu (L.A. Celi).\n\n© 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/ 4.0/).",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk9",
      "text": "techniques and evaluation metrics for different sources of ias. These include, but are not limited to, bias arising from dataset composition, model feature encoding, the use of learned demographic features (also known as shortcut features), and bias in ground truth labels.",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk10",
      "text": "Datasets can encode bias, such as from underrepre- sentation of already disadvantaged subgroups. Clinician ias can also be reflected in data and learned by AI. In medical images, bias may even be introduced from ac- cess to different quality scanners. These biases in the data should be documented, e.g., by using “datasheets for datasets”.’ Federated learning methods can also aid in training/tuning model(s) on more varied databases from different parts of the world and/or from under- represented",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk11",
      "text": "subgroups. Moreover, dataset bias miti- gating strategies may be helpful, including dataset preprocessing, e.g., reweighing unintended features so that they are statistically independent of the target/ outcome label.° However, it is unclear how well these methods work for medical images.",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk12",
      "text": "Model feature encoding is another source of bias. Al models can identify race and sex from medical images across modalities and use these characteristics to detect diseases, even when such characteristics are not asso- ciated with the diagnosis.’ Even after removing sensitive information from datasets, which may not even be possible for medical images, models can still encode and use other correlated features for prediction. The “fairness through awareness” framework’ shows why we cannot assume",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk13",
      "text": "sensitive information has been expunged from a dataset. The framework also offers a metric-based approach for ensuring that a model’s la- beling of similar individuals is indeed similar.",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk14",
      "text": "Furthermore, models can inherit disparities from medical data through learning to depend on correlations between unrelated input features (e.g., nonbinary gender, immigration status), and the predicted out- comes. Glocker et al. highlighted difficulties in detecting what information is used in model predictions,’ despite trying a range of methods from transfer learning, mul- titask learning, and unsupervised exploration of feature representations. Besides these methods, algorithmic transparency,",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk15",
      "text": "explainability and interpretability,*°® focus instead on understanding how encoded input features are used for model prediction. Without an in-depth understanding of what features AI models use in mak- ing predictions, the promise of AI may not be realized.",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk16",
      "text": "eBioMedicine\n\n2023;90: 104525 Published Online 14 March 2023 https://doi.org/10. 1016/j.ebiom.2023. 104525\n\nwww.thelancet.com Vol 90 April, 2023\n\nComment",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk17",
      "text": "Few have explored metrics that quantify the effect of training on potentially biased ground truth labels. The closest in the fairness literature involves social welfare functions® that aim to capture the underlying social phenomena and inequities when the model learns from not completely reliant on ground truth assessing readiness of medical imaging AI tools. Short of such metrics, intra- and post-processing de-biasing techniques may help reduce subgroup performance lata. More work is needed to",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk18",
      "text": "develop metrics that are labels for isparity. An example was employed in recent work on neural network pruning and fine-tuning for chest X-ray classifiers.\"",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk19",
      "text": "q AI in healthcare is intended to improve access to uality healthcare, especially for those who are marginalized. It is worrisome to find evidence across many works that these models utilize non-clinical de- mographic attributes and are likely to propagate existing isparities. Current attempts to understand how imag- ing models encode and use non-clinical demographic information for prediction are encouraging, but are still limited. More interdisciplinary communication and collaboration between",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk20",
      "text": "AI researchers, healthcare pro- viders, social scientists, and the public would be needed to advance fairness, transparency, and accountability of medical imaging models.",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk21",
      "text": "Contributors\n\nAll the authors participated in the outline development, writing and editing of the manuscript.\n\nDeclaration of interests\n\nLA.C. received support for attending meetings and/or for travel by Massachusetts Institute of Technology, and cloud credits from Amazon, Google, and Oracle. The other authors have no conflicts of interest to declare.",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk22",
      "text": "References\n\n1 Gichoya JW, Banerjee I, Bhimireddy AR, et al. Al recognition of patient race in medical imaging: a modeling study. Lancet Digit Health. 2022;4(6):e406-e414.\n\nSeyyed-Kalantari L, Zhang H, McDermott MB, Chen IY, Ghassemi M. Underdiagnosis bias of artificial intelligence algo- rithms applied to chest radiographs in under-served patient pop- ulations. Nat Med. 2021;27(12):2176-2182.",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk23",
      "text": "Glocker B, Jones C, Bernhardt M, Winzeck S. Algorithmic encod- ing of protected characteristics in chest X-ray disease detection models. eBioMedicine. 2023;89:104467. https://doi.org/10.1016/j. ebiom.2023.104467.\n\nZong Y, Yang Y, Hospedales T. MEDFAIR: benchmarking fairness for medical imaging. In: Proceedings of the Eleventh International Conference on Learning Representations (ICLR). 2023.\n\nGebru T, Morgenstern J, Vecchione B, et al. Datasheets for datasets. Commun ACM. 2021;64(12):86-92.",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk24",
      "text": "Kamiran F, Calders T. Data preprocessing techniques for classifi- cation without discrimination. Knowl Inf Syst. 2012;33(1):1-33.\n\nDwork C, Hardt M, Pitassi T, Reingold O, Zemel R. Fairness through awareness. In: Proceedings of the 3rd Innovations in Theo- retical Computer Science Conference. 2012:214-226.\n\nSalahuddin Z, Woodruff HC, Chatterjee A, Lambin P. Trans- parency of deep neural networks for medical image analysis: a re- view of interpretability methods. Comput Biol Med. 2022;140:105111.",
      "source": "p5.pdf"
    },
    {
      "id": "p5.pdf_chunk25",
      "text": "Jungmann F, Ziegelmayer S, Lohoefer FK, et al. Algorithmic trans- parency and interpretability measures improve radiologists’ perfor- mance in BI-RADS 4 classification. Eur Radiol. 2023;33(3):1844-1851.\n\n10 Marcinkevics R, Ozkan E, Vogt JE. Debiasing deep chest x-ray classifiers using intra-and post-processing methods. In: Machine Learning for Healthcare Conference. PMLR; 2022:504-536.\n\nwww.thelancet.com Vol 90 April, 2023",
      "source": "p5.pdf"
    }
  ]
}